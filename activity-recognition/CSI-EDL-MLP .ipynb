{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "587c469f",
   "metadata": {
    "id": "587c469f"
   },
   "source": [
    "# MLP Training and Testing\n",
    "\n",
    "Sample code to train and test a simple MLP with CSI data extracted from a variational autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b258982",
   "metadata": {
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1677569943807,
     "user": {
      "displayName": "Federico CERUTTI",
      "userId": "05236606107795315109"
     },
     "user_tz": -60
    },
    "id": "3b258982"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TF log and warnings\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03db33a4",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677569944306,
     "user": {
      "displayName": "Federico CERUTTI",
      "userId": "05236606107795315109"
     },
     "user_tz": -60
    },
    "id": "03db33a4"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0) # predictable random numbers, for demonstration only\n",
    "\n",
    "# computes golden ratio for figures\n",
    "def goldenrect(h):\n",
    "    return (h * 1.618, h)\n",
    "\n",
    "def summary_clf(y_test, predicted, y_score, _labels = None):\n",
    "    print(classification_report(y_test, predicted, labels= _labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a495f56",
   "metadata": {
    "id": "9a495f56"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "The `latent_space_dataset` directory contains some datasets of CSI that have been already processed by the VAE. The VAE has been trained without any information about the target classes; it just tries to minimize reconstruction loss + KL loss.\n",
    "\n",
    "The Encoder in the VAE maps sequences of CSI into **2 Gaussian variables** with parameters (z_mean, z_log_var).\n",
    "\n",
    "More in detail, from the dataset we load `data` and `labels`.\n",
    "- `data`: every element is a 4-tuple with the values (z1_mean, z2_mean, z1_log_var, z2_log_var)\n",
    "- `labels`: 5 different classes, labelled with integers from 0 to 4 (0 = walk, 1 = run, 2 = jump, 3 = sit, 4 = empty)\n",
    "\n",
    "Available datasets:\n",
    "- `single_antenna`: data of just antenna 1, normalized wrt to the maximum value over the entire dataset (four antennas are available, numbered from 0 to 3)\n",
    "- `four_antennas`: data of the four antennas fused together, normalized wrt to the maximum value over the entire dataset\n",
    "- `four_antennas_latent_space_3`: same as `four_antennas`, but the CSI is mapped onto 3 Gaussian variables; hence, every element in `data` is a 6-tuple with the values (z1_mean, z2_mean, z3_mean, z1_log_var, z2_log_var, z3_log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "N8hPCwgQ_KUd",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1677569945438,
     "user": {
      "displayName": "Federico CERUTTI",
      "userId": "05236606107795315109"
     },
     "user_tz": -60
    },
    "id": "N8hPCwgQ_KUd"
   },
   "outputs": [],
   "source": [
    "semantic_classes = [\"Walk\", \"Run\", \"Jump\", \"Sit\", \"Empty\"]\n",
    "base_directory = './results'\n",
    "os.makedirs(base_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c1fd41",
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1677570061690,
     "user": {
      "displayName": "Federico CERUTTI",
      "userId": "05236606107795315109"
     },
     "user_tz": -60
    },
    "id": "33c1fd41"
   },
   "outputs": [],
   "source": [
    "def load_experiment(name, _test_size = 0.2, _random_state = 42):\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    # features columns\n",
    "    fcolumns = ['mu1','mu2','sigma1','sigma2']\n",
    "    \n",
    "    # check which experiments we wants to load\n",
    "    if name == \"No-Fused-1\":\n",
    "        with open('./latent_space_dataset/single_antenna_0.pkl', 'rb') as f:\n",
    "            data, labels = pickle.load(f)\n",
    "    elif name == \"No-Fused-2\":\n",
    "        with open('./latent_space_dataset/single_antenna_1.pkl', 'rb') as f:\n",
    "            data, labels = pickle.load(f)\n",
    "    elif name == \"No-Fused-3\":\n",
    "        with open('./latent_space_dataset/single_antenna_2.pkl', 'rb') as f:\n",
    "            data, labels = pickle.load(f)\n",
    "    elif name == \"No-Fused-4\":\n",
    "        with open('./latent_space_dataset/single_antenna_3.pkl', 'rb') as f:\n",
    "            data, labels = pickle.load(f)\n",
    "    elif name == \"Early-Fusing\":\n",
    "        with open('./latent_space_dataset/four_antennas.pkl', 'rb') as f:\n",
    "            data, labels = pickle.load(f)\n",
    "    elif name == \"Early-Fusing3\": # Same as Early-Fusing, but mapping the input data onto 3-dim Gaussian variables\n",
    "        with open('./latent_space_dataset/four_antennas_latent_space_3.pkl', 'rb') as f:\n",
    "            fcolumns = ['mu1','mu2', 'mu3', 'sigma1','sigma2','sigma3']\n",
    "            data, labels = pickle.load(f)\n",
    "    elif name == \"Delayed-Fusing\":\n",
    "        fcolumns=[\n",
    "                    'mu1_0','mu2_0','sigma1_0','sigma2_0',\n",
    "                    'mu1_1','mu2_1','sigma1_1','sigma2_1',\n",
    "                    'mu1_2','mu2_2','sigma1_2','sigma2_2',\n",
    "                    'mu1_3','mu2_3','sigma1_3','sigma2_3']\n",
    "        with open('./latent_space_dataset/four_antennas.pkl', 'rb') as f:\n",
    "            data, labels = pickle.load(f)\n",
    "        for ant in range(1,4):\n",
    "            with open(f'./latent_space_dataset/single_antenna_{ant}.pkl', 'rb') as f:\n",
    "                data_tmp, labels_tmp = pickle.load(f)\n",
    "            data = np.concatenate((data, data_tmp), axis=1)\n",
    "\n",
    "    # labels are categoricals\n",
    "    labels = np.asarray(labels, dtype=np.int32)\n",
    "    \n",
    "    # let's load into a dataframe\n",
    "    df = pd.DataFrame(data, columns=fcolumns)\n",
    "    df['signal'] = labels\n",
    "    \n",
    "    # standard scaler\n",
    "    scaler = StandardScaler().fit(df[fcolumns])\n",
    "    df[fcolumns] = scaler.transform(df[fcolumns])\n",
    "    \n",
    "    # test/train split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[fcolumns], df['signal'], \n",
    "                                                        test_size=_test_size, \n",
    "                                                        random_state=_random_state, \n",
    "                                                        stratify=df['signal'])\n",
    "    \n",
    "    \n",
    "    # one-hot-encoding\n",
    "    y_train_dummy = keras.utils.to_categorical(y_train)\n",
    "    y_test_dummy = keras.utils.to_categorical(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2d0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_reconstructed(directory, _test_size = 0.2, _random_state = 42):\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    # features columns\n",
    "    fcolumns = ['mu1','mu2','sigma1','sigma2']\n",
    "    \n",
    "    # check which experiments we wants to load\n",
    "    with open(directory, 'rb') as f:\n",
    "        data, labels = pickle.load(f)\n",
    "\n",
    "    # labels are categoricals\n",
    "    labels = np.asarray(labels, dtype=np.int32)\n",
    "    \n",
    "    # let's load into a dataframe\n",
    "    df = pd.DataFrame(data, columns=fcolumns)\n",
    "    df['signal'] = labels\n",
    "    \n",
    "    # standard scaler\n",
    "    scaler = StandardScaler().fit(df[fcolumns])\n",
    "    df[fcolumns] = scaler.transform(df[fcolumns])\n",
    "    \n",
    "    # test/train split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[fcolumns], df['signal'], \n",
    "                                                        test_size=_test_size, \n",
    "                                                        random_state=_random_state, \n",
    "                                                        stratify=df['signal'])\n",
    "    \n",
    "    # one-hot-encoding\n",
    "    y_train_dummy = keras.utils.to_categorical(y_train)\n",
    "    y_test_dummy = keras.utils.to_categorical(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c26dc867",
   "metadata": {
    "id": "c26dc867"
   },
   "source": [
    "## EDL models\n",
    "\n",
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654a4dc2",
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1677569979090,
     "user": {
      "displayName": "Federico CERUTTI",
      "userId": "05236606107795315109"
     },
     "user_tz": -60
    },
    "id": "654a4dc2"
   },
   "outputs": [],
   "source": [
    "num_epochs_annealing = 1\n",
    "num_classes = 5\n",
    "\n",
    "ep = 1.0\n",
    "class GetEpochs(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global ep\n",
    "        ep += 1\n",
    "\n",
    "def res_to_mean(ev, dim = 5):\n",
    "    return np.max(dirichlet.mean(ev.reshape(dim,)+1))\n",
    "\n",
    "def res_to_dirichlet(ev):\n",
    "    alpha = ev.reshape(2,)+1\n",
    "    S = np.sum(alpha)\n",
    "    K = 2.0\n",
    "    return dirichlet.mean(alpha), K/S\n",
    "\n",
    "def edl_accuracy(yTrue, yPred):\n",
    "    pred = K.argmax(yPred, axis=1)\n",
    "    truth = K.argmax(yTrue, axis=1)\n",
    "    match = K.reshape(K.cast(K.equal(pred, truth), \"float32\"),(-1,1))\n",
    "    return K.mean(match)\n",
    "\n",
    "def load_edl_experiment(name):\n",
    "    keras.models.load_model(name)\n",
    "\n",
    "def plot_res_beta(ev):\n",
    "    alpha = ev.reshape(2,)+1\n",
    "    plt.figure(figsize=(16,9))\n",
    "    x = np.linspace(0,1,1000)\n",
    "    plt.plot(x, beta.pdf(x, alpha[1], alpha[0]))\n",
    "    x1, x2 = beta.interval(0.95, alpha[1], alpha[0])\n",
    "    areaplot = np.multiply(beta.pdf(x, alpha[1],alpha[0]), rect(x,x1, x2))\n",
    "    plt.fill_between(x, 0, areaplot, alpha=0.5)\n",
    "\n",
    "def results_test(num_components, num_levels, dump_directory):\n",
    "    X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns = load_experiment_reconstructed(dump_directory)\n",
    "    model_directory = os.path.join(base_directory, f'{num_components}_components/models/{num_components}components_{num_levels}lvls_Keras_Model.keras')\n",
    "    mlp_edl = keras.models.load_model(model_directory, compile=False)\n",
    "    mlp_edl_scores = np.array([res_to_mean(r, dim=5) for r in mlp_edl.predict(X_test)])\n",
    "    y_predictions_edl = np.array(tf.argmax(mlp_edl.predict(X_test), axis=1))\n",
    "    print(summary_clf(y_test, y_predictions_edl, mlp_edl_scores))\n",
    "    accuracy = accuracy_score(y_test, y_predictions_edl)\n",
    "    cm = confusion_matrix(y_test, y_predictions_edl)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=semantic_classes)\n",
    "    cmdisp = disp.plot(cmap=\"cividis\")\n",
    "    CM_directory = os.path.join(base_directory, f'{num_components}_components/CMs/{num_components}components_{num_levels}lvls_ConfusionMatrix.png')\n",
    "    os.makedirs(os.path.dirname(CM_directory), exist_ok=True)\n",
    "    cmdisp.figure_.savefig(CM_directory, bbox_inches='tight')\n",
    "    return round(accuracy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8149a517",
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1677570289857,
     "user": {
      "displayName": "Federico CERUTTI",
      "userId": "05236606107795315109"
     },
     "user_tz": -60
    },
    "id": "8149a517"
   },
   "outputs": [],
   "source": [
    "def run_edl_experiment(name, num_components, num_levels, _X_train, _y_train_dummy):\n",
    "\n",
    "    model_edl = None\n",
    "    num_classes = 5\n",
    "    \n",
    "    if name == \"Delayed-Fusing\":\n",
    "        num_epochs_annealing = 3\n",
    "        batch_size = 128\n",
    "        lr = 0.01\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5, activation='softplus'))\n",
    "\n",
    "    elif name == \"Early-Fusing\":\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 128\n",
    "        lr = 0.001\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(4,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5,activation='softplus'))\n",
    "\n",
    "    elif name == \"Early-Fusing3\":\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 128\n",
    "        lr = 0.01\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(6,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5,activation='softplus'))\n",
    "\n",
    "    else:\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 128\n",
    "        lr = 0.01\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(4, activation='relu', input_shape=(4,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5,activation='softplus'))\n",
    "\n",
    "    def KL(alpha):\n",
    "        beta=K.constant(np.ones((1,num_classes)),dtype=\"float32\")\n",
    "        S_alpha = K.sum(alpha,axis=1,keepdims=True)\n",
    "        S_beta = K.sum(beta,axis=1,keepdims=True)\n",
    "        lnB = tf.math.lgamma(S_alpha) - K.sum(tf.math.lgamma(alpha),axis=1,keepdims=True)\n",
    "        lnB_uni = K.sum(tf.math.lgamma(beta),axis=1,keepdims=True) - tf.math.lgamma(S_beta)\n",
    "\n",
    "        dg0 = tf.math.digamma(S_alpha)\n",
    "        dg1 = tf.math.digamma(alpha)\n",
    "\n",
    "        return K.sum((alpha - beta)*(dg1-dg0),axis=1,keepdims=True) + lnB + lnB_uni\n",
    "\n",
    "    # Loss function considering the expected squared error and the KL divergence\n",
    "    def mse_loss(yTrue,yPred):\n",
    "        alpha = yPred + 1\n",
    "        S = K.sum(alpha, axis=1, keepdims=True)\n",
    "        m = alpha / S\n",
    "\n",
    "        # A + B minimises the sum of squared loss, see discussion in EDL paper for the derivation\n",
    "        A = K.sum((yTrue-m)**2, axis=1, keepdims=True)\n",
    "        B = K.sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True)\n",
    "\n",
    "        # the lambda_t parameter, in this case min{1, t/10} with t the number of epochs\n",
    "        ll = min(1.0, float(ep/float(num_epochs_annealing)))\n",
    "        \n",
    "        alp = yPred*(1-yTrue) + 1 \n",
    "        C =  ll * KL(alp)\n",
    "\n",
    "        return A + B + C\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model_edl.compile(loss=mse_loss, optimizer=optimizer, metrics=[edl_accuracy])\n",
    "    \n",
    "    # Define early stop policy\n",
    "    #early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "    model_edl.fit(_X_train, _y_train_dummy,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      verbose=1,\n",
    "      #callbacks=[GetEpochs(), early_stop_cb],\n",
    "      shuffle=True)\n",
    "\n",
    "    model_directory = os.path.join(base_directory, f'{num_components}_components/models/{num_components}components_{num_levels}lvls_Keras_Model.keras')\n",
    "    os.makedirs(os.path.dirname(model_directory), exist_ok=True)\n",
    "    model_edl.save(model_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f42632",
   "metadata": {},
   "source": [
    "## Iterative Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(range(1, 11)) + list(range(15, 41, 5))\n",
    "components = list(range(50, 101, 10))\n",
    "levels = [2**i for i in range(1, 8)]\n",
    "antenna = 0\n",
    "\n",
    "results = []\n",
    "\n",
    "for num_components in components:\n",
    "    for num_levels in levels:\n",
    "        print(f\"------------------------- Running experiment for {num_components} components with {num_levels} levels -------------------------\")\n",
    "        dump_directory =  os.path.join(base_directory, f'{num_components}_components/dumps/{num_components}components_{num_levels}lvls_single_antenna_{antenna}.pkl')\n",
    "        \n",
    "        # Load data\n",
    "        X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns = load_experiment_reconstructed(dump_directory)\n",
    "        \n",
    "        # Run model\n",
    "        name = \"No-Fused-1\"\n",
    "        run_edl_experiment(name, num_components, num_levels, X_train, y_train_dummy)\n",
    "\n",
    "        # Test model\n",
    "        accuracy = results_test(num_components, num_levels, dump_directory)\n",
    "        results.append(\n",
    "            {\n",
    "                \"num_components\": num_components,\n",
    "                \"num_levels\": num_levels,\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "        \n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results_csv/results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d88903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    #if num_components not in components:\n",
    "    #    continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE', linewidth=3)\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Bits per symbol')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join('accuracy_bit_comparison[BxS][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e102239",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "#components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    if num_components not in components:\n",
    "        continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_win_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_win_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE')\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Average bits per window')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join('accuracy_bit_comparison[BxW][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f43db71",
   "metadata": {},
   "source": [
    "VAE output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279248bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [2**i for i in range(1, 8)]\n",
    "antenna = 0\n",
    "\n",
    "results = []\n",
    "\n",
    "for num_levels in levels:\n",
    "    print(f\"------------------------- Running experiment for 0 components with {num_levels} levels -------------------------\")\n",
    "    dump_directory =  os.path.join(base_directory, f'0_components/dumps/{num_levels}lvls_single_antenna_{antenna}.pkl')\n",
    "    \n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns = load_experiment_reconstructed(dump_directory)\n",
    "    \n",
    "    # Run model\n",
    "    name = \"No-Fused-1\"\n",
    "    run_edl_experiment(name, num_components, num_levels, X_train, y_train_dummy)\n",
    "\n",
    "    # Test model\n",
    "    accuracy = results_test(num_components, num_levels, dump_directory)\n",
    "    results.append(\n",
    "        {\n",
    "            \"num_components\": num_components,\n",
    "            \"num_levels\": num_levels,\n",
    "            \"accuracy\": accuracy\n",
    "        })\n",
    "        \n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('VAE_results.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f46ab3ed",
   "metadata": {},
   "source": [
    "## Single Run\n",
    "\n",
    "### Define and run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db19c8",
   "metadata": {
    "id": "b5db19c8"
   },
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\"\"\"for i in range(1, 5):\n",
    "    experiments.append(\"No-Fused-%d\" % i)\n",
    "experiments.append(\"Early-Fusing\")\n",
    "experiments.append(\"Early-Fusing3\")\n",
    "experiments.append(\"Delayed-Fusing\")\n",
    "\"\"\"\n",
    "\n",
    "experiments.append(\"No-Fused-1\")\n",
    "print(f'Experiments to run: {experiments}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "202cc612",
   "metadata": {},
   "source": [
    "Either train the models from scratch or use the ones already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af41d15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 84695,
     "status": "error",
     "timestamp": 1677570151080,
     "user": {
      "displayName": "Federico CERUTTI",
      "userId": "05236606107795315109"
     },
     "user_tz": -60
    },
    "id": "4af41d15",
    "outputId": "c97cec92-e510-445d-906d-082ab282ceaf"
   },
   "outputs": [],
   "source": [
    "train_from_scratch = True\n",
    "reconstructed = True\n",
    "\n",
    "if train_from_scratch:\n",
    "    for exp in experiments:\n",
    "        print(exp)\n",
    "        print(\"Loading data\")\n",
    "        X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns = load_experiment(exp, reconstructed=reconstructed)\n",
    "        \n",
    "        print(\"Fit model and save\")\n",
    "        run_edl_experiment(exp, X_train, y_train_dummy)\n",
    "else:\n",
    "    !wget https://zenodo.org/record/7983057/files/KERAS_models.zip\n",
    "    !unzip -o KERAS_models.zip\n",
    "    !rm KERAS_models.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEg35_Uu855c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "executionInfo": {
     "elapsed": 7077,
     "status": "ok",
     "timestamp": 1677570524608,
     "user": {
      "displayName": "Federico CERUTTI",
      "userId": "05236606107795315109"
     },
     "user_tz": -60
    },
    "id": "lEg35_Uu855c",
    "outputId": "b9a9a0bc-d98a-4a1e-d3ed-e48e5f832d92"
   },
   "outputs": [],
   "source": [
    "experiments_res = []\n",
    "\"\"\"for i in range(1, 5):\n",
    "   experiments_res.append(\"No-Fused-%d\" % i)\n",
    "experiments_res.append(\"Early-Fusing\")\n",
    "experiments_res.append(\"Early-Fusing3\")\n",
    "experiments_res.append(\"Delayed-Fusing\")\"\"\"\n",
    "\n",
    "experiments_res.append(\"No-Fused-1\")\n",
    "for _e in experiments_res:\n",
    "    accuracy = results_test(_e, reconstructed)\n",
    "    print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
