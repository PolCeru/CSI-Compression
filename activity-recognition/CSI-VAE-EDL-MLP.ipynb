{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE training and processing\n",
    "\n",
    "Sample code to train a new VAE and run the CSI processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_keras\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]= '1' # Use legacy keras for compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTENNAS = 1\n",
    "antenna = 0  # if ANTENNAS==1, this value selects the antenna ID (from 0 to 3)\n",
    "\n",
    "BATCH_SIZE = 25\n",
    "latent_dim = 2\n",
    "num_activities = 5\n",
    "folder_name = f'models/single_antenna_{antenna}'\n",
    "\n",
    "base_directory = './models'\n",
    "saveGraph = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state) # predictable random numbers, for demonstration only\n",
    "tf.random.set_seed(random_state) # reproducibility\n",
    "\n",
    "# computes golden ratio for figures\n",
    "def goldenrect(h):\n",
    "    return (h * 1.618, h)\n",
    "\n",
    "def summary_clf(y_test, predicted, y_score, _labels = None):\n",
    "    print(classification_report(y_test, predicted, labels= _labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSI data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsiData(tf_keras.utils.Sequence):\n",
    "    def __init__(self, csi, labels, indices, batch_size=25, window_size=450, antennas=1):\n",
    "        self.csi = csi\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        self.batch_size = batch_size\n",
    "        self.window_size = window_size\n",
    "        self.antennas = antennas\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.indices.shape[-1] / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, batch_idx):\n",
    "        first_idx = batch_idx * self.batch_size\n",
    "        last_idx = (batch_idx + 1) * self.batch_size\n",
    "        \n",
    "        data_batch = [self.csi[x:x + self.window_size, ...] for x in range(first_idx, last_idx)]\n",
    "        labels_batch = np.transpose([self.labels[first_idx:last_idx]])\n",
    "\n",
    "        data_batch = tf.convert_to_tensor(data_batch)\n",
    "        labels_batch = tf.convert_to_tensor(labels_batch)\n",
    "\n",
    "        if self.antennas == 1:\n",
    "            data_batch = tf.expand_dims(data_batch, 3)\n",
    "            labels_batch = tf.expand_dims(labels_batch, 2)\n",
    "\n",
    "        return data_batch, labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_test_CSI_data(file_list, num_samples=12000, window_size=450, batch_size=25, antennas=1, random_state=42):\n",
    "    if antennas == 1:\n",
    "        train_csi = tf.zeros([0, 2048], dtype=tf.float32)\n",
    "        test_csi = tf.zeros([0, 2048], dtype=tf.float32)\n",
    "    else:\n",
    "        train_csi = tf.zeros([0, 2048, antennas], dtype=tf.float32)\n",
    "        test_csi = tf.zeros([0, 2048, antennas], dtype=tf.float32)\n",
    "\n",
    "    train_labels = tf.zeros([0], dtype=tf.int32)\n",
    "    test_labels = tf.zeros([0], dtype=tf.int32)\n",
    "    train_indices = tf.zeros([0], dtype=tf.int32)\n",
    "    test_indices = tf.zeros([0], dtype=tf.int32)\n",
    "\n",
    "    train_num_samples = math.floor(num_samples * 0.8)\n",
    "    test_num_samples = num_samples - train_num_samples\n",
    "\n",
    "    for file in file_list:\n",
    "        # Load CSI data from MATLAB file\n",
    "        mat = sio.loadmat(file)      # WARNING This code does not handle exceptions for simplicity...\n",
    "        data = np.array(mat['csi'])  # ...exceptions would require keeping track of indices\n",
    "        if antennas == 1:\n",
    "            data = data[range(num_samples), ..., int(antenna)]\n",
    "        data = np.round(np.abs(data))\n",
    "        train_index_offset = train_csi.shape[0]\n",
    "        test_index_offset = test_csi.shape[0]\n",
    "        activity_label = file_list.index(file)  # Labels depend on file index \n",
    "\n",
    "        train_data = data[:train_num_samples]\n",
    "        test_data = data[train_num_samples:]\n",
    "        \n",
    "        # Cast CSI data into temporary TF tensors for building the dataset\n",
    "        tmp_train_csi = tf.convert_to_tensor(train_data, dtype=tf.float32)\n",
    "        tmp_train_labels = tf.convert_to_tensor(activity_label * np.ones(train_num_samples - window_size), dtype=tf.int32)\n",
    "        tmp_train_indices = tf.convert_to_tensor(tf.range(train_index_offset, train_index_offset + train_num_samples - window_size), dtype=tf.int32)\n",
    "\n",
    "        # Concatenate to the previous tensors\n",
    "        train_csi = tf.concat([train_csi, tmp_train_csi], axis=0)\n",
    "        train_labels = tf.concat([train_labels, tmp_train_labels], axis=0)\n",
    "        train_indices = tf.concat([train_indices, tmp_train_indices], axis=0)\n",
    "\n",
    "        tmp_test_csi = tf.convert_to_tensor(test_data, dtype=tf.float32)\n",
    "        tmp_test_labels = tf.convert_to_tensor(activity_label * np.ones(test_num_samples - window_size), dtype=tf.int32)\n",
    "        tmp_test_indices = tf.convert_to_tensor(tf.range(test_index_offset, test_index_offset + test_num_samples - window_size), dtype=tf.int32)\n",
    "\n",
    "        test_csi = tf.concat([test_csi, tmp_test_csi], axis=0)\n",
    "        test_labels = tf.concat([test_labels, tmp_test_labels], axis=0)\n",
    "        test_indices = tf.concat([test_indices, tmp_test_indices], axis=0)\n",
    "        \n",
    "    # Normalize the CSI dataset\n",
    "    if antennas == 1:\n",
    "        train_csi = tf.math.divide(train_csi, tf.math.reduce_max(train_csi, axis=(0, 1)))\n",
    "        test_csi = tf.math.divide(test_csi, tf.math.reduce_max(test_csi, axis=(0, 1)))\n",
    "    else:\n",
    "        train_csi = tf.math.divide(train_csi, tf.math.reduce_max(train_csi, axis=(0, 1, 2)))\n",
    "        test_csi = tf.math.divide(test_csi, tf.math.reduce_max(test_csi, axis=(0, 1, 2)))\n",
    "\n",
    "    train_data = CsiData(train_csi, train_labels, train_indices, batch_size=batch_size, window_size=window_size, antennas=antennas)\n",
    "    test_data = CsiData(test_csi, test_labels, test_indices, batch_size=batch_size, window_size=window_size, antennas=antennas)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf_keras.layers.Layer):\n",
    "    \"\"\"Takes a couple (z_mean, z_log_var) to draw a sample z from the latent space.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf_keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "def create_csi_encoder(input_shape, latent_dim):\n",
    "    encoder_inputs = tf_keras.Input(shape=input_shape)\n",
    "    x = tf_keras.layers.Conv2D(32, (5, 8), activation='relu', strides=(5, 8), padding='valid')(encoder_inputs)\n",
    "    x = tf_keras.layers.Conv2D(32, (5, 8), activation='relu', strides=(5, 8), padding='valid')(x)\n",
    "    x = tf_keras.layers.Conv2D(32, (2, 4), activation='relu', strides=(2, 4), padding='valid')(x)\n",
    "    x = tf_keras.layers.Flatten()(x)\n",
    "    x = tf_keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "    z_mean = tf_keras.layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = tf_keras.layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    return tf_keras.Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "\n",
    "def create_csi_decoder(input_shape, latent_dim, out_filter):\n",
    "    decoder_inputs = tf_keras.Input(shape=(latent_dim,))\n",
    "    x = tf_keras.layers.Dense(math.prod(input_shape), activation='relu')(decoder_inputs)\n",
    "    x = tf_keras.layers.Reshape(input_shape)(x)\n",
    "    x = tf_keras.layers.Conv2DTranspose(32, (2, 4), activation='relu', strides=(2, 4), padding='same')(x)\n",
    "    x = tf_keras.layers.Conv2DTranspose(32, (5, 8), activation='relu', strides=(5, 8), padding='same')(x)\n",
    "    x = tf_keras.layers.Conv2DTranspose(32, (5, 8), activation='relu', strides=(5, 8), padding='same')(x)\n",
    "    decoder_outputs = tf_keras.layers.Conv2DTranspose(out_filter, out_filter, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    return tf_keras.Model(decoder_inputs, decoder_outputs, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf_keras.Model):\n",
    "    def __init__(self, enc_input_shape=(450, 2048, 1), dec_input_shape=(9, 8, 32), latent_dim=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = create_csi_encoder(enc_input_shape, latent_dim)\n",
    "        self.decoder = create_csi_decoder(dec_input_shape, latent_dim, enc_input_shape[-1])\n",
    "        self.total_loss_tracker = tf_keras.metrics.Mean(name='total_loss')\n",
    "        self.reconstruction_loss_tracker = tf_keras.metrics.Mean(name='reconstruction_loss')\n",
    "        self.kl_loss_tracker = tf_keras.metrics.Mean(name='kl_loss')\n",
    "\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf_keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'reconstruction_loss': self.reconstruction_loss_tracker.result(),\n",
    "            'kl_loss': self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vae_encoder(vae, source):\n",
    "    #Use the VAE to process CSI data\n",
    "    z_data = np.zeros([0, 4])\n",
    "    z_labels = np.zeros([0])\n",
    "\n",
    "    for (data, labels) in source:\n",
    "        labels = tf.squeeze(labels)\n",
    "        z_mean, z_log_var, _ = vae.encoder.predict(data, verbose=0)\n",
    "        z_tmp = np.concatenate([z_mean, z_log_var], axis=1)\n",
    "        z_data = np.concatenate([z_data, z_tmp], axis=0)\n",
    "        z_labels = np.concatenate([z_labels, labels.numpy().ravel()], axis=0)\n",
    "        \n",
    "    return z_data, z_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f'./{folder_name}/' + 'cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "checkpoint_cb = tf_keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only=True)\n",
    "early_stopping_cb = tf_keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "csv_logger_cb = tf_keras.callbacks.CSVLogger(f'./{folder_name}/model_history_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_components(data, target, directory=base_directory, saveGraph=False, plotGraph=True):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    #Apply PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(data)\n",
    "\n",
    "    var_cumulative = np.cumsum(pca.explained_variance_ratio_)*100\n",
    "\n",
    "    #finds PCs that explain 95% of the variance\n",
    "    num_components = np.argmax(var_cumulative > target) + 1\n",
    "    print(f\"Number of components explaining {target}% variance: \"+ str(num_components))\n",
    "\n",
    "    if plotGraph:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title('Cumulative Explained Variance explained by the components')\n",
    "        plt.ylabel('Cumulative Explained variance')\n",
    "        plt.xlabel('Principal components')\n",
    "        plt.axvline(x=num_components, color=\"r\", linestyle=\"--\")\n",
    "        plt.axhline(y=target, color=\"r\", linestyle=\"--\")\n",
    "        plt.plot(range(1, pca.n_components_ + 1), var_cumulative, marker='o', linestyle='--')\n",
    "        plt.grid()\n",
    "        if (saveGraph):\n",
    "            graph_path = os.path.join(directory, 'var_cumulative_x_component.png')\n",
    "            plt.savefig(graph_path)\n",
    "            print(\"Graph saved in: \", graph_path)\n",
    "        plt.show()\n",
    "\n",
    "    return num_components\n",
    "\n",
    "def analyze_PCA(data, n_components, directory=base_directory, saveGraph=False, plotGraph=True):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_data = pca.fit_transform(data)\n",
    "\n",
    "    reduced_df = pd.DataFrame(data=reduced_data, columns=[f'PC{i}' for i in range(n_components)])\n",
    "\n",
    "    #Explained variance ratio\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    print(\"Explained variance ratio:\", explained_variance_ratio)\n",
    "\n",
    "    #Cumulative explained variance\n",
    "    cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "    print(\"Final Cumulative Explained Variance:\", cumulative_explained_variance[-1])\n",
    "\n",
    "    if (plotGraph):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, n_components + 1), cumulative_explained_variance, marker='o', linestyle='--')\n",
    "        plt.title('Cumulative Explained Variance by PCA Components')\n",
    "        plt.xlabel('Number of Principal Components')\n",
    "        plt.ylabel('Cumulative Explained Variance')\n",
    "        plt.grid()\n",
    "        if (saveGraph):\n",
    "            graph_path = os.path.join(directory, 'cumulative_explained_variance.png')\n",
    "            plt.savefig(graph_path)\n",
    "            print(\"Graph saved in: \", graph_path)\n",
    "        plt.show()\n",
    "    \n",
    "    return reduced_df, pca\n",
    "\n",
    "def reconstruct_data(df, pca, columns):\n",
    "    df_reconstructed = pca.inverse_transform(df.values)\n",
    "    df_reconstructed = pd.DataFrame(df_reconstructed, columns=columns)    \n",
    "    return df_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lloyd_max_quantization(data, num_levels=16, max_iter=100, delta=1e-6):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    clusters = np.linspace(min_val, max_val, num_levels) #Uniformly spaced \n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        thresholds = (clusters[:-1] + clusters[1:]) / 2 #Defines intervals of clusters\n",
    "        indices = np.digitize(data, thresholds) #Assign each data point to a cluster\n",
    "        \n",
    "        new_clusters = np.array([data[indices == i].mean() for i in range(num_levels)]) #Update clusters to better represent the data\n",
    "        \n",
    "        empty_clusters = np.isnan(new_clusters) #Restore previous cluster if empty\n",
    "        new_clusters[empty_clusters] = clusters[empty_clusters] \n",
    "\n",
    "        #stop if changes between iterations are small\n",
    "        if np.max(np.abs(new_clusters - clusters)) < delta:\n",
    "            break\n",
    "\n",
    "        clusters = new_clusters\n",
    "\n",
    "    #Quantize the data based on the final clusters\n",
    "    quantized_data = clusters[indices]\n",
    "\n",
    "    return quantized_data, clusters, thresholds\n",
    "\n",
    "def dequantize_lloyd_max(quantized_data, clusters, thresholds):\n",
    "    indices = np.digitize(quantized_data, thresholds, right=True)\n",
    "    return clusters[indices]\n",
    "\n",
    "def apply_quantization(reduced_df, lvls):\n",
    "    df_quantized = reduced_df.apply(lambda col: lloyd_max_quantization(col.values, num_levels=lvls)[0])\n",
    "    return df_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bits_needed(source, verbose=True):\n",
    "    data = source.copy()\n",
    "    window_size = 450\n",
    "    bits_needed_window = {}\n",
    "    total_bits = 0\n",
    "    total_symbols = 0\n",
    "    \n",
    "    for index in range(0, len(data), window_size):\n",
    "        bits_needed = {}\n",
    "        data_window = data.iloc[index : index + window_size] \n",
    "        window_total_bits = 0\n",
    "        window_total_symbols = 0\n",
    "        \n",
    "        for col in data_window.columns:\n",
    "            num_symbols = len(data_window[col].unique())\n",
    "            total_num_symbols = len(data_window[col])\n",
    "            \n",
    "            if num_symbols > 1:\n",
    "                bits_needed[col] = np.ceil(np.log2(num_symbols)).astype(int)  # Number of bits to represent each symbol\n",
    "            else:\n",
    "                bits_needed[col] = 1  # If only one unique symbol\n",
    "            if verbose: print(f\"Column: {col}, Bits needed: {bits_needed[col]} bits\")\n",
    "            \n",
    "            # bits this column in the window\n",
    "            column_bits = bits_needed[col] * total_num_symbols\n",
    "            window_total_bits += column_bits\n",
    "            window_total_symbols += total_num_symbols\n",
    "\n",
    "        bits_needed_window[index] = window_total_bits\n",
    "        if verbose: print(f\"Window: {index}, Average bits needed: {window_total_bits:.2f} bits\")\n",
    "    \n",
    "        total_bits += window_total_bits\n",
    "        total_symbols += window_total_symbols\n",
    "\n",
    "    average_bits_per_symbol = total_bits / total_symbols if total_symbols > 0 else 0\n",
    "    average_bits_per_window = np.mean(list(bits_needed_window.values())).round(2)\n",
    "\n",
    "    #print(f\"\\nGlobal metrics:\")\n",
    "    print(f\"Average bits per symbol: {average_bits_per_symbol:.2f} bits\")\n",
    "    print(f\"Average bits per window: {average_bits_per_window:.2f} bits\")\n",
    "    print(f\"Bits for the whole dataset: {total_bits:.2f} bits\")\n",
    "\n",
    "    return average_bits_per_symbol.round(2), average_bits_per_window, total_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_needed(source, num_lvls=-1):\n",
    "    data = source.copy()\n",
    "    window_size = 450\n",
    "    num_features = len(data.columns)\n",
    "    bits_needed_unique = {}\n",
    "    avg_bits_needed = {}\n",
    "    bits_needed_window = {}\n",
    "    total_bits_needed_dataset = 0\n",
    "\n",
    "    for index in range(0, len(data), window_size):\n",
    "        data_window = data.iloc[index : index + window_size] \n",
    "        for col in data_window.columns:\n",
    "            num_symbols = len(data_window[col].unique())\n",
    "            if num_lvls > 0:\n",
    "                bits_needed_unique[col] = np.ceil(np.log2(num_lvls)).astype(int)\n",
    "                #print(f\"Column: {col}, Bits needed: {bits_needed_unique[col]} bits (num levels: {num_lvls})\")\n",
    "            else:\n",
    "                bits_needed_unique[col] = np.ceil(np.log2(num_symbols)).astype(int)\n",
    "                \n",
    "        avg_bits_needed[index] = np.mean(list(bits_needed_unique.values())).round(2)\n",
    "        bits_needed_window[index] = sum(bits_needed_unique.values())\n",
    "        total_bits_needed_dataset += sum(bits_needed_unique.values())\n",
    "\n",
    "    bits_needed = np.mean(list(avg_bits_needed.values())).round(2)\n",
    "    bits_needed_window = np.mean(list(bits_needed_window.values())).round(2)\n",
    "\n",
    "    return bits_needed, bits_needed_window, total_bits_needed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "The VAE has been trained without any information about the target classes; it just tries to minimize reconstruction loss + KL loss.\n",
    "\n",
    "The Encoder in the VAE maps sequences of CSI into **2 Gaussian variables** with parameters (z_mean, z_log_var).\n",
    "\n",
    "More in detail, from the dataset we load `data` and `labels`.\n",
    "- `data`: every element is a 4-tuple with the values (z1_mean, z2_mean, z1_log_var, z2_log_var)\n",
    "- `labels`: 5 different classes, labelled with integers from 0 to 4 (0 = walk, 1 = run, 2 = jump, 3 = sit, 4 = empty)\n",
    "\n",
    "Available datasets:\n",
    "- `single_antenna`: data of just antenna 1, normalized wrt to the maximum value over the entire dataset (four antennas are available, numbered from 0 to 3)\n",
    "- `four_antennas`: data of the four antennas fused together, normalized wrt to the maximum value over the entire dataset\n",
    "- `four_antennas_latent_space_3`: same as `four_antennas`, but the CSI is mapped onto 3 Gaussian variables; hence, every element in `data` is a 6-tuple with the values (z1_mean, z2_mean, z3_mean, z1_log_var, z2_log_var, z3_log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_classes = [\"Walk\", \"Run\", \"Jump\", \"Sit\", \"Empty\"]\n",
    "base_directory = './results'\n",
    "os.makedirs(base_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(directory, scaler=None):\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    # features columns\n",
    "    fcolumns = ['mu1','mu2','sigma1','sigma2']\n",
    "    \n",
    "    # check which experiments we wants to load\n",
    "    with open(directory, 'rb') as f:\n",
    "        data, labels = pickle.load(f)\n",
    "\n",
    "    # labels are categoricals\n",
    "    labels = np.asarray(labels, dtype=np.int32)\n",
    "    \n",
    "    # let's load into a dataframe\n",
    "    df = pd.DataFrame(data, columns=fcolumns)\n",
    "    df['signal'] = labels\n",
    "    \n",
    "    if scaler is None:\n",
    "        # Fit scaler on training data\n",
    "        scaler = StandardScaler().fit(df[fcolumns])\n",
    "    df[fcolumns] = scaler.transform(df[fcolumns])\n",
    "    \n",
    "    X = df[fcolumns]\n",
    "    y = df['signal']\n",
    "\n",
    "    # one-hot-encoding\n",
    "    y_dummy = keras.utils.to_categorical(y)\n",
    "    \n",
    "    return X, y, y_dummy, scaler, fcolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_reconstructed(directory, _test_size = 0.2, _random_state = 42):\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    # features columns\n",
    "    fcolumns = ['mu1','mu2','sigma1','sigma2']\n",
    "    \n",
    "    # check which experiments we wants to load\n",
    "    with open(directory, 'rb') as f:\n",
    "        data, labels = pickle.load(f)\n",
    "\n",
    "    # labels are categoricals\n",
    "    labels = np.asarray(labels, dtype=np.int32)\n",
    "    \n",
    "    # let's load into a dataframe\n",
    "    df = pd.DataFrame(data, columns=fcolumns)\n",
    "    df['signal'] = labels\n",
    "    \n",
    "    # standard scaler\n",
    "    scaler = StandardScaler().fit(df[fcolumns])\n",
    "    df[fcolumns] = scaler.transform(df[fcolumns])\n",
    "    \n",
    "    # test/train split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[fcolumns], df['signal'], \n",
    "                                                        test_size=_test_size, \n",
    "                                                        random_state=_random_state, \n",
    "                                                        stratify=df['signal'])\n",
    "    \n",
    "    # one-hot-encoding\n",
    "    y_train_dummy = keras.utils.to_categorical(y_train)\n",
    "    y_test_dummy = keras.utils.to_categorical(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_test2(dump_directory, num_components=0, num_levels=0):\n",
    "    X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns = load_experiment_reconstructed(dump_directory)\n",
    "    model_directory = os.path.join(base_directory, f'{num_components}_components/models/{num_components}components_{num_levels}lvls_Keras_Model.keras')\n",
    "    mlp_edl = keras.models.load_model(model_directory, compile=False)\n",
    "    mlp_edl_scores = np.array([res_to_mean(r, dim=5) for r in mlp_edl.predict(X_test)])\n",
    "    y_predictions_edl = np.array(tf.argmax(mlp_edl.predict(X_test), axis=1))\n",
    "    print(summary_clf(y_test, y_predictions_edl, mlp_edl_scores))\n",
    "    accuracy = accuracy_score(y_test, y_predictions_edl)\n",
    "    cm = confusion_matrix(y_test, y_predictions_edl)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=semantic_classes)\n",
    "    cmdisp = disp.plot(cmap=\"cividis\")\n",
    "    CM_directory = os.path.join(base_directory, f'{num_components}_components/CMs/{num_components}components_{num_levels}lvls_ConfusionMatrix.png')\n",
    "    os.makedirs(os.path.dirname(CM_directory), exist_ok=True)\n",
    "    cmdisp.figure_.savefig(CM_directory, bbox_inches='tight')\n",
    "    return round(accuracy, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_annealing = 1\n",
    "num_classes = 5\n",
    "\n",
    "ep = 1.0\n",
    "class GetEpochs(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global ep\n",
    "        ep += 1\n",
    "\n",
    "def res_to_mean(ev, dim = 5):\n",
    "    return np.max(dirichlet.mean(ev.reshape(dim,)+1))\n",
    "\n",
    "def res_to_dirichlet(ev):\n",
    "    alpha = ev.reshape(2,)+1\n",
    "    S = np.sum(alpha)\n",
    "    K = 2.0\n",
    "    return dirichlet.mean(alpha), K/S\n",
    "\n",
    "def edl_accuracy(yTrue, yPred):\n",
    "    pred = K.argmax(yPred, axis=1)\n",
    "    truth = K.argmax(yTrue, axis=1)\n",
    "    match = K.reshape(K.cast(K.equal(pred, truth), \"float32\"),(-1,1))\n",
    "    return K.mean(match)\n",
    "\n",
    "def load_edl_experiment(name):\n",
    "    keras.models.load_model(name)\n",
    "\n",
    "def plot_res_beta(ev):\n",
    "    alpha = ev.reshape(2,)+1\n",
    "    plt.figure(figsize=(16,9))\n",
    "    x = np.linspace(0,1,1000)\n",
    "    plt.plot(x, beta.pdf(x, alpha[1], alpha[0]))\n",
    "    x1, x2 = beta.interval(0.95, alpha[1], alpha[0])\n",
    "    areaplot = np.multiply(beta.pdf(x, alpha[1],alpha[0]), rect(x,x1, x2))\n",
    "    plt.fill_between(x, 0, areaplot, alpha=0.5)\n",
    "\n",
    "def results_test (train_dir, test_dir, num_components=0, num_levels=0):\n",
    "    X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dir)\n",
    "    X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dir, scaler)\n",
    "    model_directory = os.path.join(base_directory, f'{num_components}_components/models/{num_components}components_{num_levels}lvls_Keras_Model.keras')\n",
    "    \n",
    "    mlp_edl = keras.models.load_model(model_directory, compile=False)\n",
    "    mlp_edl_scores = np.array([res_to_mean(r, dim=5) for r in mlp_edl.predict(X_test)])\n",
    "    y_predictions_edl = np.array(tf.argmax(mlp_edl.predict(X_test), axis=1))\n",
    "\n",
    "    print(summary_clf(y_test, y_predictions_edl, mlp_edl_scores))\n",
    "    accuracy = accuracy_score(y_test, y_predictions_edl)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_predictions_edl)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=semantic_classes)\n",
    "    cmdisp = disp.plot(cmap=\"cividis\")\n",
    "    CM_directory = os.path.join(base_directory, f'{num_components}_components/CMs/{num_components}components_{num_levels}lvls_ConfusionMatrix.png')\n",
    "    os.makedirs(os.path.dirname(CM_directory), exist_ok=True)\n",
    "    cmdisp.figure_.savefig(CM_directory, bbox_inches='tight')\n",
    "\n",
    "    return round(accuracy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_edl_experiment(name, _X_train, _y_train_dummy, num_components=0, num_levels=0):\n",
    "\n",
    "    model_edl = None\n",
    "    num_classes = 5\n",
    "    \n",
    "    if name == \"Delayed-Fusing\":\n",
    "        num_epochs_annealing = 3\n",
    "        batch_size = 128\n",
    "        lr = 0.01\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5, activation='softplus'))\n",
    "\n",
    "    elif name == \"Early-Fusing\":\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 128\n",
    "        lr = 0.001\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(4,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5,activation='softplus'))\n",
    "\n",
    "    elif name == \"Early-Fusing3\":\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 128\n",
    "        lr = 0.01\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(6,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5,activation='softplus'))\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 64\n",
    "        lr = 0.0001\n",
    "        epochs = 100\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "        model_edl.add(tf.keras.layers.Dropout(0.5))\n",
    "        model_edl.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "        model_edl.add(tf.keras.layers.Dropout(0.5))\n",
    "        model_edl.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "        model_edl.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "        \"\"\"\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 128\n",
    "        lr = 0.01\n",
    "        epochs = 100\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(4, activation='relu', input_shape=(4,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5,activation='softplus'))\n",
    "       \n",
    "\n",
    "\n",
    "    def KL(alpha):\n",
    "        beta=K.constant(np.ones((1,num_classes)),dtype=\"float32\")\n",
    "        S_alpha = K.sum(alpha,axis=1,keepdims=True)\n",
    "        S_beta = K.sum(beta,axis=1,keepdims=True)\n",
    "        lnB = tf.math.lgamma(S_alpha) - K.sum(tf.math.lgamma(alpha),axis=1,keepdims=True)\n",
    "        lnB_uni = K.sum(tf.math.lgamma(beta),axis=1,keepdims=True) - tf.math.lgamma(S_beta)\n",
    "\n",
    "        dg0 = tf.math.digamma(S_alpha)\n",
    "        dg1 = tf.math.digamma(alpha)\n",
    "\n",
    "        return K.sum((alpha - beta)*(dg1-dg0),axis=1,keepdims=True) + lnB + lnB_uni\n",
    "\n",
    "    # Loss function considering the expected squared error and the KL divergence\n",
    "    def mse_loss(yTrue,yPred):\n",
    "        alpha = yPred + 1\n",
    "        S = K.sum(alpha, axis=1, keepdims=True)\n",
    "        m = alpha / S\n",
    "\n",
    "        # A + B minimises the sum of squared loss, see discussion in EDL paper for the derivation\n",
    "        A = K.sum((yTrue-m)**2, axis=1, keepdims=True)\n",
    "        B = K.sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True)\n",
    "\n",
    "        # the lambda_t parameter, in this case min{1, t/10} with t the number of epochs\n",
    "        ll = min(1.0, float(ep/float(num_epochs_annealing)))\n",
    "        \n",
    "        alp = yPred*(1-yTrue) + 1 \n",
    "        C =  ll * KL(alp)\n",
    "\n",
    "        return A + B + C\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model_edl.compile(loss=mse_loss, optimizer=optimizer, metrics=[edl_accuracy])\n",
    "\n",
    "    model_edl.fit(_X_train, _y_train_dummy,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      verbose=1,\n",
    "      shuffle=False)\n",
    "\n",
    "    model_directory = os.path.join(base_directory, f'{num_components}_components/models/{num_components}components_{num_levels}lvls_Keras_Model.keras')\n",
    "    os.makedirs(os.path.dirname(model_directory), exist_ok=True)\n",
    "    model_edl.save(model_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(range(1, 11)) + list(range(15, 41, 5)) + list(range(50, 101, 10))\n",
    "levels = [2**i for i in range(1, 8)]\n",
    "\n",
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "csi_generator = CsiDataGenerator(file_list, batch_size=BATCH_SIZE, antenna_select=antenna)\n",
    "\n",
    "csi_data = csi_generator.csi.numpy()\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "\n",
    "df_csi_data_original = pd.DataFrame(csi_data, columns=csi_subcarriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_components in components:\n",
    "    print(f\"-------------- {num_components} components --------------\")\n",
    "    directory = f'./results/{num_components}_components/dumps'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    df_csi_data = df_csi_data_original.copy()\n",
    "    #Apply PCA\n",
    "    \n",
    "    df_reduced, pca = analyze_PCA(df_csi_data, num_components, directory=directory, saveGraph=True, plotGraph=True)\n",
    "\n",
    "    for num_levels in levels:\n",
    "        print(f\"-------------- {num_components} components w/ {num_levels} lvls --------------\")\n",
    "        #Quantize the data\n",
    "        df_train_quantized = apply_quantization(df_reduced, num_levels)\n",
    "\n",
    "        #Reconstruct the data\n",
    "        df_train_reconstructed = reconstruct_data(df_train_quantized, pca, csi_subcarriers)\n",
    "        df_train_reconstructed = df_train_reconstructed.to_numpy()\n",
    "        reconstructed_train_data = tf.convert_to_tensor(df_train_reconstructed)\n",
    "        csi_generator.csi = reconstructed_train_data\n",
    "\n",
    "        #Use the VAE to process CSI data\n",
    "        z_data = np.zeros([0, 4])\n",
    "        z_labels = np.zeros([0])\n",
    "\n",
    "        vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "        vae.compile(optimizer=keras.optimizers.Adam())\n",
    "        vae.load_weights(f'./{folder_name}/weights_vae').expect_partial()\n",
    "\n",
    "        for (data, labels) in csi_generator:\n",
    "            labels = tf.squeeze(labels)\n",
    "            z_mean, z_log_var, _ = vae.encoder.predict(data, verbose=0)\n",
    "            z_tmp = np.concatenate([z_mean, z_log_var], axis=1)\n",
    "            z_data = np.concatenate([z_data, z_tmp], axis=0)\n",
    "            z_labels = np.concatenate([z_labels, labels], axis=0)\n",
    "\n",
    "        # Store the latent space representation of CSI data to file.\n",
    "        sub_dir=os.path.join(directory, f'{num_components}components_{num_levels}lvls_single_antenna_{antenna}.pkl')\n",
    "        with open(sub_dir, 'wb') as f:\n",
    "            pickle.dump([z_data, z_labels], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for num_components in components:\n",
    "    for num_levels in levels:\n",
    "        print(f\"------------------------- Running experiment for {num_components} components with {num_levels} levels -------------------------\")\n",
    "        dump_directory =  os.path.join(base_directory, f'{num_components}_components/dumps/{num_components}components_{num_levels}lvls_single_antenna_{antenna}.pkl')\n",
    "        \n",
    "        # Load data\n",
    "        X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns = load_experiment_reconstructed(dump_directory)\n",
    "        \n",
    "        # Run model\n",
    "        name = \"No-Fused-1\"\n",
    "        run_edl_experiment(name, num_components, num_levels, X_train, y_train_dummy)\n",
    "\n",
    "        # Test model\n",
    "        accuracy = results_test(num_components, num_levels, dump_directory)\n",
    "        results.append(\n",
    "            {\n",
    "                \"num_components\": num_components,\n",
    "                \"num_levels\": num_levels,\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "        \n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results_csv/results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    #if num_components not in components:\n",
    "    #    continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE', linewidth=3)\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Bits per symbol')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join('accuracy_bit_comparison[BxS][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "#components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    if num_components not in components:\n",
    "        continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_win_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_win_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE')\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Average bits per window')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join('accuracy_bit_comparison[BxW][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(range(1, 11)) + list(range(15, 41, 5))\n",
    "components = (range(50, 101, 10))\n",
    "levels = [2**i for i in range(1, 8)]\n",
    "bit_results = []\n",
    "\n",
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "csi_generator = CsiDataGenerator(file_list, batch_size=BATCH_SIZE, antenna_select=antenna)\n",
    "\n",
    "csi_data = csi_generator.csi.numpy()\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "\n",
    "df_csi_data_original = pd.DataFrame(csi_data, columns=csi_subcarriers)\n",
    "\n",
    "OG_bits, OG_win_bits,total_OG_bits = bits_needed(df_csi_data_original)\n",
    "print(f\"Bits needed: {OG_bits} bits\")\n",
    "print(f\"AvgBits needed per window: {OG_win_bits} bits\")\n",
    "print(f\"Total Bits needed: {total_OG_bits} bits\")\n",
    "\n",
    "for num_components in components:\n",
    "    print(f\"-------------- {num_components} components ----------------------\")\n",
    "    directory = f'./results/{num_components}_components/dumps'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    df_csi_data = df_csi_data_original.copy()\n",
    "\n",
    "    #Apply PCA\n",
    "    df_reduced, pca = analyze_PCA(df_csi_data, num_components, directory=directory, plotGraph=False)\n",
    "    \n",
    "    print (f\"DF_CSI_DATA\")\n",
    "    #PCA_avg_bits_per_symbol, PCA_avg_bits_per_window, PCA_total_bits = compute_bits_needed(df_reduced, verbose=False)\n",
    "    PCA_bits, PCA_win_bits,total_PCA_bits = bits_needed(df_reduced)\n",
    "    print(f\"Bits needed: {PCA_bits} bits\")\n",
    "    print(f\"AvgBits needed per window: {PCA_win_bits} bits\")\n",
    "    print(f\"Total Bits needed: {total_PCA_bits} bits\")\n",
    "\n",
    "    for num_levels in levels:\n",
    "        print(f\"-------------- {num_components} components {num_levels} lvls --------------\")\n",
    "        #Quantize the data\n",
    "        df_train_quantized = apply_quantization(df_reduced, num_levels)\n",
    "        print (f\"DF_QUANTIZED\")\n",
    "        #QT_avg_bits_per_symbol, QT_avg_bits_per_window, QT_total_bits = compute_bits_needed(df_quantized, verbose=False)\n",
    "        QT_bits, QT_win_bits, total_QT_bits = bits_needed(df_train_quantized, num_levels)\n",
    "        print(f\"Bits needed: {QT_bits} bits\")\n",
    "        print(f\"AvgBits needed per window: {QT_win_bits} bits\")\n",
    "        print(f\"Total Bits needed: {total_QT_bits} bits\")\n",
    "\n",
    "        #Reconstruct the data\n",
    "        df_train_reconstructed = reconstruct_data(df_train_quantized, pca, csi_subcarriers)\n",
    "        print (f\"DF_RECONSTRUCTED\")\n",
    "        #REC_avg_bits_per_symbol, REC_avg_bits_per_window, REC_total_bits = compute_bits_needed(df_reconstructed, verbose=False)\n",
    "        REC_bits, REC_win_bits, total_REC_bits = bits_needed(df_train_reconstructed)\n",
    "        print(f\"Bits needed: {REC_bits} bits\")\n",
    "        print(f\"AvgBits needed per window: {REC_win_bits} bits\")\n",
    "        print(f\"Total Bits needed: {total_REC_bits} bits\")\n",
    "        \n",
    "        df_train_reconstructed = df_train_reconstructed.to_numpy()\n",
    "        reconstructed_train_data = tf.convert_to_tensor(df_train_reconstructed)\n",
    "        csi_generator.csi = reconstructed_train_data\n",
    "\n",
    "        bit_results.append({\n",
    "            'num_components': num_components,\n",
    "            'num_levels': num_levels,\n",
    "            'OG_bits': OG_bits,\n",
    "            'PCA_bits': PCA_bits,\n",
    "            'QT_bits': QT_bits,\n",
    "            'REC_bits': REC_bits,\n",
    "            'OG_win_bits': OG_win_bits,\n",
    "            'PCA_win_bits': PCA_win_bits,\n",
    "            'QT_win_bits': QT_win_bits,\n",
    "            'REC_win_bits': REC_win_bits,\n",
    "            'total_OG_bits': total_OG_bits,\n",
    "            'total_PCA_bits': total_PCA_bits,\n",
    "            'total_QT_bits': total_QT_bits,\n",
    "            'total_REC_bits': total_REC_bits\n",
    "        })\n",
    "\n",
    "bit_results = pd.DataFrame(bit_results)\n",
    "bit_results.to_csv(f'./results_csv/bit_results_single_antenna2_{antenna}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Output Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "csi_generator = CsiDataGenerator(file_list, batch_size=BATCH_SIZE, antenna_select=antenna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the VAE to process CSI data\n",
    "z_data = np.zeros([0, 4])\n",
    "z_labels = np.zeros([0])\n",
    "\n",
    "vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.load_weights(f'./{folder_name}/weights_vae').expect_partial()\n",
    "\n",
    "for (data, labels) in csi_generator:\n",
    "    labels = tf.squeeze(labels)\n",
    "    z_mean, z_log_var, _ = vae.encoder.predict(data, verbose=0)\n",
    "    z_tmp = np.concatenate([z_mean, z_log_var], axis=1)\n",
    "    z_data = np.concatenate([z_data, z_tmp], axis=0)\n",
    "    z_labels = np.concatenate([z_labels, labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f'./results/0_components/dumps'\n",
    "bit_results = []\n",
    "\n",
    "df_z_data = pd.DataFrame(z_data, columns=[f'z_mean_{i}' for i in range(2)] + [f'z_log_var_{i}' for i in range(2)])\n",
    "\n",
    "for lvl in levels:\n",
    "    print(f\"-------------- {lvl} lvls --------------\")\n",
    "    sub_dir=os.path.join(directory, f'{lvl}lvls_single_antenna_{antenna}.pkl')\n",
    "\n",
    "    df_train_quantized = apply_quantization(df_z_data, lvl)\n",
    "    print (f\"DF_QUANTIZED\")\n",
    "        #QT_avg_bits_per_symbol, QT_avg_bits_per_window, QT_total_bits = compute_bits_needed(df_quantized, verbose=False)\n",
    "    QT_bits, QT_win_bits, total_QT_bits = bits_needed(df_train_quantized, lvl)\n",
    "    print(f\"Bits needed: {QT_bits} bits\")\n",
    "    print(f\"AvgBits needed per window: {QT_win_bits} bits\")\n",
    "    print(f\"Total Bits needed: {total_QT_bits} bits\")\n",
    "\n",
    "    z_data = df_train_quantized.to_numpy()\n",
    "\n",
    "#    with open(sub_dir, 'wb') as f:\n",
    "#       pickle.dump([z_data, z_labels], f)\n",
    "\n",
    "    bit_results.append({\n",
    "            'num_levels': lvl,\n",
    "            'QT_bits': QT_bits,\n",
    "            'QT_win_bits': QT_win_bits,\n",
    "            'total_QT_bits': total_QT_bits,\n",
    "        })\n",
    "\n",
    "bit_results = pd.DataFrame(bit_results)\n",
    "bit_results.to_csv(f'./results/csv/VAE_bit_results_single_antenna_{antenna}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "csi_generator = CsiDataGenerator(file_list, batch_size=BATCH_SIZE, antenna_select=antenna)\n",
    "\n",
    "target = 90\n",
    "num_levels = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_data = csi_generator.csi.numpy()\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "\n",
    "df_csi_data = pd.DataFrame(csi_data, columns=csi_subcarriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = find_n_components(df_csi_data, target, plotGraph=False)\n",
    "df_reduced, pca = analyze_PCA(df_csi_data, num_components, plotGraph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_quantized = apply_quantization(df_reduced, num_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_reconstructed = reconstruct_data(df_train_quantized, pca, csi_subcarriers)\n",
    "\n",
    "df_train_reconstructed = df_train_reconstructed.to_numpy()\n",
    "reconstructed_train_data = tf.convert_to_tensor(df_train_reconstructed)\n",
    "\n",
    "print('Original csi data shape:', df_csi_data.shape)\n",
    "print('PCA df shape:', df_reduced.shape)\n",
    "print('Reconstructed csi data shape:', reconstructed_train_data.shape)\n",
    "\n",
    "csi_generator.csi = reconstructed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the VAE to process CSI data\n",
    "z_data = np.zeros([0, 4])\n",
    "z_labels = np.zeros([0])\n",
    "\n",
    "vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.load_weights(f'./{folder_name}/weights_vae').expect_partial()\n",
    "\n",
    "for (data, labels) in csi_generator:\n",
    "    labels = tf.squeeze(labels)\n",
    "    z_mean, z_log_var, _ = vae.encoder.predict(data, verbose=0)\n",
    "    z_tmp = np.concatenate([z_mean, z_log_var], axis=1)\n",
    "    z_data = np.concatenate([z_data, z_tmp], axis=0)\n",
    "    z_labels = np.concatenate([z_labels, labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'single_antenna_{antenna}', 'wb') as f:\n",
    "    pickle.dump([z_data, z_labels], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Comprehenisve Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(range(1, 11)) + list(range(15, 41, 5)) + list(range(50, 101, 10))\n",
    "components = [1, 2, 3, 4, 10, 20, 30, 40, 50, 100]\n",
    "levels = [2**i for i in range(1, 8)]\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "\n",
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "\n",
    "train_data, test_data = load_split_train_test_CSI_data(file_list, batch_size=BATCH_SIZE, antennas=ANTENNAS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "df_csi_train = pd.DataFrame(train_data.csi.numpy(), columns=csi_subcarriers)\n",
    "df_csi_test = pd.DataFrame(test_data.csi.numpy(), columns=csi_subcarriers)\n",
    "\n",
    "for num_components in components:\n",
    "    print(f\"-------------- {num_components} components --------------\")\n",
    "    df_train = df_csi_train.copy()\n",
    "    df_test = df_csi_test.copy()\n",
    "    directory = f'./dumps/{num_components}_components'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    #Apply PCA\n",
    "    df_train_reduced, pca = analyze_PCA(df_train, num_components, directory=directory, saveGraph=True, plotGraph=True)\n",
    "\n",
    "    test_reduced = pca.transform(df_test)\n",
    "    df_test_reduced = pd.DataFrame(test_reduced, columns=[f'PC{i}' for i in range(num_components)])\n",
    "\n",
    "    for num_levels in levels:\n",
    "        print(f\"-------------- {num_components} components w/ {num_levels} lvls --------------\")\n",
    "        filename = f'{num_levels}lvls_single_antenna_{antenna}'\n",
    "        #Quantize the data\n",
    "        df_train_quantized = apply_quantization(df_train_reduced, num_levels)\n",
    "        df_test_quantized = apply_quantization(df_test_reduced, num_levels)\n",
    "\n",
    "        #Reconstruct the data\n",
    "        df_train_reconstructed = reconstruct_data(df_train_quantized, pca, csi_subcarriers)\n",
    "        df_train_reconstructed = df_train_reconstructed.to_numpy()\n",
    "        reconstructed_train_data = tf.convert_to_tensor(df_train_reconstructed, dtype=tf.float32)\n",
    "        train_data.csi = reconstructed_train_data\n",
    "\n",
    "        df_test_reconstructed = reconstruct_data(df_test_quantized, pca, csi_subcarriers)\n",
    "        df_test_reconstructed = df_test_reconstructed.to_numpy()\n",
    "        reconstructed_test_data = tf.convert_to_tensor(df_test_reconstructed, dtype=tf.float32)\n",
    "        test_data.csi = reconstructed_test_data\n",
    "\n",
    "        vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "        vae.compile(optimizer=tf_keras.optimizers.Adam())\n",
    "        vae.load_weights(f'./{folder_name}/train_weights_vae').expect_partial()\n",
    "        \n",
    "        print(\"Encoding train data...\")\n",
    "        z_data_train, z_labels_train = apply_vae_encoder(vae, train_data)\n",
    "        \n",
    "        print(\"Encoding test data...\")\n",
    "        z_data_test, z_labels_test = apply_vae_encoder(vae, test_data)\n",
    "\n",
    "        train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "        os.makedirs(os.path.dirname(train_dump_dir), exist_ok=True)\n",
    "        test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "        os.makedirs(os.path.dirname(test_dump_dir), exist_ok=True)\n",
    "        print(\"Saving data...\")\n",
    "        with open(train_dump_dir, 'wb') as f:\n",
    "            pickle.dump([z_data_train, z_labels_train], f)\n",
    "        with open(test_dump_dir, 'wb') as f:\n",
    "            pickle.dump([z_data_test, z_labels_test], f)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_components in components:\n",
    "    directory = f'./dumps/{num_components}_components'\n",
    "    for num_levels in levels:  \n",
    "        print(f\"-------------- {num_components} components w/ {num_levels} lvls --------------\")\n",
    "        train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "        test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "\n",
    "        X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dump_dir)\n",
    "        X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dump_dir, scaler)\n",
    "\n",
    "        name = \"No-Fused-1\"\n",
    "        run_edl_experiment(name, num_components, num_levels, X_train, y_train_dummy)\n",
    "\n",
    "        # Test model\n",
    "        accuracy = results_test(num_components, num_levels, train_dump_dir, test_dump_dir)\n",
    "        results.append(\n",
    "            {\n",
    "                \"num_components\": num_components,\n",
    "                \"num_levels\": num_levels,\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "        \n",
    "results_df = pd.DataFrame(results)\n",
    "os.makedirs('results_csv', exist_ok=True)\n",
    "results_df.to_csv('results_csv/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    #if num_components not in components:\n",
    "    #    continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE', linewidth=3)\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Bits per symbol')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "#plt.savefig(os.path.join('accuracy_bit_comparison[BxS][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "#components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    if num_components not in components:\n",
    "        continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_win_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_win_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE')\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Average bits per window')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "#plt.savefig(os.path.join('accuracy_bit_comparison[BxW][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "train_data, test_data = load_split_train_test_CSI_data(file_list, batch_size=BATCH_SIZE, antennas=ANTENNAS)\n",
    "\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "df_csi_train = pd.DataFrame(train_data.csi.numpy(), columns=csi_subcarriers)\n",
    "df_csi_test = pd.DataFrame(test_data.csi.numpy(), columns=csi_subcarriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load_pretrained_models = True\n",
    "\n",
    "if load_pretrained_models:\n",
    "    print('Loading pretrained models...')\n",
    "    !wget https://zenodo.org/record/7983057/files/VAE_models.zip\n",
    "    !unzip -o VAE_models.zip\n",
    "    !rm VAE_models.zip\n",
    "else:\n",
    "    # Train from scratch\n",
    "    #!mkdir {folder_name}\n",
    "    vae = VAE()\n",
    "    vae.compile(optimizer=tf_keras.optimizers.Adam())\n",
    "    vae.save_weights(checkpoint_path.format(epoch=0))\n",
    "    vae.fit(train_data, epochs=20, shuffle=True,\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, csv_logger_cb])\n",
    "    vae.save_weights(f'./{folder_name}/train_weights_vae')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "folder_name = f'models/old_single_antenna_{antenna}'\n",
    "\n",
    "print(f\"-------------- 0 components --------------\")\n",
    "directory = './dumps/0_components'\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "filename = f'0lvls_single_antenna_{antenna}'\n",
    "\n",
    "vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "vae.compile(optimizer=tf_keras.optimizers.Adam())\n",
    "vae.load_weights(f'./{folder_name}/weights_vae').expect_partial()\n",
    "\n",
    "print(\"Encoding train data...\")\n",
    "z_data_train, z_labels_train = apply_vae_encoder(vae, train_data)\n",
    "\n",
    "print(\"Encoding test data...\")\n",
    "z_data_test, z_labels_test = apply_vae_encoder(vae, test_data)\n",
    "\n",
    "train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "os.makedirs(os.path.dirname(train_dump_dir), exist_ok=True)\n",
    "test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "os.makedirs(os.path.dirname(test_dump_dir), exist_ok=True)\n",
    "with open(train_dump_dir, 'wb') as f:\n",
    "    pickle.dump([z_data_train, z_labels_train], f)\n",
    "with open(test_dump_dir, 'wb') as f:\n",
    "    pickle.dump([z_data_test, z_labels_test], f)\n",
    "\n",
    "print(\"-------------- Training and testing DL model --------------\")\n",
    "X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dump_dir)\n",
    "X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dump_dir, scaler)\n",
    "\n",
    "name = \"No-Fused-1\"\n",
    "run_edl_experiment(name, X_train, y_train_dummy)\n",
    "\n",
    "# Test model\n",
    "accuracy = results_test(train_dump_dir, test_dump_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './dumps/0_components'\n",
    "filename = f'0lvls_single_antenna_{antenna}'\n",
    "train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "results = []\n",
    "\n",
    "print(\"-------------- Training and testing DL model --------------\")\n",
    "X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dump_dir)\n",
    "X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dump_dir, scaler)\n",
    "\n",
    "name = \"No-Fused-1\"\n",
    "run_edl_experiment(name, X_train, y_train_dummy)\n",
    "\n",
    "# Test model\n",
    "accuracy = results_test(train_dump_dir, test_dump_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae shapes:  (57750, 4) (57750,)\n",
      "******************************************\n",
      "first index: 0 last index: 11550\n",
      "first label: 0.0 last label: 0.0\n",
      "2310\n",
      "-------- 0 ---------\n",
      "0\n",
      "idx 0 to 1350\n",
      "(1350, 4)\n",
      "idx 1800 to 1950\n",
      "(150, 4)\n",
      "-------- 1 ---------\n",
      "2310\n",
      "idx 2310 to 3660\n",
      "(1350, 4)\n",
      "idx 4110 to 4260\n",
      "(150, 4)\n",
      "-------- 2 ---------\n",
      "4620\n",
      "idx 4620 to 5970\n",
      "(1350, 4)\n",
      "idx 6420 to 6570\n",
      "(150, 4)\n",
      "-------- 3 ---------\n",
      "6930\n",
      "idx 6930 to 8280\n",
      "(1350, 4)\n",
      "idx 8730 to 8880\n",
      "(150, 4)\n",
      "-------- 4 ---------\n",
      "9240\n",
      "idx 9240 to 10590\n",
      "(1350, 4)\n",
      "idx 11040 to 11190\n",
      "(150, 4)\n",
      "******************************************\n",
      "first index: 11550 last index: 23100\n",
      "first label: 1.0 last label: 1.0\n",
      "2310\n",
      "-------- 0 ---------\n",
      "0\n",
      "idx 0 to 1350\n",
      "(1350, 4)\n",
      "idx 1800 to 1950\n",
      "(150, 4)\n",
      "-------- 1 ---------\n",
      "2310\n",
      "idx 2310 to 3660\n",
      "(1350, 4)\n",
      "idx 4110 to 4260\n",
      "(150, 4)\n",
      "-------- 2 ---------\n",
      "4620\n",
      "idx 4620 to 5970\n",
      "(1350, 4)\n",
      "idx 6420 to 6570\n",
      "(150, 4)\n",
      "-------- 3 ---------\n",
      "6930\n",
      "idx 6930 to 8280\n",
      "(1350, 4)\n",
      "idx 8730 to 8880\n",
      "(150, 4)\n",
      "-------- 4 ---------\n",
      "9240\n",
      "idx 9240 to 10590\n",
      "(1350, 4)\n",
      "idx 11040 to 11190\n",
      "(150, 4)\n",
      "******************************************\n",
      "first index: 23100 last index: 34650\n",
      "first label: 2.0 last label: 2.0\n",
      "2310\n",
      "-------- 0 ---------\n",
      "0\n",
      "idx 0 to 1350\n",
      "(1350, 4)\n",
      "idx 1800 to 1950\n",
      "(150, 4)\n",
      "-------- 1 ---------\n",
      "2310\n",
      "idx 2310 to 3660\n",
      "(1350, 4)\n",
      "idx 4110 to 4260\n",
      "(150, 4)\n",
      "-------- 2 ---------\n",
      "4620\n",
      "idx 4620 to 5970\n",
      "(1350, 4)\n",
      "idx 6420 to 6570\n",
      "(150, 4)\n",
      "-------- 3 ---------\n",
      "6930\n",
      "idx 6930 to 8280\n",
      "(1350, 4)\n",
      "idx 8730 to 8880\n",
      "(150, 4)\n",
      "-------- 4 ---------\n",
      "9240\n",
      "idx 9240 to 10590\n",
      "(1350, 4)\n",
      "idx 11040 to 11190\n",
      "(150, 4)\n",
      "******************************************\n",
      "first index: 34650 last index: 46200\n",
      "first label: 3.0 last label: 3.0\n",
      "2310\n",
      "-------- 0 ---------\n",
      "0\n",
      "idx 0 to 1350\n",
      "(1350, 4)\n",
      "idx 1800 to 1950\n",
      "(150, 4)\n",
      "-------- 1 ---------\n",
      "2310\n",
      "idx 2310 to 3660\n",
      "(1350, 4)\n",
      "idx 4110 to 4260\n",
      "(150, 4)\n",
      "-------- 2 ---------\n",
      "4620\n",
      "idx 4620 to 5970\n",
      "(1350, 4)\n",
      "idx 6420 to 6570\n",
      "(150, 4)\n",
      "-------- 3 ---------\n",
      "6930\n",
      "idx 6930 to 8280\n",
      "(1350, 4)\n",
      "idx 8730 to 8880\n",
      "(150, 4)\n",
      "-------- 4 ---------\n",
      "9240\n",
      "idx 9240 to 10590\n",
      "(1350, 4)\n",
      "idx 11040 to 11190\n",
      "(150, 4)\n",
      "******************************************\n",
      "first index: 46200 last index: 57750\n",
      "first label: 4.0 last label: 4.0\n",
      "2310\n",
      "-------- 0 ---------\n",
      "0\n",
      "idx 0 to 1350\n",
      "(1350, 4)\n",
      "idx 1800 to 1950\n",
      "(150, 4)\n",
      "-------- 1 ---------\n",
      "2310\n",
      "idx 2310 to 3660\n",
      "(1350, 4)\n",
      "idx 4110 to 4260\n",
      "(150, 4)\n",
      "-------- 2 ---------\n",
      "4620\n",
      "idx 4620 to 5970\n",
      "(1350, 4)\n",
      "idx 6420 to 6570\n",
      "(150, 4)\n",
      "-------- 3 ---------\n",
      "6930\n",
      "idx 6930 to 8280\n",
      "(1350, 4)\n",
      "idx 8730 to 8880\n",
      "(150, 4)\n",
      "-------- 4 ---------\n",
      "9240\n",
      "idx 9240 to 10590\n",
      "(1350, 4)\n",
      "idx 11040 to 11190\n",
      "(150, 4)\n",
      "(33750, 4) (3750, 4)\n",
      "(33750,) (3750,)\n"
     ]
    }
   ],
   "source": [
    "directory = './dumps/0_components/vae_single_antenna_0.pkl'\n",
    "filename = f'0lvls_single_antenna_{antenna}'\n",
    "with open(directory, 'rb') as f:\n",
    "    vae_data, vae_labels = pickle.load(f)\n",
    "\n",
    "n_samples_activity = vae_data.shape[0]//5\n",
    "file_number = list(range(5))\n",
    "print(\"vae shapes: \", vae_data.shape, vae_labels.shape)\n",
    "train_data = np.zeros([0, 4])\n",
    "train_labels = np.zeros([0])\n",
    "test_data = np.zeros([0, 4])\n",
    "test_labels = np.zeros([0])\n",
    "\n",
    "for file_number in range(5):\n",
    "    print(f\"******************************************\")\n",
    "    first_idx = n_samples_activity * file_number\n",
    "    last_idx = first_idx + n_samples_activity\n",
    "\n",
    "    #print(type(vae_data), type(vae_labels))\n",
    "    print(f\"first index: {first_idx} last index: {last_idx}\")\n",
    "    print(f\"first label: {vae_labels[first_idx]} last label: {vae_labels[last_idx-1]}\")\n",
    "\n",
    "    print(int(n_samples_activity/5))\n",
    "\n",
    "    data = vae_data[first_idx : last_idx]\n",
    "    labels = vae_labels[first_idx : last_idx]\n",
    "    iter = 0\n",
    "\n",
    "    for iter in range(5):\n",
    "        print(f\"-------- {iter} ---------\")\n",
    "        print((n_samples_activity//5) * iter)\n",
    "        start_train_idx = 0 + (n_samples_activity//5) * iter\n",
    "        end_train_idx = start_train_idx + 150 * 9\n",
    "        print(f\"idx {start_train_idx} to {end_train_idx}\")\n",
    "        train = data[start_train_idx : end_train_idx]\n",
    "        train_label = labels[start_train_idx : end_train_idx]\n",
    "        print(train.shape)\n",
    "\n",
    "        start_test_idx = end_train_idx + 150 * 3\n",
    "        end_test_idx =  start_test_idx + 150 * 1\n",
    "\n",
    "        print(f\"idx {start_test_idx} to {end_test_idx}\")\n",
    "        test = data[start_test_idx : end_test_idx]\n",
    "        test_label = labels[start_test_idx : end_test_idx]\n",
    "        print(test.shape)\n",
    "\n",
    "        train_data = np.append(train_data, train, axis=0)\n",
    "        train_labels = np.append(train_labels, train_label, axis=0)\n",
    "        test_data = np.append(test_data, test, axis=0)\n",
    "        test_labels = np.append(test_labels, test_label, axis=0)\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(train_labels.shape, test_labels.shape)\n",
    "\n",
    "directory = './dumps/0_components'\n",
    "train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "os.makedirs(os.path.dirname(train_dump_dir), exist_ok=True)\n",
    "test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "os.makedirs(os.path.dirname(test_dump_dir), exist_ok=True)\n",
    "with open(train_dump_dir, 'wb') as f:\n",
    "    pickle.dump([train_data, train_labels], f)\n",
    "with open(test_dump_dir, 'wb') as f:\n",
    "    pickle.dump([test_data, test_labels], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Training and testing DL model --------------\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paolo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - edl_accuracy: 0.4212 - loss: 0.8821\n",
      "Epoch 2/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - edl_accuracy: 0.3083 - loss: 0.8679\n",
      "Epoch 3/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - edl_accuracy: 0.2812 - loss: 0.8652\n",
      "Epoch 4/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - edl_accuracy: 0.4106 - loss: 0.7247\n",
      "Epoch 5/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - edl_accuracy: 0.3554 - loss: 0.8666\n",
      "Epoch 6/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - edl_accuracy: 0.4410 - loss: 0.7445\n",
      "Epoch 7/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - edl_accuracy: 0.4579 - loss: 0.7608\n",
      "Epoch 8/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - edl_accuracy: 0.4319 - loss: 0.8332\n",
      "Epoch 9/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - edl_accuracy: 0.4428 - loss: 0.8802\n",
      "Epoch 10/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - edl_accuracy: 0.3891 - loss: 0.9146\n",
      "Epoch 11/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - edl_accuracy: 0.4584 - loss: 0.8227\n",
      "Epoch 12/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - edl_accuracy: 0.4298 - loss: 0.8468\n",
      "Epoch 13/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - edl_accuracy: 0.4570 - loss: 0.8453\n",
      "Epoch 14/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - edl_accuracy: 0.4649 - loss: 0.8062\n",
      "Epoch 15/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - edl_accuracy: 0.4626 - loss: 0.7969\n",
      "Epoch 16/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - edl_accuracy: 0.4110 - loss: 0.8504\n",
      "Epoch 17/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - edl_accuracy: 0.5047 - loss: 0.7558\n",
      "Epoch 18/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - edl_accuracy: 0.5209 - loss: 0.7649\n",
      "Epoch 19/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - edl_accuracy: 0.5773 - loss: 0.7282\n",
      "Epoch 20/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - edl_accuracy: 0.5731 - loss: 0.7122\n",
      "Epoch 21/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - edl_accuracy: 0.6069 - loss: 0.6846\n",
      "Epoch 22/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - edl_accuracy: 0.6459 - loss: 0.6438\n",
      "Epoch 23/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - edl_accuracy: 0.6674 - loss: 0.6188\n",
      "Epoch 24/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - edl_accuracy: 0.6735 - loss: 0.6237\n",
      "Epoch 25/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - edl_accuracy: 0.6978 - loss: 0.5971\n",
      "Epoch 26/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - edl_accuracy: 0.7115 - loss: 0.5879\n",
      "Epoch 27/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - edl_accuracy: 0.7146 - loss: 0.5855\n",
      "Epoch 28/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - edl_accuracy: 0.7145 - loss: 0.5843\n",
      "Epoch 29/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - edl_accuracy: 0.7196 - loss: 0.5797\n",
      "Epoch 30/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - edl_accuracy: 0.7253 - loss: 0.5669\n",
      "Epoch 31/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - edl_accuracy: 0.7287 - loss: 0.5697\n",
      "Epoch 32/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - edl_accuracy: 0.7330 - loss: 0.5581\n",
      "Epoch 33/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - edl_accuracy: 0.7343 - loss: 0.5579\n",
      "Epoch 34/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - edl_accuracy: 0.7369 - loss: 0.5492\n",
      "Epoch 35/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - edl_accuracy: 0.7389 - loss: 0.5495\n",
      "Epoch 36/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - edl_accuracy: 0.7376 - loss: 0.5479\n",
      "Epoch 37/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.7424 - loss: 0.5488\n",
      "Epoch 38/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - edl_accuracy: 0.7444 - loss: 0.5476\n",
      "Epoch 39/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - edl_accuracy: 0.7464 - loss: 0.5483\n",
      "Epoch 40/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - edl_accuracy: 0.7468 - loss: 0.5423\n",
      "Epoch 41/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - edl_accuracy: 0.7456 - loss: 0.5387\n",
      "Epoch 42/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - edl_accuracy: 0.7480 - loss: 0.5350\n",
      "Epoch 43/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - edl_accuracy: 0.7459 - loss: 0.5401\n",
      "Epoch 44/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - edl_accuracy: 0.7520 - loss: 0.5340\n",
      "Epoch 45/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - edl_accuracy: 0.7458 - loss: 0.5383\n",
      "Epoch 46/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - edl_accuracy: 0.7554 - loss: 0.5242\n",
      "Epoch 47/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - edl_accuracy: 0.7529 - loss: 0.5258\n",
      "Epoch 48/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - edl_accuracy: 0.7512 - loss: 0.5272\n",
      "Epoch 49/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - edl_accuracy: 0.7450 - loss: 0.5274\n",
      "Epoch 50/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - edl_accuracy: 0.7569 - loss: 0.5110\n",
      "Epoch 51/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - edl_accuracy: 0.7657 - loss: 0.5062\n",
      "Epoch 52/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - edl_accuracy: 0.7635 - loss: 0.5047\n",
      "Epoch 53/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - edl_accuracy: 0.7618 - loss: 0.5028\n",
      "Epoch 54/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - edl_accuracy: 0.7653 - loss: 0.4981\n",
      "Epoch 55/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - edl_accuracy: 0.7674 - loss: 0.4905\n",
      "Epoch 56/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - edl_accuracy: 0.7728 - loss: 0.4857\n",
      "Epoch 57/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - edl_accuracy: 0.7743 - loss: 0.4802\n",
      "Epoch 58/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - edl_accuracy: 0.7734 - loss: 0.4780\n",
      "Epoch 59/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - edl_accuracy: 0.7739 - loss: 0.4756\n",
      "Epoch 60/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - edl_accuracy: 0.7665 - loss: 0.4880\n",
      "Epoch 61/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - edl_accuracy: 0.7596 - loss: 0.4981\n",
      "Epoch 62/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - edl_accuracy: 0.7594 - loss: 0.4848\n",
      "Epoch 63/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - edl_accuracy: 0.7844 - loss: 0.4489\n",
      "Epoch 64/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - edl_accuracy: 0.7853 - loss: 0.4421\n",
      "Epoch 65/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - edl_accuracy: 0.7926 - loss: 0.4320\n",
      "Epoch 66/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - edl_accuracy: 0.8010 - loss: 0.4190\n",
      "Epoch 67/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - edl_accuracy: 0.8080 - loss: 0.4113\n",
      "Epoch 68/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - edl_accuracy: 0.8172 - loss: 0.3961\n",
      "Epoch 69/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.8185 - loss: 0.3878\n",
      "Epoch 70/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - edl_accuracy: 0.8194 - loss: 0.3790\n",
      "Epoch 71/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - edl_accuracy: 0.8216 - loss: 0.3717\n",
      "Epoch 72/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - edl_accuracy: 0.8258 - loss: 0.3592\n",
      "Epoch 73/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - edl_accuracy: 0.8304 - loss: 0.3471\n",
      "Epoch 74/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - edl_accuracy: 0.8294 - loss: 0.3379\n",
      "Epoch 75/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - edl_accuracy: 0.8376 - loss: 0.3258\n",
      "Epoch 76/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - edl_accuracy: 0.8439 - loss: 0.3171\n",
      "Epoch 77/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - edl_accuracy: 0.8431 - loss: 0.3117\n",
      "Epoch 78/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - edl_accuracy: 0.8438 - loss: 0.3044\n",
      "Epoch 79/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - edl_accuracy: 0.8487 - loss: 0.3037\n",
      "Epoch 80/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - edl_accuracy: 0.8528 - loss: 0.2900\n",
      "Epoch 81/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - edl_accuracy: 0.8545 - loss: 0.2890\n",
      "Epoch 82/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - edl_accuracy: 0.8511 - loss: 0.2897\n",
      "Epoch 83/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - edl_accuracy: 0.8493 - loss: 0.2987\n",
      "Epoch 84/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - edl_accuracy: 0.8618 - loss: 0.2771\n",
      "Epoch 85/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - edl_accuracy: 0.8637 - loss: 0.2732\n",
      "Epoch 86/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - edl_accuracy: 0.8647 - loss: 0.2715\n",
      "Epoch 87/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - edl_accuracy: 0.8696 - loss: 0.2631\n",
      "Epoch 88/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - edl_accuracy: 0.8699 - loss: 0.2605\n",
      "Epoch 89/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - edl_accuracy: 0.8726 - loss: 0.2543\n",
      "Epoch 90/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - edl_accuracy: 0.8740 - loss: 0.2496\n",
      "Epoch 91/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - edl_accuracy: 0.8740 - loss: 0.2496\n",
      "Epoch 92/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - edl_accuracy: 0.8749 - loss: 0.2441\n",
      "Epoch 93/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - edl_accuracy: 0.8752 - loss: 0.2476\n",
      "Epoch 94/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - edl_accuracy: 0.8771 - loss: 0.2403\n",
      "Epoch 95/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - edl_accuracy: 0.8764 - loss: 0.2448\n",
      "Epoch 96/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - edl_accuracy: 0.8794 - loss: 0.2357\n",
      "Epoch 97/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - edl_accuracy: 0.8763 - loss: 0.2443\n",
      "Epoch 98/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - edl_accuracy: 0.8834 - loss: 0.2294\n",
      "Epoch 99/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - edl_accuracy: 0.8830 - loss: 0.2360\n",
      "Epoch 100/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - edl_accuracy: 0.8819 - loss: 0.2296\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86       750\n",
      "           1       0.81      1.00      0.89       750\n",
      "           2       1.00      1.00      1.00       750\n",
      "           3       1.00      0.80      0.89       750\n",
      "           4       0.83      1.00      0.91       750\n",
      "\n",
      "    accuracy                           0.91      3750\n",
      "   macro avg       0.93      0.91      0.91      3750\n",
      "weighted avg       0.93      0.91      0.91      3750\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = './dumps/0_components'\n",
    "filename = f'0lvls_single_antenna_{antenna}'\n",
    "train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "results = []\n",
    "\n",
    "print(\"-------------- Training and testing DL model --------------\")\n",
    "X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dump_dir)\n",
    "X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dump_dir, scaler)\n",
    "\n",
    "name = \"No-Fused-1\"\n",
    "run_edl_experiment(name, X_train, y_train_dummy)\n",
    "\n",
    "# Test model\n",
    "accuracy = results_test(train_dump_dir, test_dump_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paolo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - edl_accuracy: 0.5736 - loss: 0.6306\n",
      "Epoch 2/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - edl_accuracy: 0.9089 - loss: 0.2266\n",
      "Epoch 3/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - edl_accuracy: 0.9347 - loss: 0.1629\n",
      "Epoch 4/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - edl_accuracy: 0.9401 - loss: 0.1439\n",
      "Epoch 5/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - edl_accuracy: 0.9420 - loss: 0.1344\n",
      "Epoch 6/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - edl_accuracy: 0.9435 - loss: 0.1290\n",
      "Epoch 7/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - edl_accuracy: 0.9453 - loss: 0.1256\n",
      "Epoch 8/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - edl_accuracy: 0.9464 - loss: 0.1227\n",
      "Epoch 9/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - edl_accuracy: 0.9469 - loss: 0.1210\n",
      "Epoch 10/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - edl_accuracy: 0.9469 - loss: 0.1194\n",
      "Epoch 11/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.9475 - loss: 0.1185\n",
      "Epoch 12/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - edl_accuracy: 0.9480 - loss: 0.1169\n",
      "Epoch 13/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - edl_accuracy: 0.9483 - loss: 0.1161\n",
      "Epoch 14/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - edl_accuracy: 0.9482 - loss: 0.1155\n",
      "Epoch 15/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - edl_accuracy: 0.9485 - loss: 0.1147\n",
      "Epoch 16/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - edl_accuracy: 0.9484 - loss: 0.1148\n",
      "Epoch 17/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - edl_accuracy: 0.9487 - loss: 0.1137\n",
      "Epoch 18/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - edl_accuracy: 0.9484 - loss: 0.1132\n",
      "Epoch 19/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - edl_accuracy: 0.9488 - loss: 0.1126\n",
      "Epoch 20/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.9487 - loss: 0.1123\n",
      "Epoch 21/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - edl_accuracy: 0.9485 - loss: 0.1124\n",
      "Epoch 22/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.9487 - loss: 0.1114\n",
      "Epoch 23/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - edl_accuracy: 0.9487 - loss: 0.1110\n",
      "Epoch 24/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - edl_accuracy: 0.9484 - loss: 0.1113\n",
      "Epoch 25/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - edl_accuracy: 0.9490 - loss: 0.1107\n",
      "Epoch 26/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - edl_accuracy: 0.9489 - loss: 0.1102\n",
      "Epoch 27/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - edl_accuracy: 0.9488 - loss: 0.1102\n",
      "Epoch 28/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - edl_accuracy: 0.9494 - loss: 0.1098\n",
      "Epoch 29/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - edl_accuracy: 0.9492 - loss: 0.1096\n",
      "Epoch 30/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - edl_accuracy: 0.9495 - loss: 0.1094\n",
      "Epoch 31/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - edl_accuracy: 0.9495 - loss: 0.1094\n",
      "Epoch 32/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - edl_accuracy: 0.9494 - loss: 0.1091\n",
      "Epoch 33/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.9494 - loss: 0.1089\n",
      "Epoch 34/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - edl_accuracy: 0.9498 - loss: 0.1081\n",
      "Epoch 35/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - edl_accuracy: 0.9498 - loss: 0.1079\n",
      "Epoch 36/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - edl_accuracy: 0.9499 - loss: 0.1078\n",
      "Epoch 37/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - edl_accuracy: 0.9503 - loss: 0.1074\n",
      "Epoch 38/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.9501 - loss: 0.1073\n",
      "Epoch 39/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - edl_accuracy: 0.9504 - loss: 0.1068\n",
      "Epoch 40/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - edl_accuracy: 0.9509 - loss: 0.1064\n",
      "Epoch 41/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - edl_accuracy: 0.9509 - loss: 0.1066\n",
      "Epoch 42/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - edl_accuracy: 0.9509 - loss: 0.1064\n",
      "Epoch 43/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - edl_accuracy: 0.9510 - loss: 0.1062\n",
      "Epoch 44/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - edl_accuracy: 0.9513 - loss: 0.1058\n",
      "Epoch 45/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - edl_accuracy: 0.9514 - loss: 0.1056\n",
      "Epoch 46/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - edl_accuracy: 0.9510 - loss: 0.1062\n",
      "Epoch 47/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - edl_accuracy: 0.9511 - loss: 0.1058\n",
      "Epoch 48/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - edl_accuracy: 0.9511 - loss: 0.1053\n",
      "Epoch 49/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - edl_accuracy: 0.9508 - loss: 0.1058\n",
      "Epoch 50/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - edl_accuracy: 0.9513 - loss: 0.1055\n",
      "Epoch 51/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - edl_accuracy: 0.9512 - loss: 0.1054\n",
      "Epoch 52/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - edl_accuracy: 0.9511 - loss: 0.1059\n",
      "Epoch 53/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - edl_accuracy: 0.9514 - loss: 0.1052\n",
      "Epoch 54/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - edl_accuracy: 0.9515 - loss: 0.1051\n",
      "Epoch 55/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - edl_accuracy: 0.9513 - loss: 0.1056\n",
      "Epoch 56/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - edl_accuracy: 0.9516 - loss: 0.1054\n",
      "Epoch 57/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - edl_accuracy: 0.9512 - loss: 0.1057\n",
      "Epoch 58/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - edl_accuracy: 0.9516 - loss: 0.1056\n",
      "Epoch 59/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - edl_accuracy: 0.9515 - loss: 0.1049\n",
      "Epoch 60/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - edl_accuracy: 0.9514 - loss: 0.1051\n",
      "Epoch 61/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - edl_accuracy: 0.9518 - loss: 0.1049\n",
      "Epoch 62/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - edl_accuracy: 0.9518 - loss: 0.1046\n",
      "Epoch 63/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - edl_accuracy: 0.9516 - loss: 0.1049\n",
      "Epoch 64/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - edl_accuracy: 0.9515 - loss: 0.1046\n",
      "Epoch 65/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - edl_accuracy: 0.9522 - loss: 0.1047\n",
      "Epoch 66/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - edl_accuracy: 0.9521 - loss: 0.1046\n",
      "Epoch 67/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - edl_accuracy: 0.9521 - loss: 0.1047\n",
      "Epoch 68/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - edl_accuracy: 0.9525 - loss: 0.1041\n",
      "Epoch 69/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - edl_accuracy: 0.9521 - loss: 0.1043\n",
      "Epoch 70/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - edl_accuracy: 0.9523 - loss: 0.1041\n",
      "Epoch 71/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - edl_accuracy: 0.9523 - loss: 0.1044\n",
      "Epoch 72/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - edl_accuracy: 0.9524 - loss: 0.1040\n",
      "Epoch 73/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - edl_accuracy: 0.9525 - loss: 0.1040\n",
      "Epoch 74/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - edl_accuracy: 0.9524 - loss: 0.1041\n",
      "Epoch 75/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - edl_accuracy: 0.9523 - loss: 0.1042\n",
      "Epoch 76/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - edl_accuracy: 0.9524 - loss: 0.1037\n",
      "Epoch 77/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - edl_accuracy: 0.9522 - loss: 0.1040\n",
      "Epoch 78/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - edl_accuracy: 0.9524 - loss: 0.1035\n",
      "Epoch 79/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - edl_accuracy: 0.9526 - loss: 0.1035\n",
      "Epoch 80/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - edl_accuracy: 0.9523 - loss: 0.1038\n",
      "Epoch 81/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - edl_accuracy: 0.9521 - loss: 0.1042\n",
      "Epoch 82/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - edl_accuracy: 0.9525 - loss: 0.1036\n",
      "Epoch 83/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - edl_accuracy: 0.9526 - loss: 0.1035\n",
      "Epoch 84/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - edl_accuracy: 0.9527 - loss: 0.1034\n",
      "Epoch 85/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.9525 - loss: 0.1035\n",
      "Epoch 86/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - edl_accuracy: 0.9523 - loss: 0.1036\n",
      "Epoch 87/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - edl_accuracy: 0.9523 - loss: 0.1036\n",
      "Epoch 88/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - edl_accuracy: 0.9526 - loss: 0.1034\n",
      "Epoch 89/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - edl_accuracy: 0.9527 - loss: 0.1032\n",
      "Epoch 90/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - edl_accuracy: 0.9526 - loss: 0.1028\n",
      "Epoch 91/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - edl_accuracy: 0.9526 - loss: 0.1033\n",
      "Epoch 92/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - edl_accuracy: 0.9525 - loss: 0.1033\n",
      "Epoch 93/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - edl_accuracy: 0.9530 - loss: 0.1036\n",
      "Epoch 94/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - edl_accuracy: 0.9527 - loss: 0.1033\n",
      "Epoch 95/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - edl_accuracy: 0.9524 - loss: 0.1029\n",
      "Epoch 96/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - edl_accuracy: 0.9530 - loss: 0.1026\n",
      "Epoch 97/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - edl_accuracy: 0.9531 - loss: 0.1029\n",
      "Epoch 98/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - edl_accuracy: 0.9528 - loss: 0.1027\n",
      "Epoch 99/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - edl_accuracy: 0.9528 - loss: 0.1025\n",
      "Epoch 100/100\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - edl_accuracy: 0.9529 - loss: 0.1036\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      2310\n",
      "           1       0.91      0.95      0.93      2310\n",
      "           2       0.99      0.93      0.96      2310\n",
      "           3       0.97      0.93      0.95      2310\n",
      "           4       0.94      0.98      0.96      2310\n",
      "\n",
      "    accuracy                           0.95     11550\n",
      "   macro avg       0.95      0.95      0.95     11550\n",
      "weighted avg       0.95      0.95      0.95     11550\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = './dumps/0_components/vae_single_antenna_0.pkl'\n",
    "\n",
    "X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns = load_experiment_reconstructed(directory)\n",
    "name = \"No-Fused-1\"\n",
    "run_edl_experiment(name, X_train, y_train_dummy)\n",
    "\n",
    "# Test model\n",
    "accuracy = results_test2(directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
