{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE training and processing\n",
    "\n",
    "Sample code to train a new VAE and run the CSI processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Paolo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_keras\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]= '1' # Use legacy keras for compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTENNAS = 1\n",
    "antenna = 0  # if ANTENNAS==1, this value selects the antenna ID (from 0 to 3)\n",
    "\n",
    "BATCH_SIZE = 25\n",
    "latent_dim = 2\n",
    "num_activities = 5\n",
    "folder_name = f'models/single_antenna_{antenna}'\n",
    "\n",
    "base_directory = './models'\n",
    "saveGraph = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state) # predictable random numbers, for demonstration only\n",
    "tf.random.set_seed(random_state) # reproducibility\n",
    "\n",
    "# computes golden ratio for figures\n",
    "def goldenrect(h):\n",
    "    return (h * 1.618, h)\n",
    "\n",
    "def summary_clf(y_test, predicted, y_score, _labels = None):\n",
    "    print(classification_report(y_test, predicted, labels= _labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSI data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsiData(tf_keras.utils.Sequence):\n",
    "    def __init__(self, csi, labels, indices, batch_size=25, window_size=450, antennas=1):\n",
    "        self.csi = csi\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        self.batch_size = batch_size\n",
    "        self.window_size = window_size\n",
    "        self.antennas = antennas\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.indices.shape[-1] / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, batch_idx):\n",
    "        first_idx = batch_idx * self.batch_size\n",
    "        last_idx = (batch_idx + 1) * self.batch_size\n",
    "        \n",
    "        data_batch = [self.csi[x:x + self.window_size, ...] for x in range(first_idx, last_idx)]\n",
    "        labels_batch = np.transpose([self.labels[first_idx:last_idx]])\n",
    "\n",
    "        data_batch = tf.convert_to_tensor(data_batch)\n",
    "        labels_batch = tf.convert_to_tensor(labels_batch)\n",
    "\n",
    "        if self.antennas == 1:\n",
    "            data_batch = tf.expand_dims(data_batch, 3)\n",
    "            labels_batch = tf.expand_dims(labels_batch, 2)\n",
    "\n",
    "        return data_batch, labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_test_CSI_data(file_list, num_samples=12000, window_size=450, batch_size=25, antennas=1, random_state=42):\n",
    "    if antennas == 1:\n",
    "        train_csi = tf.zeros([0, 2048], dtype=tf.float32)\n",
    "        test_csi = tf.zeros([0, 2048], dtype=tf.float32)\n",
    "    else:\n",
    "        train_csi = tf.zeros([0, 2048, antennas], dtype=tf.float32)\n",
    "        test_csi = tf.zeros([0, 2048, antennas], dtype=tf.float32)\n",
    "\n",
    "    train_labels = tf.zeros([0], dtype=tf.int32)\n",
    "    test_labels = tf.zeros([0], dtype=tf.int32)\n",
    "    train_indices = tf.zeros([0], dtype=tf.int32)\n",
    "    test_indices = tf.zeros([0], dtype=tf.int32)\n",
    "\n",
    "    train_num_samples = math.floor(num_samples * 0.8)\n",
    "    test_num_samples = num_samples - train_num_samples\n",
    "\n",
    "    for file in file_list:\n",
    "        # Load CSI data from MATLAB file\n",
    "        mat = sio.loadmat(file)      # WARNING This code does not handle exceptions for simplicity...\n",
    "        data = np.array(mat['csi'])  # ...exceptions would require keeping track of indices\n",
    "        if antennas == 1:\n",
    "            data = data[range(num_samples), ..., int(antenna)]\n",
    "        data = np.round(np.abs(data))\n",
    "        train_index_offset = train_csi.shape[0]\n",
    "        test_index_offset = test_csi.shape[0]\n",
    "        activity_label = file_list.index(file)  # Labels depend on file index \n",
    "\n",
    "        train_data, test_data = train_test_split(data, test_size=0.2, random_state=random_state, shuffle=True)\n",
    "        \n",
    "        # Cast CSI data into temporary TF tensors for building the dataset\n",
    "        tmp_train_csi = tf.convert_to_tensor(train_data, dtype=tf.float32)\n",
    "        tmp_train_labels = tf.convert_to_tensor(activity_label * np.ones(train_num_samples - window_size), dtype=tf.int32)\n",
    "        tmp_train_indices = tf.convert_to_tensor(tf.range(train_index_offset, train_index_offset + train_num_samples - window_size), dtype=tf.int32)\n",
    "\n",
    "        # Concatenate to the previous tensors\n",
    "        train_csi = tf.concat([train_csi, tmp_train_csi], axis=0)\n",
    "        train_labels = tf.concat([train_labels, tmp_train_labels], axis=0)\n",
    "        train_indices = tf.concat([train_indices, tmp_train_indices], axis=0)\n",
    "\n",
    "        # Cast CSI data into temporary TF tensors for building the dataset\n",
    "        tmp_test_csi = tf.convert_to_tensor(test_data, dtype=tf.float32)\n",
    "        tmp_test_labels = tf.convert_to_tensor(activity_label * np.ones(test_num_samples - window_size), dtype=tf.int32)\n",
    "        tmp_test_indices = tf.convert_to_tensor(tf.range(test_index_offset, test_index_offset + test_num_samples - window_size), dtype=tf.int32)\n",
    "\n",
    "        # Concatenate to the previous tensors\n",
    "        test_csi = tf.concat([test_csi, tmp_test_csi], axis=0)\n",
    "        test_labels = tf.concat([test_labels, tmp_test_labels], axis=0)\n",
    "        test_indices = tf.concat([test_indices, tmp_test_indices], axis=0)\n",
    "        \n",
    "    # Normalize the CSI dataset\n",
    "    if antennas == 1:\n",
    "        train_csi = tf.math.divide(train_csi, tf.math.reduce_max(train_csi, axis=(0, 1)))\n",
    "        test_csi = tf.math.divide(test_csi, tf.math.reduce_max(test_csi, axis=(0, 1)))\n",
    "    else:\n",
    "        train_csi = tf.math.divide(train_csi, tf.math.reduce_max(train_csi, axis=(0, 1, 2)))\n",
    "        test_csi = tf.math.divide(test_csi, tf.math.reduce_max(test_csi, axis=(0, 1, 2)))\n",
    "\n",
    "    train_data = CsiData(train_csi, train_labels, train_indices, batch_size=batch_size, window_size=window_size, antennas=antennas)\n",
    "    test_data = CsiData(test_csi, test_labels, test_indices, batch_size=batch_size, window_size=window_size, antennas=antennas)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf_keras.layers.Layer):\n",
    "    \"\"\"Takes a couple (z_mean, z_log_var) to draw a sample z from the latent space.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf_keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "def create_csi_encoder(input_shape, latent_dim):\n",
    "    encoder_inputs = tf_keras.Input(shape=input_shape)\n",
    "    x = tf_keras.layers.Conv2D(32, (5, 8), activation='relu', strides=(5, 8), padding='valid')(encoder_inputs)\n",
    "    x = tf_keras.layers.Conv2D(32, (5, 8), activation='relu', strides=(5, 8), padding='valid')(x)\n",
    "    x = tf_keras.layers.Conv2D(32, (2, 4), activation='relu', strides=(2, 4), padding='valid')(x)\n",
    "    x = tf_keras.layers.Flatten()(x)\n",
    "    x = tf_keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "    z_mean = tf_keras.layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = tf_keras.layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    return tf_keras.Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "\n",
    "def create_csi_decoder(input_shape, latent_dim, out_filter):\n",
    "    decoder_inputs = tf_keras.Input(shape=(latent_dim,))\n",
    "    x = tf_keras.layers.Dense(math.prod(input_shape), activation='relu')(decoder_inputs)\n",
    "    x = tf_keras.layers.Reshape(input_shape)(x)\n",
    "    x = tf_keras.layers.Conv2DTranspose(32, (2, 4), activation='relu', strides=(2, 4), padding='same')(x)\n",
    "    x = tf_keras.layers.Conv2DTranspose(32, (5, 8), activation='relu', strides=(5, 8), padding='same')(x)\n",
    "    x = tf_keras.layers.Conv2DTranspose(32, (5, 8), activation='relu', strides=(5, 8), padding='same')(x)\n",
    "    decoder_outputs = tf_keras.layers.Conv2DTranspose(out_filter, out_filter, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    return tf_keras.Model(decoder_inputs, decoder_outputs, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf_keras.Model):\n",
    "    def __init__(self, enc_input_shape=(450, 2048, 1), dec_input_shape=(9, 8, 32), latent_dim=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = create_csi_encoder(enc_input_shape, latent_dim)\n",
    "        self.decoder = create_csi_decoder(dec_input_shape, latent_dim, enc_input_shape[-1])\n",
    "        self.total_loss_tracker = tf_keras.metrics.Mean(name='total_loss')\n",
    "        self.reconstruction_loss_tracker = tf_keras.metrics.Mean(name='reconstruction_loss')\n",
    "        self.kl_loss_tracker = tf_keras.metrics.Mean(name='kl_loss')\n",
    "\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf_keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'reconstruction_loss': self.reconstruction_loss_tracker.result(),\n",
    "            'kl_loss': self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vae_encoder(vae, source):\n",
    "    #Use the VAE to process CSI data\n",
    "    z_data = np.zeros([0, 4])\n",
    "    z_labels = np.zeros([0])\n",
    "\n",
    "    for (data, labels) in source:\n",
    "        labels = tf.squeeze(labels)\n",
    "        z_mean, z_log_var, _ = vae.encoder.predict(data, verbose=0)\n",
    "        z_tmp = np.concatenate([z_mean, z_log_var], axis=1)\n",
    "        z_data = np.concatenate([z_data, z_tmp], axis=0)\n",
    "        z_labels = np.concatenate([z_labels, labels.numpy().ravel()], axis=0)\n",
    "        \n",
    "    return z_data, z_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f'./{folder_name}/' + 'cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "checkpoint_cb = tf_keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only=True)\n",
    "early_stopping_cb = tf_keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "csv_logger_cb = tf_keras.callbacks.CSVLogger(f'./{folder_name}/model_history_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_components(data, target, directory=base_directory, saveGraph=False, plotGraph=True):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    #Apply PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(data)\n",
    "\n",
    "    var_cumulative = np.cumsum(pca.explained_variance_ratio_)*100\n",
    "\n",
    "    #finds PCs that explain 95% of the variance\n",
    "    num_components = np.argmax(var_cumulative > target) + 1\n",
    "    print(f\"Number of components explaining {target}% variance: \"+ str(num_components))\n",
    "\n",
    "    if plotGraph:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title('Cumulative Explained Variance explained by the components')\n",
    "        plt.ylabel('Cumulative Explained variance')\n",
    "        plt.xlabel('Principal components')\n",
    "        plt.axvline(x=num_components, color=\"r\", linestyle=\"--\")\n",
    "        plt.axhline(y=target, color=\"r\", linestyle=\"--\")\n",
    "        plt.plot(range(1, pca.n_components_ + 1), var_cumulative, marker='o', linestyle='--')\n",
    "        plt.grid()\n",
    "        if (saveGraph):\n",
    "            graph_path = os.path.join(directory, 'var_cumulative_x_component.png')\n",
    "            plt.savefig(graph_path)\n",
    "            print(\"Graph saved in: \", graph_path)\n",
    "        plt.show()\n",
    "\n",
    "    return num_components\n",
    "\n",
    "def analyze_PCA(data, n_components, directory=base_directory, saveGraph=False, plotGraph=True):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_data = pca.fit_transform(data)\n",
    "\n",
    "    reduced_df = pd.DataFrame(data=reduced_data, columns=[f'PC{i}' for i in range(n_components)])\n",
    "\n",
    "    #Explained variance ratio\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    print(\"Explained variance ratio:\", explained_variance_ratio)\n",
    "\n",
    "    #Cumulative explained variance\n",
    "    cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "    print(\"Final Cumulative Explained Variance:\", cumulative_explained_variance[-1])\n",
    "\n",
    "    if (plotGraph):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, n_components + 1), cumulative_explained_variance, marker='o', linestyle='--')\n",
    "        plt.title('Cumulative Explained Variance by PCA Components')\n",
    "        plt.xlabel('Number of Principal Components')\n",
    "        plt.ylabel('Cumulative Explained Variance')\n",
    "        plt.grid()\n",
    "        if (saveGraph):\n",
    "            graph_path = os.path.join(directory, 'cumulative_explained_variance.png')\n",
    "            plt.savefig(graph_path)\n",
    "            print(\"Graph saved in: \", graph_path)\n",
    "        plt.show()\n",
    "    \n",
    "    return reduced_df, pca\n",
    "\n",
    "def reconstruct_data(df, pca, columns):\n",
    "    df_reconstructed = pca.inverse_transform(df.values)\n",
    "    df_reconstructed = pd.DataFrame(df_reconstructed, columns=columns)    \n",
    "    return df_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lloyd_max_quantization(data, num_levels=16, max_iter=100, delta=1e-6):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    clusters = np.linspace(min_val, max_val, num_levels) #Uniformly spaced \n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        thresholds = (clusters[:-1] + clusters[1:]) / 2 #Defines intervals of clusters\n",
    "        indices = np.digitize(data, thresholds) #Assign each data point to a cluster\n",
    "        \n",
    "        new_clusters = np.array([data[indices == i].mean() for i in range(num_levels)]) #Update clusters to better represent the data\n",
    "        \n",
    "        empty_clusters = np.isnan(new_clusters) #Restore previous cluster if empty\n",
    "        new_clusters[empty_clusters] = clusters[empty_clusters] \n",
    "\n",
    "        #stop if changes between iterations are small\n",
    "        if np.max(np.abs(new_clusters - clusters)) < delta:\n",
    "            break\n",
    "\n",
    "        clusters = new_clusters\n",
    "\n",
    "    #Quantize the data based on the final clusters\n",
    "    quantized_data = clusters[indices]\n",
    "\n",
    "    return quantized_data, clusters, thresholds\n",
    "\n",
    "def dequantize_lloyd_max(quantized_data, clusters, thresholds):\n",
    "    indices = np.digitize(quantized_data, thresholds, right=True)\n",
    "    return clusters[indices]\n",
    "\n",
    "def apply_quantization(reduced_df, lvls):\n",
    "    df_quantized = reduced_df.apply(lambda col: lloyd_max_quantization(col.values, num_levels=lvls)[0])\n",
    "    return df_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bits_needed(source, verbose=True):\n",
    "    data = source.copy()\n",
    "    window_size = 450\n",
    "    bits_needed_window = {}\n",
    "    total_bits = 0\n",
    "    total_symbols = 0\n",
    "    \n",
    "    for index in range(0, len(data), window_size):\n",
    "        bits_needed = {}\n",
    "        data_window = data.iloc[index : index + window_size] \n",
    "        window_total_bits = 0\n",
    "        window_total_symbols = 0\n",
    "        \n",
    "        for col in data_window.columns:\n",
    "            num_symbols = len(data_window[col].unique())\n",
    "            total_num_symbols = len(data_window[col])\n",
    "            \n",
    "            if num_symbols > 1:\n",
    "                bits_needed[col] = np.ceil(np.log2(num_symbols)).astype(int)  # Number of bits to represent each symbol\n",
    "            else:\n",
    "                bits_needed[col] = 1  # If only one unique symbol\n",
    "            if verbose: print(f\"Column: {col}, Bits needed: {bits_needed[col]} bits\")\n",
    "            \n",
    "            # bits this column in the window\n",
    "            column_bits = bits_needed[col] * total_num_symbols\n",
    "            window_total_bits += column_bits\n",
    "            window_total_symbols += total_num_symbols\n",
    "\n",
    "        bits_needed_window[index] = window_total_bits\n",
    "        if verbose: print(f\"Window: {index}, Average bits needed: {window_total_bits:.2f} bits\")\n",
    "    \n",
    "        total_bits += window_total_bits\n",
    "        total_symbols += window_total_symbols\n",
    "\n",
    "    average_bits_per_symbol = total_bits / total_symbols if total_symbols > 0 else 0\n",
    "    average_bits_per_window = np.mean(list(bits_needed_window.values())).round(2)\n",
    "\n",
    "    #print(f\"\\nGlobal metrics:\")\n",
    "    print(f\"Average bits per symbol: {average_bits_per_symbol:.2f} bits\")\n",
    "    print(f\"Average bits per window: {average_bits_per_window:.2f} bits\")\n",
    "    print(f\"Bits for the whole dataset: {total_bits:.2f} bits\")\n",
    "\n",
    "    return average_bits_per_symbol.round(2), average_bits_per_window, total_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_needed(source, num_lvls=-1):\n",
    "    data = source.copy()\n",
    "    window_size = 450\n",
    "    num_features = len(data.columns)\n",
    "    bits_needed_unique = {}\n",
    "    avg_bits_needed = {}\n",
    "    bits_needed_window = {}\n",
    "    total_bits_needed_dataset = 0\n",
    "\n",
    "    for index in range(0, len(data), window_size):\n",
    "        data_window = data.iloc[index : index + window_size] \n",
    "        for col in data_window.columns:\n",
    "            num_symbols = len(data_window[col].unique())\n",
    "            if num_lvls > 0:\n",
    "                bits_needed_unique[col] = np.ceil(np.log2(num_lvls)).astype(int)\n",
    "                #print(f\"Column: {col}, Bits needed: {bits_needed_unique[col]} bits (num levels: {num_lvls})\")\n",
    "            else:\n",
    "                bits_needed_unique[col] = np.ceil(np.log2(num_symbols)).astype(int)\n",
    "                \n",
    "        avg_bits_needed[index] = np.mean(list(bits_needed_unique.values())).round(2)\n",
    "        bits_needed_window[index] = sum(bits_needed_unique.values())\n",
    "        total_bits_needed_dataset += sum(bits_needed_unique.values())\n",
    "\n",
    "    bits_needed = np.mean(list(avg_bits_needed.values())).round(2)\n",
    "    bits_needed_window = np.mean(list(bits_needed_window.values())).round(2)\n",
    "\n",
    "    return bits_needed, bits_needed_window, total_bits_needed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "The VAE has been trained without any information about the target classes; it just tries to minimize reconstruction loss + KL loss.\n",
    "\n",
    "The Encoder in the VAE maps sequences of CSI into **2 Gaussian variables** with parameters (z_mean, z_log_var).\n",
    "\n",
    "More in detail, from the dataset we load `data` and `labels`.\n",
    "- `data`: every element is a 4-tuple with the values (z1_mean, z2_mean, z1_log_var, z2_log_var)\n",
    "- `labels`: 5 different classes, labelled with integers from 0 to 4 (0 = walk, 1 = run, 2 = jump, 3 = sit, 4 = empty)\n",
    "\n",
    "Available datasets:\n",
    "- `single_antenna`: data of just antenna 1, normalized wrt to the maximum value over the entire dataset (four antennas are available, numbered from 0 to 3)\n",
    "- `four_antennas`: data of the four antennas fused together, normalized wrt to the maximum value over the entire dataset\n",
    "- `four_antennas_latent_space_3`: same as `four_antennas`, but the CSI is mapped onto 3 Gaussian variables; hence, every element in `data` is a 6-tuple with the values (z1_mean, z2_mean, z3_mean, z1_log_var, z2_log_var, z3_log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_classes = [\"Walk\", \"Run\", \"Jump\", \"Sit\", \"Empty\"]\n",
    "base_directory = './results'\n",
    "os.makedirs(base_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(directory, scaler=None):\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    # features columns\n",
    "    fcolumns = ['mu1','mu2','sigma1','sigma2']\n",
    "    \n",
    "    # check which experiments we wants to load\n",
    "    with open(directory, 'rb') as f:\n",
    "        data, labels = pickle.load(f)\n",
    "\n",
    "    # labels are categoricals\n",
    "    labels = np.asarray(labels, dtype=np.int32)\n",
    "    \n",
    "    # let's load into a dataframe\n",
    "    df = pd.DataFrame(data, columns=fcolumns)\n",
    "    df['signal'] = labels\n",
    "    \n",
    "    if scaler is None:\n",
    "        # Fit scaler on training data\n",
    "        scaler = StandardScaler().fit(df[fcolumns])\n",
    "    df[fcolumns] = scaler.transform(df[fcolumns])\n",
    "    \n",
    "    X = df[fcolumns]\n",
    "    y = df['signal']\n",
    "\n",
    "    # one-hot-encoding\n",
    "    y_dummy = keras.utils.to_categorical(y)\n",
    "    \n",
    "    return X, y, y_dummy, scaler, fcolumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_annealing = 1\n",
    "num_classes = 5\n",
    "\n",
    "ep = 1.0\n",
    "class GetEpochs(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global ep\n",
    "        ep += 1\n",
    "\n",
    "def res_to_mean(ev, dim = 5):\n",
    "    return np.max(dirichlet.mean(ev.reshape(dim,)+1))\n",
    "\n",
    "def res_to_dirichlet(ev):\n",
    "    alpha = ev.reshape(2,)+1\n",
    "    S = np.sum(alpha)\n",
    "    K = 2.0\n",
    "    return dirichlet.mean(alpha), K/S\n",
    "\n",
    "def edl_accuracy(yTrue, yPred):\n",
    "    pred = K.argmax(yPred, axis=1)\n",
    "    truth = K.argmax(yTrue, axis=1)\n",
    "    match = K.reshape(K.cast(K.equal(pred, truth), \"float32\"),(-1,1))\n",
    "    return K.mean(match)\n",
    "\n",
    "def load_edl_experiment(name):\n",
    "    keras.models.load_model(name)\n",
    "\n",
    "def plot_res_beta(ev):\n",
    "    alpha = ev.reshape(2,)+1\n",
    "    plt.figure(figsize=(16,9))\n",
    "    x = np.linspace(0,1,1000)\n",
    "    plt.plot(x, beta.pdf(x, alpha[1], alpha[0]))\n",
    "    x1, x2 = beta.interval(0.95, alpha[1], alpha[0])\n",
    "    areaplot = np.multiply(beta.pdf(x, alpha[1],alpha[0]), rect(x,x1, x2))\n",
    "    plt.fill_between(x, 0, areaplot, alpha=0.5)\n",
    "\n",
    "def results_test(num_components, num_levels, train_dir, test_dir):\n",
    "    X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dir)\n",
    "    X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dir, scaler)\n",
    "    model_directory = os.path.join(base_directory, f'{num_components}_components/models/{num_components}components_{num_levels}lvls_Keras_Model.keras')\n",
    "    \n",
    "    mlp_edl = keras.models.load_model(model_directory, compile=False)\n",
    "    mlp_edl_scores = np.array([res_to_mean(r, dim=5) for r in mlp_edl.predict(X_test)])\n",
    "    y_predictions_edl = np.array(tf.argmax(mlp_edl.predict(X_test), axis=1))\n",
    "\n",
    "    print(summary_clf(y_test, y_predictions_edl, mlp_edl_scores))\n",
    "    accuracy = accuracy_score(y_test, y_predictions_edl)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_predictions_edl)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=semantic_classes)\n",
    "    cmdisp = disp.plot(cmap=\"cividis\")\n",
    "    CM_directory = os.path.join(base_directory, f'{num_components}_components/CMs/{num_components}components_{num_levels}lvls_ConfusionMatrix.png')\n",
    "    os.makedirs(os.path.dirname(CM_directory), exist_ok=True)\n",
    "    cmdisp.figure_.savefig(CM_directory, bbox_inches='tight')\n",
    "\n",
    "    return round(accuracy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_edl_experiment(name, num_components, num_levels, _X_train, _y_train_dummy):\n",
    "\n",
    "    model_edl = None\n",
    "    num_classes = 5\n",
    "    \n",
    "    if name == \"Delayed-Fusing\":\n",
    "        num_epochs_annealing = 3\n",
    "        batch_size = 128\n",
    "        lr = 0.01\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5, activation='softplus'))\n",
    "\n",
    "    elif name == \"Early-Fusing\":\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 128\n",
    "        lr = 0.001\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(4,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5,activation='softplus'))\n",
    "\n",
    "    elif name == \"Early-Fusing3\":\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 128\n",
    "        lr = 0.01\n",
    "        epochs = 50\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(6,)))\n",
    "        model_edl.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "        model_edl.add(tf.keras.layers.Dense(units=5,activation='softplus'))\n",
    "\n",
    "    else:\n",
    "        num_epochs_annealing = 22\n",
    "        batch_size = 64\n",
    "        lr = 0.0001\n",
    "        epochs = 100\n",
    "        model_edl = tf.keras.models.Sequential()\n",
    "        model_edl.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "        model_edl.add(tf.keras.layers.Dropout(0.5))\n",
    "        model_edl.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "        model_edl.add(tf.keras.layers.Dropout(0.5))\n",
    "        model_edl.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "        model_edl.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    def KL(alpha):\n",
    "        beta=K.constant(np.ones((1,num_classes)),dtype=\"float32\")\n",
    "        S_alpha = K.sum(alpha,axis=1,keepdims=True)\n",
    "        S_beta = K.sum(beta,axis=1,keepdims=True)\n",
    "        lnB = tf.math.lgamma(S_alpha) - K.sum(tf.math.lgamma(alpha),axis=1,keepdims=True)\n",
    "        lnB_uni = K.sum(tf.math.lgamma(beta),axis=1,keepdims=True) - tf.math.lgamma(S_beta)\n",
    "\n",
    "        dg0 = tf.math.digamma(S_alpha)\n",
    "        dg1 = tf.math.digamma(alpha)\n",
    "\n",
    "        return K.sum((alpha - beta)*(dg1-dg0),axis=1,keepdims=True) + lnB + lnB_uni\n",
    "\n",
    "    # Loss function considering the expected squared error and the KL divergence\n",
    "    def mse_loss(yTrue,yPred):\n",
    "        alpha = yPred + 1\n",
    "        S = K.sum(alpha, axis=1, keepdims=True)\n",
    "        m = alpha / S\n",
    "\n",
    "        # A + B minimises the sum of squared loss, see discussion in EDL paper for the derivation\n",
    "        A = K.sum((yTrue-m)**2, axis=1, keepdims=True)\n",
    "        B = K.sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True)\n",
    "\n",
    "        # the lambda_t parameter, in this case min{1, t/10} with t the number of epochs\n",
    "        ll = min(1.0, float(ep/float(num_epochs_annealing)))\n",
    "        \n",
    "        alp = yPred*(1-yTrue) + 1 \n",
    "        C =  ll * KL(alp)\n",
    "\n",
    "        return A + B + C\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model_edl.compile(loss=mse_loss, optimizer=optimizer, metrics=[edl_accuracy])\n",
    "\n",
    "    model_edl.fit(_X_train, _y_train_dummy,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      verbose=1,\n",
    "      shuffle=False)\n",
    "\n",
    "    model_directory = os.path.join(base_directory, f'{num_components}_components/models/{num_components}components_{num_levels}lvls_Keras_Model.keras')\n",
    "    os.makedirs(os.path.dirname(model_directory), exist_ok=True)\n",
    "    model_edl.save(model_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(range(1, 11)) + list(range(15, 41, 5)) + list(range(50, 101, 10))\n",
    "levels = [2**i for i in range(1, 8)]\n",
    "\n",
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "csi_generator = CsiDataGenerator(file_list, batch_size=BATCH_SIZE, antenna_select=antenna)\n",
    "\n",
    "csi_data = csi_generator.csi.numpy()\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "\n",
    "df_csi_data_original = pd.DataFrame(csi_data, columns=csi_subcarriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_components in components:\n",
    "    print(f\"-------------- {num_components} components --------------\")\n",
    "    directory = f'./results/{num_components}_components/dumps'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    df_csi_data = df_csi_data_original.copy()\n",
    "    #Apply PCA\n",
    "    \n",
    "    df_reduced, pca = analyze_PCA(df_csi_data, num_components, directory=directory, saveGraph=True, plotGraph=True)\n",
    "\n",
    "    for num_levels in levels:\n",
    "        print(f\"-------------- {num_components} components w/ {num_levels} lvls --------------\")\n",
    "        #Quantize the data\n",
    "        df_train_quantized = apply_quantization(df_reduced, num_levels)\n",
    "\n",
    "        #Reconstruct the data\n",
    "        df_train_reconstructed = reconstruct_data(df_train_quantized, pca, csi_subcarriers)\n",
    "        df_train_reconstructed = df_train_reconstructed.to_numpy()\n",
    "        reconstructed_train_data = tf.convert_to_tensor(df_train_reconstructed)\n",
    "        csi_generator.csi = reconstructed_train_data\n",
    "\n",
    "        #Use the VAE to process CSI data\n",
    "        z_data = np.zeros([0, 4])\n",
    "        z_labels = np.zeros([0])\n",
    "\n",
    "        vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "        vae.compile(optimizer=keras.optimizers.Adam())\n",
    "        vae.load_weights(f'./{folder_name}/weights_vae').expect_partial()\n",
    "\n",
    "        for (data, labels) in csi_generator:\n",
    "            labels = tf.squeeze(labels)\n",
    "            z_mean, z_log_var, _ = vae.encoder.predict(data, verbose=0)\n",
    "            z_tmp = np.concatenate([z_mean, z_log_var], axis=1)\n",
    "            z_data = np.concatenate([z_data, z_tmp], axis=0)\n",
    "            z_labels = np.concatenate([z_labels, labels], axis=0)\n",
    "\n",
    "        # Store the latent space representation of CSI data to file.\n",
    "        sub_dir=os.path.join(directory, f'{num_components}components_{num_levels}lvls_single_antenna_{antenna}.pkl')\n",
    "        with open(sub_dir, 'wb') as f:\n",
    "            pickle.dump([z_data, z_labels], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for num_components in components:\n",
    "    for num_levels in levels:\n",
    "        print(f\"------------------------- Running experiment for {num_components} components with {num_levels} levels -------------------------\")\n",
    "        dump_directory =  os.path.join(base_directory, f'{num_components}_components/dumps/{num_components}components_{num_levels}lvls_single_antenna_{antenna}.pkl')\n",
    "        \n",
    "        # Load data\n",
    "        X_train, X_test, y_train, y_test, y_train_dummy, y_test_dummy, scaler, df, fcolumns = load_experiment_reconstructed(dump_directory)\n",
    "        \n",
    "        # Run model\n",
    "        name = \"No-Fused-1\"\n",
    "        run_edl_experiment(name, num_components, num_levels, X_train, y_train_dummy)\n",
    "\n",
    "        # Test model\n",
    "        accuracy = results_test(num_components, num_levels, dump_directory)\n",
    "        results.append(\n",
    "            {\n",
    "                \"num_components\": num_components,\n",
    "                \"num_levels\": num_levels,\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "        \n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results_csv/results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    #if num_components not in components:\n",
    "    #    continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE', linewidth=3)\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Bits per symbol')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join('accuracy_bit_comparison[BxS][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "#components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    if num_components not in components:\n",
    "        continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_win_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_win_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE')\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Average bits per window')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join('accuracy_bit_comparison[BxW][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(range(1, 11)) + list(range(15, 41, 5))\n",
    "components = (range(50, 101, 10))\n",
    "levels = [2**i for i in range(1, 8)]\n",
    "bit_results = []\n",
    "\n",
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "csi_generator = CsiDataGenerator(file_list, batch_size=BATCH_SIZE, antenna_select=antenna)\n",
    "\n",
    "csi_data = csi_generator.csi.numpy()\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "\n",
    "df_csi_data_original = pd.DataFrame(csi_data, columns=csi_subcarriers)\n",
    "\n",
    "OG_bits, OG_win_bits,total_OG_bits = bits_needed(df_csi_data_original)\n",
    "print(f\"Bits needed: {OG_bits} bits\")\n",
    "print(f\"AvgBits needed per window: {OG_win_bits} bits\")\n",
    "print(f\"Total Bits needed: {total_OG_bits} bits\")\n",
    "\n",
    "for num_components in components:\n",
    "    print(f\"-------------- {num_components} components ----------------------\")\n",
    "    directory = f'./results/{num_components}_components/dumps'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    df_csi_data = df_csi_data_original.copy()\n",
    "\n",
    "    #Apply PCA\n",
    "    df_reduced, pca = analyze_PCA(df_csi_data, num_components, directory=directory, plotGraph=False)\n",
    "    \n",
    "    print (f\"DF_CSI_DATA\")\n",
    "    #PCA_avg_bits_per_symbol, PCA_avg_bits_per_window, PCA_total_bits = compute_bits_needed(df_reduced, verbose=False)\n",
    "    PCA_bits, PCA_win_bits,total_PCA_bits = bits_needed(df_reduced)\n",
    "    print(f\"Bits needed: {PCA_bits} bits\")\n",
    "    print(f\"AvgBits needed per window: {PCA_win_bits} bits\")\n",
    "    print(f\"Total Bits needed: {total_PCA_bits} bits\")\n",
    "\n",
    "    for num_levels in levels:\n",
    "        print(f\"-------------- {num_components} components {num_levels} lvls --------------\")\n",
    "        #Quantize the data\n",
    "        df_train_quantized = apply_quantization(df_reduced, num_levels)\n",
    "        print (f\"DF_QUANTIZED\")\n",
    "        #QT_avg_bits_per_symbol, QT_avg_bits_per_window, QT_total_bits = compute_bits_needed(df_quantized, verbose=False)\n",
    "        QT_bits, QT_win_bits, total_QT_bits = bits_needed(df_train_quantized, num_levels)\n",
    "        print(f\"Bits needed: {QT_bits} bits\")\n",
    "        print(f\"AvgBits needed per window: {QT_win_bits} bits\")\n",
    "        print(f\"Total Bits needed: {total_QT_bits} bits\")\n",
    "\n",
    "        #Reconstruct the data\n",
    "        df_train_reconstructed = reconstruct_data(df_train_quantized, pca, csi_subcarriers)\n",
    "        print (f\"DF_RECONSTRUCTED\")\n",
    "        #REC_avg_bits_per_symbol, REC_avg_bits_per_window, REC_total_bits = compute_bits_needed(df_reconstructed, verbose=False)\n",
    "        REC_bits, REC_win_bits, total_REC_bits = bits_needed(df_train_reconstructed)\n",
    "        print(f\"Bits needed: {REC_bits} bits\")\n",
    "        print(f\"AvgBits needed per window: {REC_win_bits} bits\")\n",
    "        print(f\"Total Bits needed: {total_REC_bits} bits\")\n",
    "        \n",
    "        df_train_reconstructed = df_train_reconstructed.to_numpy()\n",
    "        reconstructed_train_data = tf.convert_to_tensor(df_train_reconstructed)\n",
    "        csi_generator.csi = reconstructed_train_data\n",
    "\n",
    "        bit_results.append({\n",
    "            'num_components': num_components,\n",
    "            'num_levels': num_levels,\n",
    "            'OG_bits': OG_bits,\n",
    "            'PCA_bits': PCA_bits,\n",
    "            'QT_bits': QT_bits,\n",
    "            'REC_bits': REC_bits,\n",
    "            'OG_win_bits': OG_win_bits,\n",
    "            'PCA_win_bits': PCA_win_bits,\n",
    "            'QT_win_bits': QT_win_bits,\n",
    "            'REC_win_bits': REC_win_bits,\n",
    "            'total_OG_bits': total_OG_bits,\n",
    "            'total_PCA_bits': total_PCA_bits,\n",
    "            'total_QT_bits': total_QT_bits,\n",
    "            'total_REC_bits': total_REC_bits\n",
    "        })\n",
    "\n",
    "bit_results = pd.DataFrame(bit_results)\n",
    "bit_results.to_csv(f'./results_csv/bit_results_single_antenna2_{antenna}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Output Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "csi_generator = CsiDataGenerator(file_list, batch_size=BATCH_SIZE, antenna_select=antenna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the VAE to process CSI data\n",
    "z_data = np.zeros([0, 4])\n",
    "z_labels = np.zeros([0])\n",
    "\n",
    "vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.load_weights(f'./{folder_name}/weights_vae').expect_partial()\n",
    "\n",
    "for (data, labels) in csi_generator:\n",
    "    labels = tf.squeeze(labels)\n",
    "    z_mean, z_log_var, _ = vae.encoder.predict(data, verbose=0)\n",
    "    z_tmp = np.concatenate([z_mean, z_log_var], axis=1)\n",
    "    z_data = np.concatenate([z_data, z_tmp], axis=0)\n",
    "    z_labels = np.concatenate([z_labels, labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f'./results/0_components/dumps'\n",
    "bit_results = []\n",
    "\n",
    "df_z_data = pd.DataFrame(z_data, columns=[f'z_mean_{i}' for i in range(2)] + [f'z_log_var_{i}' for i in range(2)])\n",
    "\n",
    "for lvl in levels:\n",
    "    print(f\"-------------- {lvl} lvls --------------\")\n",
    "    sub_dir=os.path.join(directory, f'{lvl}lvls_single_antenna_{antenna}.pkl')\n",
    "\n",
    "    df_train_quantized = apply_quantization(df_z_data, lvl)\n",
    "    print (f\"DF_QUANTIZED\")\n",
    "        #QT_avg_bits_per_symbol, QT_avg_bits_per_window, QT_total_bits = compute_bits_needed(df_quantized, verbose=False)\n",
    "    QT_bits, QT_win_bits, total_QT_bits = bits_needed(df_train_quantized, lvl)\n",
    "    print(f\"Bits needed: {QT_bits} bits\")\n",
    "    print(f\"AvgBits needed per window: {QT_win_bits} bits\")\n",
    "    print(f\"Total Bits needed: {total_QT_bits} bits\")\n",
    "\n",
    "    z_data = df_train_quantized.to_numpy()\n",
    "\n",
    "#    with open(sub_dir, 'wb') as f:\n",
    "#       pickle.dump([z_data, z_labels], f)\n",
    "\n",
    "    bit_results.append({\n",
    "            'num_levels': lvl,\n",
    "            'QT_bits': QT_bits,\n",
    "            'QT_win_bits': QT_win_bits,\n",
    "            'total_QT_bits': total_QT_bits,\n",
    "        })\n",
    "\n",
    "bit_results = pd.DataFrame(bit_results)\n",
    "bit_results.to_csv(f'./results/csv/VAE_bit_results_single_antenna_{antenna}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "csi_generator = CsiDataGenerator(file_list, batch_size=BATCH_SIZE, antenna_select=antenna)\n",
    "\n",
    "target = 90\n",
    "num_levels = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_data = csi_generator.csi.numpy()\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "\n",
    "df_csi_data = pd.DataFrame(csi_data, columns=csi_subcarriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = find_n_components(df_csi_data, target, plotGraph=False)\n",
    "df_reduced, pca = analyze_PCA(df_csi_data, num_components, plotGraph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_quantized = apply_quantization(df_reduced, num_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_reconstructed = reconstruct_data(df_train_quantized, pca, csi_subcarriers)\n",
    "\n",
    "df_train_reconstructed = df_train_reconstructed.to_numpy()\n",
    "reconstructed_train_data = tf.convert_to_tensor(df_train_reconstructed)\n",
    "\n",
    "print('Original csi data shape:', df_csi_data.shape)\n",
    "print('PCA df shape:', df_reduced.shape)\n",
    "print('Reconstructed csi data shape:', reconstructed_train_data.shape)\n",
    "\n",
    "csi_generator.csi = reconstructed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the VAE to process CSI data\n",
    "z_data = np.zeros([0, 4])\n",
    "z_labels = np.zeros([0])\n",
    "\n",
    "vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.load_weights(f'./{folder_name}/weights_vae').expect_partial()\n",
    "\n",
    "for (data, labels) in csi_generator:\n",
    "    labels = tf.squeeze(labels)\n",
    "    z_mean, z_log_var, _ = vae.encoder.predict(data, verbose=0)\n",
    "    z_tmp = np.concatenate([z_mean, z_log_var], axis=1)\n",
    "    z_data = np.concatenate([z_data, z_tmp], axis=0)\n",
    "    z_labels = np.concatenate([z_labels, labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'single_antenna_{antenna}', 'wb') as f:\n",
    "    pickle.dump([z_data, z_labels], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Comprehenisve Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(range(1, 11)) + list(range(15, 41, 5)) + list(range(50, 101, 10))\n",
    "components = [1, 2, 3, 4, 10, 20, 30, 40, 50, 100]\n",
    "levels = [2**i for i in range(1, 8)]\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "\n",
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "\n",
    "train_data, test_data = load_split_train_test_CSI_data(file_list, batch_size=BATCH_SIZE, antennas=ANTENNAS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "df_csi_train = pd.DataFrame(train_data.csi.numpy(), columns=csi_subcarriers)\n",
    "df_csi_test = pd.DataFrame(test_data.csi.numpy(), columns=csi_subcarriers)\n",
    "\n",
    "for num_components in components:\n",
    "    print(f\"-------------- {num_components} components --------------\")\n",
    "    df_train = df_csi_train.copy()\n",
    "    df_test = df_csi_test.copy()\n",
    "    directory = f'./dumps/{num_components}_components'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    #Apply PCA\n",
    "    df_train_reduced, pca = analyze_PCA(df_train, num_components, directory=directory, saveGraph=True, plotGraph=True)\n",
    "\n",
    "    test_reduced = pca.transform(df_test)\n",
    "    df_test_reduced = pd.DataFrame(test_reduced, columns=[f'PC{i}' for i in range(num_components)])\n",
    "\n",
    "    for num_levels in levels:\n",
    "        print(f\"-------------- {num_components} components w/ {num_levels} lvls --------------\")\n",
    "        filename = f'{num_levels}lvls_single_antenna_{antenna}'\n",
    "        #Quantize the data\n",
    "        df_train_quantized = apply_quantization(df_train_reduced, num_levels)\n",
    "        df_test_quantized = apply_quantization(df_test_reduced, num_levels)\n",
    "\n",
    "        #Reconstruct the data\n",
    "        df_train_reconstructed = reconstruct_data(df_train_quantized, pca, csi_subcarriers)\n",
    "        df_train_reconstructed = df_train_reconstructed.to_numpy()\n",
    "        reconstructed_train_data = tf.convert_to_tensor(df_train_reconstructed, dtype=tf.float32)\n",
    "        train_data.csi = reconstructed_train_data\n",
    "\n",
    "        df_test_reconstructed = reconstruct_data(df_test_quantized, pca, csi_subcarriers)\n",
    "        df_test_reconstructed = df_test_reconstructed.to_numpy()\n",
    "        reconstructed_test_data = tf.convert_to_tensor(df_test_reconstructed, dtype=tf.float32)\n",
    "        test_data.csi = reconstructed_test_data\n",
    "\n",
    "        vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "        vae.compile(optimizer=tf_keras.optimizers.Adam())\n",
    "        vae.load_weights(f'./{folder_name}/train_weights_vae').expect_partial()\n",
    "        \n",
    "        print(\"Encoding train data...\")\n",
    "        z_data_train, z_labels_train = apply_vae_encoder(vae, train_data)\n",
    "        \n",
    "        print(\"Encoding test data...\")\n",
    "        z_data_test, z_labels_test = apply_vae_encoder(vae, test_data)\n",
    "\n",
    "        train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "        os.makedirs(os.path.dirname(train_dump_dir), exist_ok=True)\n",
    "        test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "        os.makedirs(os.path.dirname(test_dump_dir), exist_ok=True)\n",
    "        print(\"Saving data...\")\n",
    "        with open(train_dump_dir, 'wb') as f:\n",
    "            pickle.dump([z_data_train, z_labels_train], f)\n",
    "        with open(test_dump_dir, 'wb') as f:\n",
    "            pickle.dump([z_data_test, z_labels_test], f)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_components in components:\n",
    "    directory = f'./dumps/{num_components}_components'\n",
    "    for num_levels in levels:  \n",
    "        print(f\"-------------- {num_components} components w/ {num_levels} lvls --------------\")\n",
    "        train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "        test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "\n",
    "        X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dump_dir)\n",
    "        X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dump_dir, scaler)\n",
    "\n",
    "        name = \"No-Fused-1\"\n",
    "        run_edl_experiment(name, num_components, num_levels, X_train, y_train_dummy)\n",
    "\n",
    "        # Test model\n",
    "        accuracy = results_test(num_components, num_levels, train_dump_dir, test_dump_dir)\n",
    "        results.append(\n",
    "            {\n",
    "                \"num_components\": num_components,\n",
    "                \"num_levels\": num_levels,\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "        \n",
    "results_df = pd.DataFrame(results)\n",
    "os.makedirs('results_csv', exist_ok=True)\n",
    "results_df.to_csv('results_csv/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    #if num_components not in components:\n",
    "    #    continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE', linewidth=3)\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Bits per symbol')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "#plt.savefig(os.path.join('accuracy_bit_comparison[BxS][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.read_csv('results_csv/results.csv')\n",
    "df_bits = pd.read_csv('results_csv/bit_results_single_antenna_0.csv')\n",
    "df_VAE_accuracy = pd.read_csv('results_csv/VAE_results.csv')\n",
    "df_VAE_bits = pd.read_csv('results_csv/VAE_bit_results_single_antenna_0.csv')\n",
    "\n",
    "df_acc_bit = pd.merge(df_accuracy, df_bits, on=['num_components', 'num_levels'])\n",
    "df_VAE_acc_bit = pd.merge(df_VAE_accuracy, df_VAE_bits, on=['num_levels'])\n",
    "\n",
    "#components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25]\n",
    "components = [1, 2, 3, 4, 10]\n",
    "#components = [30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for num_components in df_acc_bit['num_components'].unique():\n",
    "    if num_components not in components:\n",
    "        continue\n",
    "    target_data = df_acc_bit[df_acc_bit['num_components'] == num_components]\n",
    "    plt.plot(target_data['QT_win_bits'], target_data['accuracy'], marker='o', linestyle='--', label=f'{num_components} components')\n",
    "plt.plot(df_VAE_acc_bit['QT_win_bits'], df_VAE_acc_bit['accuracy'], marker='o', label='Post VAE')\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\":\", label=\"max accuracy\")\n",
    "plt.title('Accuracy and Bits Comparison (quantized data)')\n",
    "plt.xlabel('Average bits per window')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "#plt.savefig(os.path.join('accuracy_bit_comparison[BxW][1-100].png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [2**i for i in range(1, 8)]\n",
    "levels = [8]\n",
    "\n",
    "file_list = [f'./dataset/S1a_{x}.mat' for x in string.ascii_uppercase[:num_activities]]\n",
    "train_data, test_data = load_split_train_test_CSI_data(file_list, batch_size=BATCH_SIZE, antennas=ANTENNAS)\n",
    "\n",
    "csi_subcarriers = [f\"Ampl_{i}\" for i in range(1024)] + [f\"Ampl_{-i}\" for i in range(1, 1025)]\n",
    "df_csi_train = pd.DataFrame(train_data.csi.numpy(), columns=csi_subcarriers)\n",
    "df_csi_test = pd.DataFrame(test_data.csi.numpy(), columns=csi_subcarriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrained_models = True\n",
    "\n",
    "if load_pretrained_models:\n",
    "    print('Loading pretrained models...')\n",
    "    \"\"\"!wget https://zenodo.org/record/7983057/files/VAE_models.zip\n",
    "    !unzip -o VAE_models.zip\n",
    "    !rm VAE_models.zip\"\"\"\n",
    "else:\n",
    "    # Train from scratch\n",
    "    #!mkdir {folder_name}\n",
    "    vae = VAE()\n",
    "    vae.compile(optimizer=tf_keras.optimizers.Adam())\n",
    "    vae.save_weights(checkpoint_path.format(epoch=0))\n",
    "    vae.fit(train_data, epochs=20, shuffle=True,\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, csv_logger_cb])\n",
    "    vae.save_weights(f'./{folder_name}/train_weights_vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "folder_name = f'models/single_antenna_{antenna}'\n",
    "\n",
    "print(f\"-------------- 0 components --------------\")\n",
    "directory = './dumps/0_components'\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "for num_levels in levels:\n",
    "    print(f\"-------------- 0 components w/ {num_levels} lvls --------------\")\n",
    "    filename = f'{num_levels}lvls_single_antenna_{antenna}'\n",
    "\n",
    "    vae = VAE(enc_input_shape=(450, 2048, ANTENNAS))\n",
    "    vae.compile(optimizer=tf_keras.optimizers.Adam())\n",
    "    vae.load_weights(f'./{folder_name}/train_weights_vae').expect_partial()\n",
    "    \n",
    "    print(\"Encoding train data...\")\n",
    "    z_data_train, z_labels_train = apply_vae_encoder(vae, train_data)\n",
    "    \n",
    "    print(\"Encoding test data...\")\n",
    "    z_data_test, z_labels_test = apply_vae_encoder(vae, test_data)\n",
    "\n",
    "    train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "    os.makedirs(os.path.dirname(train_dump_dir), exist_ok=True)\n",
    "    test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "    os.makedirs(os.path.dirname(test_dump_dir), exist_ok=True)\n",
    "    with open(train_dump_dir, 'wb') as f:\n",
    "        pickle.dump([z_data_train, z_labels_train], f)\n",
    "    with open(test_dump_dir, 'wb') as f:\n",
    "        pickle.dump([z_data_test, z_labels_test], f)\n",
    "\n",
    "    print(\"-------------- Training and testing DL model --------------\")\n",
    "    X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dump_dir)\n",
    "    X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dump_dir, scaler)\n",
    "\n",
    "    name = \"No-Fused-1\"\n",
    "    run_edl_experiment(name, 0, num_levels, X_train, y_train_dummy)\n",
    "\n",
    "    # Test model\n",
    "    accuracy = results_test(0, num_levels, train_dump_dir, test_dump_dir)\n",
    "    results.append(\n",
    "        {\n",
    "            \"num_components\": 0,\n",
    "            \"num_levels\": num_levels,\n",
    "            \"accuracy\": accuracy\n",
    "        })\n",
    "        \n",
    "results_df = pd.DataFrame(results)\n",
    "os.makedirs('results_csv', exist_ok=True)\n",
    "results_df.to_csv('results_csv/results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Training and testing DL model --------------\n",
      "Epoch 1/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 743us/step - edl_accuracy: 0.5399 - loss: 0.9803\n",
      "Epoch 2/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - edl_accuracy: 0.6446 - loss: 0.9228\n",
      "Epoch 3/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - edl_accuracy: 0.6739 - loss: 0.8782\n",
      "Epoch 4/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - edl_accuracy: 0.6816 - loss: 0.8552\n",
      "Epoch 5/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - edl_accuracy: 0.6789 - loss: 0.8428\n",
      "Epoch 6/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - edl_accuracy: 0.6900 - loss: 0.8333\n",
      "Epoch 7/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - edl_accuracy: 0.6917 - loss: 0.8279\n",
      "Epoch 8/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - edl_accuracy: 0.6813 - loss: 0.8271\n",
      "Epoch 9/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - edl_accuracy: 0.6666 - loss: 0.8265\n",
      "Epoch 10/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - edl_accuracy: 0.6507 - loss: 0.8279\n",
      "Epoch 11/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - edl_accuracy: 0.6345 - loss: 0.8290\n",
      "Epoch 12/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - edl_accuracy: 0.6217 - loss: 0.8296\n",
      "Epoch 13/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - edl_accuracy: 0.6180 - loss: 0.8295\n",
      "Epoch 14/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - edl_accuracy: 0.6200 - loss: 0.8287\n",
      "Epoch 15/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - edl_accuracy: 0.6215 - loss: 0.8271\n",
      "Epoch 16/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - edl_accuracy: 0.6293 - loss: 0.8247\n",
      "Epoch 17/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - edl_accuracy: 0.6372 - loss: 0.8219\n",
      "Epoch 18/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - edl_accuracy: 0.6445 - loss: 0.8194\n",
      "Epoch 19/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - edl_accuracy: 0.6508 - loss: 0.8164\n",
      "Epoch 20/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - edl_accuracy: 0.6563 - loss: 0.8154\n",
      "Epoch 21/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - edl_accuracy: 0.6684 - loss: 0.8118\n",
      "Epoch 22/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - edl_accuracy: 0.6765 - loss: 0.8092\n",
      "Epoch 23/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - edl_accuracy: 0.6808 - loss: 0.8076\n",
      "Epoch 24/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - edl_accuracy: 0.6894 - loss: 0.8051\n",
      "Epoch 25/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - edl_accuracy: 0.6953 - loss: 0.8032\n",
      "Epoch 26/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - edl_accuracy: 0.7004 - loss: 0.8014\n",
      "Epoch 27/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - edl_accuracy: 0.7107 - loss: 0.7985\n",
      "Epoch 28/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - edl_accuracy: 0.7132 - loss: 0.7972\n",
      "Epoch 29/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - edl_accuracy: 0.7237 - loss: 0.7946\n",
      "Epoch 30/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - edl_accuracy: 0.7290 - loss: 0.7919\n",
      "Epoch 31/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - edl_accuracy: 0.7344 - loss: 0.7909\n",
      "Epoch 32/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - edl_accuracy: 0.7409 - loss: 0.7882\n",
      "Epoch 33/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - edl_accuracy: 0.7452 - loss: 0.7870\n",
      "Epoch 34/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - edl_accuracy: 0.7507 - loss: 0.7851\n",
      "Epoch 35/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - edl_accuracy: 0.7600 - loss: 0.7830\n",
      "Epoch 36/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - edl_accuracy: 0.7595 - loss: 0.7823\n",
      "Epoch 37/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - edl_accuracy: 0.7677 - loss: 0.7795\n",
      "Epoch 38/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - edl_accuracy: 0.7705 - loss: 0.7787\n",
      "Epoch 39/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - edl_accuracy: 0.7805 - loss: 0.7759\n",
      "Epoch 40/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - edl_accuracy: 0.7845 - loss: 0.7743\n",
      "Epoch 41/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - edl_accuracy: 0.7855 - loss: 0.7732\n",
      "Epoch 42/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - edl_accuracy: 0.7920 - loss: 0.7720\n",
      "Epoch 43/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - edl_accuracy: 0.7950 - loss: 0.7706\n",
      "Epoch 44/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - edl_accuracy: 0.8005 - loss: 0.7690\n",
      "Epoch 45/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - edl_accuracy: 0.8043 - loss: 0.7677\n",
      "Epoch 46/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - edl_accuracy: 0.8059 - loss: 0.7666\n",
      "Epoch 47/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - edl_accuracy: 0.8096 - loss: 0.7654\n",
      "Epoch 48/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - edl_accuracy: 0.8156 - loss: 0.7635\n",
      "Epoch 49/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - edl_accuracy: 0.8187 - loss: 0.7627\n",
      "Epoch 50/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - edl_accuracy: 0.8249 - loss: 0.7608\n",
      "Epoch 51/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - edl_accuracy: 0.8211 - loss: 0.7614\n",
      "Epoch 52/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - edl_accuracy: 0.8311 - loss: 0.7584\n",
      "Epoch 53/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - edl_accuracy: 0.8348 - loss: 0.7573\n",
      "Epoch 54/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - edl_accuracy: 0.8335 - loss: 0.7569\n",
      "Epoch 55/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - edl_accuracy: 0.8384 - loss: 0.7556\n",
      "Epoch 56/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - edl_accuracy: 0.8428 - loss: 0.7541\n",
      "Epoch 57/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - edl_accuracy: 0.8456 - loss: 0.7532\n",
      "Epoch 58/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - edl_accuracy: 0.8446 - loss: 0.7529\n",
      "Epoch 59/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - edl_accuracy: 0.8522 - loss: 0.7511\n",
      "Epoch 60/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - edl_accuracy: 0.8549 - loss: 0.7505\n",
      "Epoch 61/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - edl_accuracy: 0.8537 - loss: 0.7499\n",
      "Epoch 62/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - edl_accuracy: 0.8607 - loss: 0.7486\n",
      "Epoch 63/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - edl_accuracy: 0.8657 - loss: 0.7468\n",
      "Epoch 64/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - edl_accuracy: 0.8624 - loss: 0.7470\n",
      "Epoch 65/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - edl_accuracy: 0.8638 - loss: 0.7461\n",
      "Epoch 66/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - edl_accuracy: 0.8639 - loss: 0.7456\n",
      "Epoch 67/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - edl_accuracy: 0.8683 - loss: 0.7443\n",
      "Epoch 68/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - edl_accuracy: 0.8689 - loss: 0.7446\n",
      "Epoch 69/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - edl_accuracy: 0.8713 - loss: 0.7432\n",
      "Epoch 70/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - edl_accuracy: 0.8745 - loss: 0.7419\n",
      "Epoch 71/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - edl_accuracy: 0.8793 - loss: 0.7412\n",
      "Epoch 72/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - edl_accuracy: 0.8810 - loss: 0.7404\n",
      "Epoch 73/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - edl_accuracy: 0.8816 - loss: 0.7394\n",
      "Epoch 74/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - edl_accuracy: 0.8817 - loss: 0.7394\n",
      "Epoch 75/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - edl_accuracy: 0.8796 - loss: 0.7391\n",
      "Epoch 76/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - edl_accuracy: 0.8804 - loss: 0.7389\n",
      "Epoch 77/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - edl_accuracy: 0.8871 - loss: 0.7373\n",
      "Epoch 78/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - edl_accuracy: 0.8861 - loss: 0.7367\n",
      "Epoch 79/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - edl_accuracy: 0.8870 - loss: 0.7368\n",
      "Epoch 80/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - edl_accuracy: 0.8871 - loss: 0.7364\n",
      "Epoch 81/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - edl_accuracy: 0.8877 - loss: 0.7359\n",
      "Epoch 82/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - edl_accuracy: 0.8934 - loss: 0.7345\n",
      "Epoch 83/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - edl_accuracy: 0.8915 - loss: 0.7346\n",
      "Epoch 84/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - edl_accuracy: 0.8924 - loss: 0.7339\n",
      "Epoch 85/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - edl_accuracy: 0.8946 - loss: 0.7332\n",
      "Epoch 86/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - edl_accuracy: 0.8926 - loss: 0.7335\n",
      "Epoch 87/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - edl_accuracy: 0.8967 - loss: 0.7324\n",
      "Epoch 88/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - edl_accuracy: 0.8954 - loss: 0.7324\n",
      "Epoch 89/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - edl_accuracy: 0.8968 - loss: 0.7318\n",
      "Epoch 90/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - edl_accuracy: 0.8980 - loss: 0.7319\n",
      "Epoch 91/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - edl_accuracy: 0.9000 - loss: 0.7307\n",
      "Epoch 92/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - edl_accuracy: 0.8985 - loss: 0.7306\n",
      "Epoch 93/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - edl_accuracy: 0.9041 - loss: 0.7295\n",
      "Epoch 94/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - edl_accuracy: 0.9034 - loss: 0.7295\n",
      "Epoch 95/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - edl_accuracy: 0.9030 - loss: 0.7293\n",
      "Epoch 96/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - edl_accuracy: 0.9009 - loss: 0.7295\n",
      "Epoch 97/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - edl_accuracy: 0.9017 - loss: 0.7290\n",
      "Epoch 98/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - edl_accuracy: 0.9010 - loss: 0.7296\n",
      "Epoch 99/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - edl_accuracy: 0.9048 - loss: 0.7283\n",
      "Epoch 100/100\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - edl_accuracy: 0.9039 - loss: 0.7284\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.30      0.46      1950\n",
      "           1       0.51      1.00      0.68      1950\n",
      "           2       0.61      0.75      0.67      1950\n",
      "           3       0.37      0.52      0.43      1950\n",
      "           4       1.00      0.11      0.19      1950\n",
      "\n",
      "    accuracy                           0.53      9750\n",
      "   macro avg       0.69      0.53      0.49      9750\n",
      "weighted avg       0.69      0.53      0.49      9750\n",
      "\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Test model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m results_test(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m8\u001b[39m, train_dump_dir, test_dump_dir)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     16\u001b[0m     {\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_components\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_levels\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy\n\u001b[0;32m     20\u001b[0m     })\n\u001b[0;32m     22\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m     23\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_csv\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGwCAYAAABy28W7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABm90lEQVR4nO3deVxUVf8H8M8dhplhXxQYUUAURc1dS6kUUBPX3J4stcS1xy1Ls4xyQa300dI2U1uUFq1sM7Py5xKkJe7iLomCoGwqy7AzMPf3Bzk6wSg4A3cYPu/ndV+P995z73zviZn5zjnnniuIoiiCiIiIyELIpA6AiIiI6E5MToiIiMiiMDkhIiIii8LkhIiIiCwKkxMiIiKyKExOiIiIyKIwOSEiIiKLIpc6AGui0+mQmpoKJycnCIIgdThERFRDoigiLy8P3t7ekMlq7/d7cXExSktLTT6PQqGASqUyQ0SWhcmJGaWmpsLHx0fqMIiIyEQpKSlo1qxZrZy7uLgY/n7OSM/UmnwutVqNxMREq0tQmJyYkZOTEwCg35AJsLVVSByNZXt6oI3UIdQL495MlDoEooZFVwYk79F/nteG0tJSpGdqkXy8C5yd7v+zUJNXDt+uJ1BaWsrkhIy71ZVja6tgcnIP9nb806sWma3UERA1SHXRNe/sIIOzgwldRzrrffoMvyGIiIikIIoViynHWykmJ0RERFJgcmIUbyUmIiIii8KWEyIiIgmw4cQ4JidEREQSEEUZRPH+OzBEK85O2K1DREREFoUtJ0RERBIQRcHElhOdGaOxLExOiIiIJKATZdCZkJyYcqyls94rIyIionqJLSdEREQSMH1ArPW2LzA5ISIikgCTE+Os98qIiIioXmLLCRERkQQq7ta5/wcMmnKspWNyQkREJAF26xjH5ISIiEgCOlGAzoTWD1OOtXTWm3YRERFRvcSWEyIiIgmIMLFbx4rbF5icEBERSYADYo2z3rSLiIiI6iW2nBAREUmALSfGMTkhIiKSAG8lNs56r4yIiIjqJbacEBERSUAUTeuaEUUzBmNhmJwQERFJgGNOjGO3DhEREVkUtpwQERFJQDRx+nprbjlhckJERCQBdusYx+SEiIhIAiJkJk1Bb83T11vvlREREVG91GBbTmJiYhAaGors7Gy4uroiKioKL7zwAnJycqQO7Z6eGngNTw1MM9h2NUOFWW+0BwC4OmkxYXgKOgVqYKfU4VqmCt/taoLYk2768o72ZZj6n2Q82D4Hok5A7Ek3fPK9D4pLber0WszpbFIRtv2Vi0tpJcjOK8crT3mhR1sH/f6vo7Pw55kC3Mgtg9xGQEtvJcb1dUPrZioAwJnEIiyMSqvy3Cuf9UarphXlktJL8NEvN5GQWgJnexkG93DBiEdda/36pDZjZBHmjSuE2l2HkwlyzF7tiCPnbaUOy+KwnqqH9cRunbupFy0n69evh5OTE8rKyvTb8vPzYWtri5CQEIOyMTExEAQBly5dquMo69aVVBUmvNZJv0S8E6jf98IzifD2LMabHwXg+RUP4OBJV8ybeAn+zQr1ZeaMvwxfdREWr22N1z8KQLuWeZjx1BUpLsVsirUimqsVeHZw4yr3ezdSYOqgRnhnRjO8Odkbnq5yLPk8DbkF5QCAQB8VNs7zNVj6dXWCl5scAd5KAEBhsQ5LvkiHh6scb/23KcL7N8LXMdnYdVRTZ9cphdF9i/H27Hws3eiAbhPdcCpBjp1rcuHhppM6NIvCeqoe1lOFW8mJKUtN7Nu3D0OHDoW3tzcEQcC2bdsM9guCUOWyatUqfZnmzZtX2r9ixQqD85w6dQq9evWCSqWCj48PVq5cWeO6qRfJSWhoKPLz83H06FH9tv3790OtVuPQoUMoLi7Wb4+Ojoavry9atmwpRah1RqcTkJNnq1/yCm7/4gj0z8ev+7xwMdkRGTeV+HaXNwqKbNDSpwAA0MyrCN3aafDBV81x8Yojzl92wsff++LRrllwcy6V6pJM1q2VPcb1dUfPO1pL7tS7oyM6tbSH2t0Wvp4KTAxrhMISEVcyKq7ZVi7AzUmuX5zsbXA4vgB9OjtBECo+BPadykdZuYhZwzzg66lArw6OGNzDGdtjc+vsOqUw56kifLJdhahfVDifJMe0lY4oLBEwaUjxvQ9uQFhP1cN6kkZBQQE6deqEtWvXVrk/LS3NYNm4cSMEQcCoUaMMyi1dutSg3HPPPaffp9Fo0L9/f/j5+eHYsWNYtWoVIiMj8dFHH9Uo1nqRnAQGBqJJkyaIiYnRb4uJicGwYcPg7++PgwcPGmwPDQ3FF198ge7du8PJyQlqtRpjx45FZmZmtV/z+vXr6N69O0aMGIGSkhJzXo5ZNPEowcZlJ7F+0SnMGX8Zjd1uxxif6IhHumTB0b4MgiDi0a5ZUMhFnLnoBAAI9C9AfqENLqXc/hI/Ge8MUQRaNy+o82uRgrZMxK5jGtirZGjupaiyzJH4AuQX6tCni5N+W/zVYrTzU8FWfvsXS5cAe1y7oUV+UXmtxy0FW7mIboFl2HP0dj2JooA9R2zRs71WwsgsC+upelhPt5mr5USj0Rgsxr6zBg4ciNdffx0jRoyocr9arTZYfvrpJ4SGhqJFixYG5W59r95aHBxuf5ds3rwZpaWl2LhxIx544AE89dRTmD17NlavXl2juqkXyQlQ0XoSHR2tX4+OjkZISAiCg4P124uKinDo0CGEhoZCq9Vi2bJlOHnyJLZt24akpCRMmDChWq+VkpKCXr16oX379vjuu++gVCqrLFdSUlLpj6Iu/J3kiPc2N8eSda2wfqsfvBqV4M3n46FSVnw5rtrUAnIbEV+uiMO3q49j+pNXsOLTlki/UTFmws1Ji9w8w+FGOp2AvEI53Jyt+8PhSHwBxryRiCdfT8TPsbmIHK+Gs0PV42z2HM9D5wA7NHa5XVfZ+eVw/Vf5W+vZ+daZnDR21UEuBzKyDD8uMrNkULs3rGb4u2E9VQ/r6TZzJSc+Pj5wcXHRL8uXLzc5toyMDPzyyy+YPHlypX0rVqxAo0aN0KVLF6xatcpgyEVsbCx69+4NheJ28hkWFob4+HhkZ2dX+/XrzYDY0NBQvPDCCygrK0NRURFOnDiB4OBgaLVarF+/HkBFpZSUlCA0NBS+vr76Y1u0aIH33nsPDz74IPLz8+Ho6Gj0deLj4/HYY49hxIgReOedd/TN+VVZvnw5lixZYr6LrKbj5130/76SCly84oCPIk/j0S5Z2HPQA2MHpcLBrhyLPmgNTb4cPTrm4KUJl/Hqu4G4kmZf5/Fakg7+dlg9rRk0heXYfSwPb23NxP+mNoWro2HCcSO3DHEJRZg32lOiSImIqiclJQXOzs76dWM/qGvis88+g5OTE0aOHGmwffbs2ejatSvc3d1x4MABREREIC0tTd8ykp6eDn9/f4NjvLy89Pvc3NxQHfWm5SQkJAQFBQU4cuQI9u/fj9atW8PDwwPBwcH6cScxMTFo0aIFfH19cezYMQwdOhS+vr5wcnJCcHAwACA5OdnoaxQVFaFXr14YOXIk3n333bsmJgAQERGB3Nxc/ZKSkmLWa66ugiI5UjOVUHuUQN24GIODM/H+luY49bczklLt8c1ObySk2GNgr+sAgOw8W7g4lRmcQyYT4WRfhmyNdY+WVylkaNLIFoE+Kswa7gEbGbD3eOUWr99P5MHRXoYHAw3Hr7g52iCnwLCF5Na6m2P9vdPpbm7kyFBWBnj961etp7sO6Vn15iOk1rGeqof1dJu5Wk6cnZ0NFnMkJxs3bsS4ceOgUqkMts+dOxchISHo2LEjpk2bhrfffhvvv/++2Yc/1Ju/hICAADRr1gzR0dGIjo7WJxve3t7w8fHBgQMHEB0djT59+qCgoABhYWFwdnbG5s2bceTIEfz4448AgNJS4wM+lUol+vXrhx07duDatWv3jEmpVFb6o5CCSlEOdeMSZOfaQmlb8Yb/99MqdToBMqFiY3yiAxzty/UDZAGgY2sNBAH4O6nqwaTWSicC2nLDyhJFEb/H5SG0kxPkNoYJamAzFc5dKUbZHcecvFSEpo1t4WhnncmJtkzAsXg5+na7/d4RBBF9u2tx8Ix1J7M1wXqqHtbTbbp/pq83ZakN+/fvR3x8PKZMmXLPsj169EBZWRmSkpIAVIxbycjIMChza12tVlc7hnqTnAAVXTsxMTGIiYkxuIW4d+/e+O2333D48GGEhobiwoULuHnzJlasWIFevXqhTZs21RoMK5PJ8MUXX6Bbt24IDQ1FampqLV7N/ZswLAUPBOTB070Egf75eGVKAnSigP3H3XE1Q4XUTCWmP3kFrXzzoW5cjGGh6egUqMGh064AgKsZdjh2zhkznqoo08Y/D1P/k4w/j7sjW1P14ND6oKhEh8S0EiSmVWTwGdlaJKaV4HpOGYpLdfhyTxbiU4qRmaPFpdQSvL8tE1l55Xj4AcNuvtOJxcjILkO/rk6VXqNXR0fIbQSs/ek6kjNL8eeZfOw4mIvHg1wqlbUma762w5THizF+YDHa+JVh3Uv5cFCJ2LRDde+DGxDWU/Wwnizbp59+im7duqFTp073LBsXFweZTAZPz4ou8KCgIOzbtw9a7e3xi7t370ZgYGC1u3SAejTmBKhITmbOnAmtVqtvOQGA4OBgzJo1C6WlpQgNDYVcLodCocD777+PadOm4cyZM1i2bFm1XsPGxgabN2/GmDFj0KdPH8TExNQo26sLjVxL8WL4ZTg5lCE3X47zlxwxf3UbaPIrfnUs29AK44dexWvPJkCl1CHthhLvbfbHsXOu+nOs+bwFnv1PMpbO+hs6UUDsSVd88p2vkVesHy6llhhMorbp/7IAAKGdHTFtSGNcvVGK6Lg8aArL4WRvgwBvJd6Y1AS+noYJ2Z7jGrTxUaKZR+VEzUElw+Jn1Pjol5uYt+EanO1lGB3shv7dpWk1qytb96rg4SpiydQCqN11iLsox8C5LsjMrle/b2od66l6WE8V6noStvz8fCQkJOjXExMTERcXB3d3d/04TY1Gg2+//RZvv/12peNjY2P1N504OTkhNjYWc+bMwdNPP61PPMaOHYslS5Zg8uTJmD9/Ps6cOYN3330Xa9asqVGsgij+uwPAciUlJcHf3x9t2rTB+fPn9duvXLmC5s2bIzAwEBcuXAAAfPXVV3j11VeRlpaGrl27IiIiAo8//jhOnDiBzp0733OG2LKyMjz55JM4f/48YmJi9Fnh3Wg0Gri4uGDgiGdha1t/WyDqwsSh9SovlsyIxdY9mSCRxdFpgaSdyM3NrbWu+lvfFaejR8DJ8f67svLytegQ+mO1Y731vfdv4eHhiIqKAgB89NFHeOGFF5CWlgYXF8MW4ePHj2PGjBm4cOECSkpK4O/vj2eeeQZz5841GOdy6tQpzJw5E0eOHEHjxo3x3HPPYf78+TW6tnqVnFg6JifVx+SkepicENWxOkxOTv0+0uTkpGOfH2o1Vqk0rDY0IiIisnj8+UpERCQBPvjPOCYnREREEhBRedqHmh5vrditQ0RERBaFLSdEREQSECFAhAndOiYca+mYnBAREUmAY06MY7cOERERWRS2nBAREUnBxJYTWHHLCZMTIiIiCYiiaV0z1jyFKrt1iIiIyKKw5YSIiEgCOrFiMeV4a8XkhIiISAK8W8c4JidEREQSYHJiHMecEBERkUVhywkREZEE2HJiHJMTIiIiCVTcSmza8daK3TpERERkUdhyQkREJAE++M84JidEREQS4JgT49itQ0RERBaFLSdEREQSYMuJcUxOiIiIJMC7dYxjtw4RERFZFLacEBERSYDdOsYxOSEiIpIAu3WMY3JCREQkAbacGMcxJ0RERGRR2HJCREQkAbacGMfkhIiISAK6fxZTjrdW7NYhIiIii8KWk1rwW9xVQGYrdRgW7cd306UOoX5Y7Cl1BERUW0zs1gG7dYiIiMicOObEOHbrEBERkUVhywkREZEERJg4CZvZIrE8TE6IiIgkwG4d49itQ0RERBaFyQkREZEEbj1bx5SlJvbt24ehQ4fC29sbgiBg27ZtBvsnTJgAQRAMlgEDBhiUycrKwrhx4+Ds7AxXV1dMnjwZ+fn5BmVOnTqFXr16QaVSwcfHBytXrqxx3TA5ISIiksCtbh1TlpooKChAp06dsHbtWqNlBgwYgLS0NP3y1VdfGewfN24czp49i927d2PHjh3Yt28fnn32Wf1+jUaD/v37w8/PD8eOHcOqVasQGRmJjz76qEaxcswJERGRBESYNqi1pscOHDgQAwcOvGsZpVIJtVpd5b7z589j586dOHLkCLp37w4AeP/99zFo0CC89dZb8Pb2xubNm1FaWoqNGzdCoVDggQceQFxcHFavXm2QxNwLW06IiIjqMY1GY7CUlJTc97liYmLg6emJwMBATJ8+HTdv3tTvi42Nhaurqz4xAYB+/fpBJpPh0KFD+jK9e/eGQqHQlwkLC0N8fDyys7OrHQeTEyIiIgmYq1vHx8cHLi4u+mX58uX3Fc+AAQPw+eefY+/evfjf//6HP/74AwMHDkR5eTkAID09HZ6ehrNWy+VyuLu7Iz09XV/Gy8vLoMyt9VtlqoPdOkRERBK4n0Gt/z4eAFJSUuDs7KzfrlQq7+t8Tz31lP7fHTp0QMeOHdGyZUvExMSgb9++9x/ofWDLCRERUT3m7OxssNxvcvJvLVq0QOPGjZGQkAAAUKvVyMzMNChTVlaGrKws/TgVtVqNjIwMgzK31o2NZakKkxMiIiIJ1PXdOjV19epV3Lx5E02aNAEABAUFIScnB8eOHdOX+f3336HT6dCjRw99mX379kGr1erL7N69G4GBgXBzc6v2azM5ISIikkBdz3OSn5+PuLg4xMXFAQASExMRFxeH5ORk5Ofn46WXXsLBgweRlJSEvXv3YtiwYQgICEBYWBgAoG3bthgwYACmTp2Kw4cP46+//sKsWbPw1FNPwdvbGwAwduxYKBQKTJ48GWfPnsU333yDd999F3Pnzq1RrExOiIiIGoCjR4+iS5cu6NKlCwBg7ty56NKlCxYtWgQbGxucOnUKjz/+OFq3bo3JkyejW7du2L9/v0E30ebNm9GmTRv07dsXgwYNwqOPPmowh4mLiwt27dqFxMREdOvWDS+++CIWLVpUo9uIAQ6IJSIikkRdP1snJCQE4l2aW/7v//7vnudwd3fHli1b7lqmY8eO2L9/f41i+zcmJ0RERBKo60nY6hN26xAREZFFYcsJERGRBOq6W6c+YXJCREQkAXNNwmaNmJwQERFJgMmJcRxzQkRERBaFLSdEREQSqGg5MWXMiRmDsTBMToiIiCTAbh3j2K1DREREFoUtJ0RERJIQIMKU24F5KzERERGZEbt1jGO3DhEREVkUtpwQERFJgC0nxjE5ISIikgCnrzeO3TpERERkUZicWDFHex3WPJ+HxO+vo+D3DPy5Pgvd22ilDqvW7IuzxeMvu6LZ441h84gXtu1TGuzPyJJh4uvOaPZ4Yzj28cTAua64mGJT5blEERj0omuV53l+jRMenOQOuxBPdA13r7XrsTQzRhbh8vc3URh9HbEfZ+PBttb7t2QK1lP1sJ4AnWj6Yq2sIjmZMGECBEGAIAiwtbWFv78/Xn75ZRQXF0sdmqQ+fkWDfg+WYPxSF3R8phF2H1Zg97vZ8G5cLnVotaKgSECnAC3efzGv0j5RBEa+4oLEVBv8+L8cHNt0E37qcvR/3g0FRZXP9e439ne9SW/i4CKM7ttw/r5G9y3G27PzsXSjA7pNdMOpBDl2rsmFh5tO6tAsCuupelhPFcR/biU2ZbFWVpGcAMCAAQOQlpaGy5cvY82aNdiwYQMWL14sdViSUSlEjAouwfy1Tth/UoFL1+RYstERCVdtMH1EFd/GVmBgUCmWPVuAEcEllfZdTLHBwbMKrJ2nwYNtyxDoV44P5+WhqETAV7vtDMrG/S3H6q/t8emrmipf5905eZgxqggtvK0zyavKnKeK8Ml2FaJ+UeF8khzTVjqisETApCENJ0GrDtZT9bCeKtwaEGvKYq2sJjlRKpVQq9Xw8fHB8OHD0a9fP+zevRsA0Lx5c7zzzjsG5Tt37ozIyEj9uiAI+OSTTzBixAjY29ujVatW2L59ex1egXnJ5SLkcqC41HB7UYmARzqWVn2QFSvRVvzCUClub5PJAKVCxF+nbPXbCouBp5e44P0X86Bu1LB+xRljKxfRLbAMe47erjxRFLDniC16tm94TfHGsJ6qh/VE1WE1ycmdzpw5gwMHDkChUNy78B2WLFmC0aNH49SpUxg0aBDGjRuHrKwso+VLSkqg0WgMFkuRXyjDgdO2WDChAE0al0MmEzGufxGC2mvRpHHD+9Jt41cGX69yvLrBEdkaAaVaYOWX9riaaYO0m7ffBnPfc0JQey2G9arc+tJQNXbVQS6vGLNzp8wsGdTuDe9vyRjWU/Wwnm4TYWLLidQXUIusJjnZsWMHHB0doVKp0KFDB2RmZuKll16q0TkmTJiAMWPGICAgAG+++Sby8/Nx+PBho+WXL18OFxcX/eLj42PqZZjV+GXOEATg2k83UBydieeeKMRXe1TQNaz3PwDAVg5892YOLibboPFATzj29UT0cQUG9CyB7J93wfb9SkQfU2DN85XHrBARmdutW4lNWayV1cxzEhoainXr1qGgoABr1qyBXC7HqFGjanSOjh076v/t4OAAZ2dnZGZmGi0fERGBuXPn6tc1Go1FJSiXr8kROssd9ioRzg46pN+0wVdLc3A5teo7VKxdtzZlOP5ZFnLzK1pOPNxEBE11R7d/7mCKPmaLS9ds4D7Aw+C4J15zQa9OWvz+QbYUYUvuRo4MZWWA179+1Xq665CeZTW/b0zGeqoe1hNVh9X8JTg4OCAgIACdOnXCxo0bcejQIXz66acAAJlMBvFfI4e02sp9m7a2tgbrgiBAd5dmBqVSCWdnZ4PFEhUWC0i/aQNXJx3CHirF9v3Kex9kxVwcRXi4ibiYYoOjF+R4/NGKLpz5zxQi7vObOB51ewGA1bPz8OmruVKGLCltmYBj8XL07XZ7rJIgiOjbXYuDZ2zvcmTDwnqqHtbTbRwQa5zVtJzcSSaT4dVXX8XcuXMxduxYeHh4IC0tTb9fo9EgMTFRwgjrRv+HSiAIQHyyHAHNyrByZj4uJMux6Re7ex9cD+UXCki4ertVKCnVBnF/y+HurIOvWodvf1fCw1UHXy8dTl+WY847ThjWqwT9e1R8SKob6aBuVPm8Pl46+HvfTlITrtogv1BA+k0ZikoExP1d8TZq518GhZV+tq752g5RC/Jw9IItDp+T44Uni+CgErFph0rq0CwK66l6WE8VOH29cVaZnADAE088gZdeeglr165Fnz59EBUVhaFDh8LV1RWLFi2CjY31d224OIp4c1o+mnmUI0sjww9/KPHaBkeUlVtnP+XRC3L0fe72pGgvvu8EABg/sAibFmiQflOGee87ISNLhiaNdHhmQBEWTCyo8es8u8IZf5y4Pdi628SKjObSd9fRvIl1DujZulcFD1cRS6YWQO2uQ9xFOQbOdUFmttU0vpoF66l6WE90L1abnMjlcsyaNQsrV67ExYsXkZiYiCFDhsDFxQXLli1rEC0n3/6uwre/N5xfIiFdtSj/K8Po/ueeKMJzT9RsjpeqztdQx56s/d4Oa7+3zlY3c2I9VQ/rCSZPpGbNk7AJ4r8HY9B902g0cHFxAfwHATIrbd83k/I/06UOoV6wecRT6hCIGhadFkjaidzc3FobR3jru2LTh7Ngb3f/YwALi0owccYHtRqrVNiGRkRERBbFart1iIiILBkHxBrH5ISIiEgCTE6MY3JCREQkAVNnebXmGWI55oSIiIgsCltOiIiIJCDCtIf3WXGvDpMTIiIiKXDMiXHs1iEiIiKLwpYTIiIiKZj68D4rbjlhckJERCQB3q1jHLt1iIiIGoB9+/Zh6NCh8Pb2hiAI2LZtm36fVqvF/Pnz0aFDBzg4OMDb2xvjx49HamqqwTmaN28OQRAMlhUrVhiUOXXqFHr16gWVSgUfHx+sXLmyxrEyOSEiIpKAaIalJgoKCtCpUyesXbu20r7CwkIcP34cCxcuxPHjx/HDDz8gPj4ejz/+eKWyS5cuRVpamn557rnn9Ps0Gg369+8PPz8/HDt2DKtWrUJkZCQ++uijGsXKbh0iIiIJ1PXdOgMHDsTAgQOr3Ofi4oLdu3cbbPvggw/w0EMPITk5Gb6+vvrtTk5OUKvVVZ5n8+bNKC0txcaNG6FQKPDAAw8gLi4Oq1evxrPPPlvtWNlyQkREVI9pNBqDpaSkxCznzc3NhSAIcHV1Ndi+YsUKNGrUCF26dMGqVatQVlam3xcbG4vevXtDoVDot4WFhSE+Ph7Z2dnVfm22nBAREUnAXC0nPj4+BtsXL16MyMjI+z8xgOLiYsyfPx9jxoyBs7Ozfvvs2bPRtWtXuLu748CBA4iIiEBaWhpWr14NAEhPT4e/v7/Buby8vPT73NzcqvX6TE6IiIgkYK67dVJSUgwSCKVSaVJcWq0Wo0ePhiiKWLduncG+uXPn6v/dsWNHKBQK/Pe//8Xy5ctNft07MTkhIiKSgLlaTpydnQ2SE1PcSkyuXLmC33///Z7n7dGjB8rKypCUlITAwECo1WpkZGQYlLm1bmycSlU45oSIiIj0icnFixexZ88eNGrU6J7HxMXFQSaTwdPTEwAQFBSEffv2QavV6svs3r0bgYGB1e7SAdhyQkREJIm6fvBffn4+EhIS9OuJiYmIi4uDu7s7mjRpgv/85z84fvw4duzYgfLycqSnpwMA3N3doVAoEBsbi0OHDiE0NBROTk6IjY3FnDlz8PTTT+sTj7Fjx2LJkiWYPHky5s+fjzNnzuDdd9/FmjVrahQrkxMiIiIJ1PWtxEePHkVoaKh+/db4kfDwcERGRmL79u0AgM6dOxscFx0djZCQECiVSnz99deIjIxESUkJ/P39MWfOHINxKC4uLti1axdmzpyJbt26oXHjxli0aFGNbiMGmJwQERE1CCEhIRDvktHcbR8AdO3aFQcPHrzn63Ts2BH79++vcXx3YnJCREQkgbpuOalPmJwQERFJgA/+M4536xAREZFFYcsJERGRBOr6bp36hMkJERGRBESYOObEbJFYHiYnREREEuCAWOM45oSIiIgsCltOiIiIJMCWE+OYnBAREUmAyYlxTE5qg6irWMio/v/tLnUI9cKet6SOoH7oNy9Z6hCIyIyYnBAREUlAhAARJkzCZsKxlo7JCRERkQTYrWMc79YhIiIii8KWEyIiIilwilijmJwQERFJwcRunQafnGzfvr3aJ3z88cfvOxgiIiKiaiUnw4cPr9bJBEFAeXm5KfEQERE1COzVMa5ayYlOxzk7iIiIzIl36xhn0piT4uJiqFQqc8VCRETUYDA5Ma7GtxKXl5dj2bJlaNq0KRwdHXH58mUAwMKFC/Hpp5+aPUAiIiJqWGqcnLzxxhuIiorCypUroVAo9Nvbt2+PTz75xKzBERERWatbLSemLNaqxsnJ559/jo8++gjjxo2DjY2NfnunTp1w4cIFswZHRERkrUQzLNaqxsnJtWvXEBAQUGm7TqeDVqs1S1BERETUcNU4OWnXrh32799faft3332HLl26mCUoIiIia8duHeNqfLfOokWLEB4ejmvXrkGn0+GHH35AfHw8Pv/8c+zYsaM2YiQiIrI6vFvHuBq3nAwbNgw///wz9uzZAwcHByxatAjnz5/Hzz//jMcee6w2YiQiIqIG5L7mOenVqxd2795t7liIiIgaDLacGHffk7AdPXoU58+fB1AxDqVbt25mC4qIiMjacfp642qcnFy9ehVjxozBX3/9BVdXVwBATk4OHn74YXz99ddo1qyZuWMkIiKiBqTGY06mTJkCrVaL8+fPIysrC1lZWTh//jx0Oh2mTJlSGzESERFZHd6tY1yNW07++OMPHDhwAIGBgfptgYGBeP/999GrVy+zBkdERGStRFGAKAomHW+tapyc+Pj4VDnZWnl5Oby9vc0SFBERkbXjgFjjatyts2rVKjz33HM4evSoftvRo0fx/PPP46233jJrcERERNTwVKvlxM3NDYJwu/mooKAAPXr0gFxecXhZWRnkcjkmTZqE4cOH10qgRERE1oR36xhXreTknXfeqeUwiIiIGhZ26xhXreQkPDy8tuMgIiIiAmDCJGwAUFxcjNLSUoNtzs7OJgVERETUELDlxLgaD4gtKCjArFmz4OnpCQcHB7i5uRksREREdG8iRIiiCUsNR53s27cPQ4cOhbe3NwRBwLZt2wzjEUUsWrQITZo0gZ2dHfr164eLFy8alMnKysK4cePg7OwMV1dXTJ48Gfn5+QZlTp06hV69ekGlUsHHxwcrV66scd3UODl5+eWX8fvvv2PdunVQKpX45JNPsGTJEnh7e+Pzzz+vcQBERERU+woKCtCpUyesXbu2yv0rV67Ee++9h/Xr1+PQoUNwcHBAWFgYiouL9WXGjRuHs2fPYvfu3dixYwf27duHZ599Vr9fo9Ggf//+8PPzw7Fjx7Bq1SpERkbio48+qlGsNe7W+fnnn/H5558jJCQEEydORK9evRAQEAA/Pz9s3rwZ48aNq+kpiYiIGhxz3a2j0WgMtiuVSiiVykrlBw4ciIEDB1Z9LlHEO++8gwULFmDYsGEAgM8//xxeXl7Ytm0bnnrqKZw/fx47d+7EkSNH0L17dwDA+++/j0GDBuGtt96Ct7c3Nm/ejNLSUmzcuBEKhQIPPPAA4uLisHr1aoMk5l5q3HKSlZWFFi1aAKgYX5KVlQUAePTRR7Fv376ano6IiKhhMnXq+n+yEx8fH7i4uOiX5cuX1ziUxMREpKeno1+/fvptLi4u6NGjB2JjYwEAsbGxcHV11ScmANCvXz/IZDIcOnRIX6Z3795QKBT6MmFhYYiPj0d2dna146lxy0mLFi2QmJgIX19ftGnTBlu3bsVDDz2En3/+Wf8gQLIcM0YWYd64QqjddTiZIMfs1Y44ct5W6rDq3JMD0jFl5DX8sMcT67b6AADcnLV49j9X0bWtBnYqHa5mKLHl1yb487jh2KmHOuTi6SGpaNG0CKVaGU5ddETkhwFSXIZZnLpUjK0xebh4rRQ3NTosmdAIj7S3r7LsO99lYcfBAkx/3BWjejsZ7Dt4rghf7tbgcpoWClugYwsVlk5sXOkcuQXl+O/qDNzILce2ZU3haFfj30T1Ct9z1cN6Mp+UlBSDm1GqajW5l/T0dACAl5eXwXYvLy/9vvT0dHh6ehrsl8vlcHd3Nyjj7+9f6Ry39lV3bGqNk5OJEyfi5MmTCA4OxiuvvIKhQ4figw8+gFarxerVq2t6umqZMGECcnJyKg3eobsb3bcYb8/Ox/RVTjh0Vo4XnizCzjW5aDPGHdezrfsL4k6t/QowuPd1XEqxM9g+f1IiHOzKsWhtAHLz5ejzUBYWPHsZM99oi0spFV/Wj3bNxpxnrmDTj01x4oITbGxENPcukuIyzKa4VEQLbwUGPOSAyM9uGi335+lCnE8uRSNnm0r79p0qxJpvszFpoAu6tFKivBxITK/8WAsAeHtrNlo0scWN3HKzXYOl4nuuelhPFcx1t46zs7PV3Slb47+COXPmYPbs2QAqmnMuXLiALVu24MSJE3j++efNHiDdvzlPFeGT7SpE/aLC+SQ5pq10RGGJgElDiu99sJVQKcsRMSURa77wQ36h4ZdsuxYF+CnaE/FJDki/UdFqUlBog9Z+hQAAmUzEjCdT8PF3zbBjnweuZaqQnGaHfcfcpbgUs3morR0mDXTBox2qbi0BgBu5ZfhgWw4ixjaC/F+5SXm5iA9/ysGzQ1ww9GFHNPOwhZ/aFiGdK59v+4F85Bfp8ESwU6V91ojvuephPf1DNMNiJmq1GgCQkZFhsD0jI0O/T61WIzMz02B/WVkZsrKyDMpUdY47X6M6TE5R/fz8MHLkSHTs2NHUU1VL8+bNK81Y27lzZ0RGRurXBUHAhg0bMGTIENjb26Nt27aIjY1FQkICQkJC4ODggIcffhiXLl3SHxMZGYnOnTtjw4YN8PHxgb29PUaPHo3c3Nw6uS5zs5WL6BZYhj1Hb/f7iaKAPUds0bN91b9wrdFzY5Jx6LQLTpyv/Kvi3GUHBHfPhpN9GQRBRMiDWbC1FXEy3hEA0Mq3EB5uWogisG7BOXy96iTemH2x3rec3ItOJ2LFliyMDnFCc3XlZvaL10pxI7ccggD8d3U6Ri+5hoiPryMxzXDOoyvpWny5Oxfzx7hDsN6Hp+rxPVc9rKfbLCg3gb+/P9RqNfbu3avfptFocOjQIQQFBQEAgoKCkJOTg2PHjunL/P7779DpdOjRo4e+zL59+wweELx7924EBgbWaLqRanXrvPfee9U+4a1WFaktW7YMq1evxurVqzF//nyMHTsWLVq0QEREBHx9fTFp0iTMmjULv/32m/6YhIQEbN26FT///DM0Gg0mT56MGTNmYPPmzVW+RklJCUpKSvTr/x4xLaXGrjrI5UBGlmH+mZklQxu/hvEBEPJgFlr5FWLmG22r3L9sQwsseDYRP7xzEmXlQEmpDEvWtUTqdRUAoIlHxX/bZ4amYf23zZBxQ4H/PJaBt+bFY+KC9sgrNGkOQ4v1dXQebGyAEY86Vrk/7WZF98znuzSY9rgr1O5yfPtHHl5cdx1Rr6jhbG+D0jIRb2y+iWeHuMLLTY60m2V1eQmS4HuuelhP0snPz0dCQoJ+PTExEXFxcXB3d4evry9eeOEFvP7662jVqhX8/f2xcOFCeHt765+Z17ZtWwwYMABTp07F+vXrodVqMWvWLDz11FPw9vYGAIwdOxZLlizB5MmTMX/+fJw5cwbvvvsu1qxZU6NYq/XpWt2TCoJgMcnJxIkTMXr0aADA/PnzERQUhIULFyIsLAwA8Pzzz2PixIkGxxQXF+Pzzz9H06ZNAVTcIjV48GC8/fbbVTZHLV++HEuWLKnlK6H74eFWihlPpmD+mlbQllXdQDhhWCoc7Mvw8upWyM2X4+HOOVjw7GXMWRWIpGt2+l/7W35V6wfJvvVZc2z532n07p6NX/Z51NXl1Jm/r5bixz/zsO4FtcHDPu+k+6eje2w/Z/TuWNGV89KT7hizLBX7ThZhSJAjPv01B75ecvTr5lBnsRPVN3U9Q+zRo0cRGhqqX587dy6AikfUREVF4eWXX0ZBQQGeffZZ5OTk4NFHH8XOnTuhUqn0x2zevBmzZs1C3759IZPJMGrUKIMGDBcXF+zatQszZ85Et27d0LhxYyxatKhGtxED1UxOEhMTa3RSS3BnN9OtkcIdOnQw2FZcXAyNRqMfSOTr66tPTICK5imdTof4+Pgqk5OIiAj9f1ygouXEx8fH7NdyP27kyFBWBni56wy2e7rrkJ5l/QPOWvkVws25DOsWnNdvs7EBOrTKx7DQTExc1B7D+1zHlMXtcCWtYqDs5av2FftDMvHuZj9k5VZ0adzaDwDaMhnSbijg6W7YhWEtTl8uQU6+DmPfSNVv0+mADT/n4If9edj8mrd+gKyf1+0uH4VcQBN3OTJzKlpI4hJKkJimRf9TKRUF/vkQHbn4Gsb1dUZ4mEvdXFAdaujvuepiPd1W18lJSEgIxLscJAgCli5diqVLlxot4+7uji1bttz1dTp27Ij9+/fXLLh/qXft0jKZrFLl3tm3dYut7e0Pzlu/AKvaptMZvkFqwthEN5ZAWybgWLwcfbuV4qd9FTEKgoi+3bVY+73dPY6u/06cd8LUyHYG2+ZNSEJKugrf7FRDqaj47/7v96lOJ+hbTC5esUepVoCPVzHOJlR0cdjYiFA3KkXGTQWsUb9u9ujayvBv+pWPb6BfN3sMeLCiFaRVMwVs5cDVTC06+FeULSsXkZ5dBk+3ijKLxzdGifb2eys+pRRvbc3GOzM80aRRvfvYqZaG/p6rLtYTVUe9+5Tw8PBAWlqafl2j0ZitZSc5ORmpqan6vrODBw9CJpMhMDDQLOeva2u+tkPUgjwcvWCLw+cqbtdzUInYtEN174PruaISGySlGn7QFZfIoMmXIynVDjY2Iq5lKPH808n46Ltm0BTI8UjnHHRtq8HCDyrmMCkstsGOPzww/vFUXM9WIOOmAqP7V9zLv+9Y/X2OVFGJDtdu3B4DkpZVjoRrpXCyl8HLTQ4XB8Pbc+Q2gLuTDXw8K5J7B5UMQ4Mc8dkuDTxc5fBys8HWmDwAQPA/3TzejQ0/WnILKhIVXy9bq57npCG/52qC9VTBXDPEWqN6l5z06dMHUVFRGDp0KFxdXbFo0SLY2FSeh+F+qFQqhIeH46233oJGo8Hs2bMxevToGt3+ZEm27lXBw1XEkqkFULvrEHdRjoFzXZDZgOYRMKa8XMBr7wdg8shrWDYrASqlDqmZSqyKao7DZ253OXz0fTOU6wTMn5QIha0OFxId8NLbrZFfjwfDxqeUYt766/r19dtzAAD9u9vj5acaVesczw5xhY1MwIqvbqJUK6KNrwJvTfOEk33D/tvie656WE8Vbj3Az5TjrVW9+ITV6XSQyytCjYiIQGJiIoYMGQIXFxcsW7bMbC0nAQEBGDlyJAYNGoSsrCwMGTIEH374oVnOLZW139uxqfQf8942bAG7lqnC0vUt73pMebmAj75rho++a1abodWpzgEq7Hmr+mOjNr/mXWmb3EbAf4e64r9DXWvlNeszvueqh/VEd1MvkpPMzEwEBFQ0tTs7O+Prr7822B8eHm6w/u9ssnnz5pW2GRsYNH36dEyfPt0cYRMRERlV1wNi65P7akPbv38/nn76aQQFBeHatWsAgC+++AJ//vmnWYPLzs7Gjh07EBMTY/AwIiIiovrOlIf+mZrYWLoaJyfff/89wsLCYGdnhxMnTugnIcvNzcWbb75p1uAmTZqEadOm4cUXX9Q/wpmIiIisW42Tk9dffx3r16/Hxx9/bHBr7iOPPILjx4+bNbgff/wRV69exRtvvGF0QihziYyMRFxcXK2+BhER0W2WNIG9ZanxmJP4+Hj07t270nYXFxfk5OSYIyYiIiKrxzEnxtW45UStVhvMzX/Ln3/+iRYtWpglKCIiImt361ZiUxZrVePkZOrUqXj++edx6NAhCIKA1NRUbN68GfPmzeNdLkRERGSyGnfrvPLKK9DpdOjbty8KCwvRu3dvKJVKzJs3D88991xtxEhERGR12K1jXI2TE0EQ8Nprr+Gll15CQkIC8vPz0a5dOzg6Vv14dSIiIqqM09cbd9+TsCkUCrRr1+7eBYmIiIhqoMbJSWho6F1v6/39999NCoiIiKgh4LN1jKtxctK5c2eDda1Wi7i4OJw5c6bSNPJERERkBPt1jKpxcrJmzZoqt0dGRiI/P9/kgIiIiKhhM9vzqZ9++mls3LjRXKcjIiKyapwf1jizPZU4NjYWKpXKXKcjIiKyahxzYlyNk5ORI0carIuiiLS0NBw9ehQLFy40W2BERETUMNU4OXFxcTFYl8lkCAwMxNKlS9G/f3+zBUZERGTNOAmbcTVKTsrLyzFx4kR06NABbm5utRUTERGR1WNyYlyNBsTa2Nigf//+fPowERGRyUST/mfNQ2JrfLdO+/btcfny5dqIhYiIiKjmycnrr7+OefPmYceOHUhLS4NGozFYiIiI6N5udeuYslirao85Wbp0KV588UUMGjQIAPD4448bTGMviiIEQUB5ebn5oyQiIrJGVpxgmKLaycmSJUswbdo0REdH12Y8RERE1MBVOzm5NdlLcHBwrQVDRETUUPDROsbV6Fbiuz2NmIiIiKqPM8QaV6PkpHXr1vdMULKyskwKiIiIiBq2GiUnS5YsqTRDLBEREdUcJ2EzrkbJyVNPPQVPT8/aioWIiKjBYHJiXLXnOeF4EyIiIqoLNb5bh4iIiEzHu3WMq3ZyotPpajMOIiKiBoV36xhXozEnROay90yy1CHUCw8ebit1CPXCkmcekDqEemHxF2elDoHuwDEnxtX42TpERERU/zRv3hyCIFRaZs6cCQAICQmptG/atGkG50hOTsbgwYNhb28PT09PvPTSSygrKzN7rGw5ISIiagCOHDli8Py7M2fO4LHHHsMTTzyh3zZ16lQsXbpUv25vb6//d3l5OQYPHgy1Wo0DBw4gLS0N48ePh62tLd58802zxsrkhIiISAJ13a3j4eFhsL5ixQq0bNnS4LE09vb2UKvVVR6/a9cunDt3Dnv27IGXlxc6d+6MZcuWYf78+YiMjIRCoajxNRjDbh0iIqJ6TKPRGCwlJSX3PKa0tBRffvklJk2aZDBVyObNm9G4cWO0b98eERERKCws1O+LjY1Fhw4d4OXlpd8WFhYGjUaDs2fNO56JLSdEREQSMFfLiY+Pj8H2xYsXIzIy8q7Hbtu2DTk5OZgwYYJ+29ixY+Hn5wdvb2+cOnUK8+fPR3x8PH744QcAQHp6ukFiAkC/np6efv8XUgUmJ0RERBIw163EKSkpcHZ21m9XKpX3PPbTTz/FwIED4e3trd/27LPP6v/doUMHNGnSBH379sWlS5fQsmXL+47zfrBbh4iIqB5zdnY2WO6VnFy5cgV79uzBlClT7lquR48eAICEhAQAgFqtRkZGhkGZW+vGxqncLyYnREREEhDNsNyPTZs2wdPTE4MHD75rubi4OABAkyZNAABBQUE4ffo0MjMz9WV2794NZ2dntGvX7j6jqRq7dYiIiCQgxSRsOp0OmzZtQnh4OOTy2ynApUuXsGXLFgwaNAiNGjXCqVOnMGfOHPTu3RsdO3YEAPTv3x/t2rXDM888g5UrVyI9PR0LFizAzJkzq9WVVBNMToiIiBqIPXv2IDk5GZMmTTLYrlAosGfPHrzzzjsoKCiAj48PRo0ahQULFujL2NjYYMeOHZg+fTqCgoLg4OCA8PBwg3lRzIXJCRERkQSkaDnp379/lYNwfXx88Mcff9zzeD8/P/z66681f+EaYnJCREQkAT6V2DgmJ0RERFLgk/+M4t06REREZFHYckJERCQBNpwYx+SEiIhIAhxzYhy7dYiIiMiisOWEiIhICiZ261hz0wmTEyIiIglwzIlx7NYhIiIii8KWEyIiIgmw5cQ4JidEREQSqLhb5/4zDCvOTditQ0RERJaFLSdEREQSYLeOcUxOiIiIJMDkxDgmJ0RERBLgDLHGccwJERERWRS2nBAREUnFmps/TMDkhIiISAIcc2Icu3WIiIjIorDlhIiISAIcEGsck5N/CIKAH3/8EcOHD5c6FLOaMbII88YVQu2uw8kEOWavdsSR87ZSh2VxGno9KWzL8NjDV9Cu5Q042muRmumIHX+0xLUMJwBA355J6Nj6OlycSlBeLsO1TEfsOtAcV9OdDc4T2Pwm+vRMhrpxAcrKZEi85oIvf35AiksyWVJGAf46exNpWcXIKyrDU8HN0Nb39vWKoojok9dxLCEHxaXl8PWwx5AeajRyVurL/HH6Oi5ey0d6VjFsZAIinmpj9PUKS8qwbsdlaArL8MqTgbBT2NTq9Umtob/nAHbr3E2D6da5fv06pk+fDl9fXyiVSqjVaoSFheGvv/4CAKSlpWHgwIEAgKSkJAiCgLi4OAkjNt3ovsV4e3Y+lm50QLeJbjiVIMfONbnwcNNJHZpFYT0BIx+7iADfbHz7f4F494tuSEh2xeSRp+DsUAIAuJFtj+3RAXj3i27YsLUTsjUqTBpxGg52pfpzPBBwHU8MiMexs15478uu2LC1E05e8JTqkkymLdNB7abC4IfUVe7/8+xNHLqQhaE9mmDqQH/YygV8sTcZ2vLbfzflOhHtfJ3RvbXbPV/vpwNp8HJVmS1+S8b3HN1Lg0lORo0ahRMnTuCzzz7D33//je3btyMkJAQ3b94EAKjVaiiVynucpX6Z81QRPtmuQtQvKpxPkmPaSkcUlgiYNKRY6tAsSkOvJ7lNOR4IuI6d+/2RdM0VWbl22HuwOW7m2KFHx1QAwMl4T1xKcUO2xg6ZWQ74dV8LqJTlUDcuAADIBBFDgi/ht/3+OHzaGzdz7JGZ5YDTFz2kvDSTtGrqhL5dPA1aS24RRREHL2Shd4fGaOPjBLWbCiMfaYq8wjJcSM7Tl+vTyRMPt2sEL7e7Jx2H47NQrC3Hw+0amf06LFFDf8/dcqvlxJTFWjWIbp2cnBzs378fMTExCA4OBgD4+fnhoYce0pe5s1vH398fANClSxcAQHBwMGJiYuo8blPYykV0CyzDii/s9dtEUcCeI7bo2V4rYWSWhfUEyGQibGRAWbnhbxVtmQx+TTWVytvIdHiwfRqKSmyQdt0RAODtmQcXp1KIooBZY4/B0UGLtOsO2Lm/BTJuOtTJddSl7Hwt8ovK0KKJo36bSmGDpo3tkHKjCB38Xap9rsycEvxx+gamDvRHdl7pvQ+o5/ieu00URYgmZBimHGvpGkRy4ujoCEdHR2zbtg09e/a8ZwvJ4cOH8dBDD2HPnj144IEHoFAoqixXUlKCkpIS/bpGU/mDXCqNXXWQy4GMLMMvnMwsGdr4NawPgLthPQGlWjmupDojtEcyMrPskV+oQKfATPg20eBmjp2+XKD/TTw18DxsbXXIK1Bg4w8dUVhcMUbA3aXiF2/fnlfw674WyNao0KvrVUz5z0msjnoQRSXWNZYgv6gMAOCoMhwX4mgn1++rjrJyHb778yr6d/WEq4Ntg0hO+J6j6mgQ3TpyuRxRUVH47LPP4OrqikceeQSvvvoqTp06VWV5D4+KpuhGjRpBrVbD3d29ynLLly+Hi4uLfvHx8am1ayCqTd/+XyAEABFTD2Hpc/sR1DkVJ+M9De4GuJziivc3d8OGbzrjYpIbxgw6px9zIggVZWIO++JsggdSM53w3e5AQBTQofX1Or+e+mLPiUx4OCvRqYWr1KGQBEQzLNaqQSQnQMWYk9TUVGzfvh0DBgxATEwMunbtiqioqPs+Z0REBHJzc/VLSkqK+QI20Y0cGcrKAC93wwFmnu46pGc1mP/s98R6qpCVa4ePv+uExR88gpWf9MC6r7vAxkZEVu7tlhNtmQ2ycu2Qku6MH/YEQqcT0L19OgAgr6CidTEz63ZTfXm5DFkaFVycSmBtHO0qGp3zi8sNtucXlen3VUdiegHOJmuw5MtzWPLlOXy25woAYOXWePx+MtN8AVsQvudu45gT4xrUX4JKpcJjjz2GhQsX4sCBA5gwYQIWL1583+dTKpVwdnY2WCyFtkzAsXg5+na73UwsCCL6dtfi4BnramI3BevJkLbMBnmFSqiUWrTyy8L5S8YHaAoCILep+IK5lukIbZmAxm6F+v0ymQ5uTsXI0VjfHShujrZwtJPjcnqBfltxaTmu3SiCT2O7uxxp6MlgH0wf3ALT/lmG9fQGAEwKa46HWlfdYlvf8T13G5MT4xrEmBNj2rVrh23btlXafmuMSXl5eaV99cmar+0QtSAPRy/Y4vA5OV54sggOKhGbdljfl4UpWE9AK78sAMCNbDs0ci3GgF6XcT3LHsfOecFWXo7Qh5Jx/nIj5BUoYG+nRc9OqXB2LMHpvyu6QEtK5Th82hv9el5Bbp4SOXkq9Op2FQBw+mJjya7LFCVaHbLuGAOSna9FWlYx7JQ2cHWwRc827th3+joaOSng5miL3+Ouw8lejja+Tvpjcgq0KCopR26BFjoRSMuqGJvj7qSA0lYGdyfD8WyFJRWfOY1dlFY9zwnfc3QvDSI5uXnzJp544glMmjQJHTt2hJOTE44ePYqVK1di2LBhlcp7enrCzs4OO3fuRLNmzaBSqeDiUv3R95Zi614VPFxFLJlaALW7DnEX5Rg41wWZ2Q2qweyeWE+ASlGO/o8kwsWxBIUltjh7sTF2HWgOnU4GmaCDh3shurTLgINKi8JiW1zNcMJH33ZGZtbtO3F+2+8PnU7A6LB4yOU6pKQ74ZPvO6K4ng6GTb1ZhKjdV/Tr/3csAwDQuYULRjzSFI8+0AjaMh1+PpiK4lIdfD3t8XRfX9ja3P67iY7LRNzlXP36+l8uAwAmPOYHf7X13cVUXXzPVeAMscYJojXfi/SPkpISREZGYteuXbh06RK0Wi18fHzwxBNP4NVXX4WdnV2lGWI/+eQTLF26FNeuXUOvXr2qdSuxRqOpSGKaDwBk9fMDmSzLK6PbSh1CvWCnbFhfavdr8RdnpQ7B8um0QNJO5Obm1lpX/a3viv7DnoWtbdV3g1aHVluKXT99VKuxSqVBtJwolUosX74cy5cvN1rm3znalClTMGXKlNoOjYiIiP6lQSQnRERElobP1jGOyQkREZEEOObEOHbUEhERkUVhywkREZEUTJ2rxIqbTpicEBERSYBjToxjtw4REVEDEBkZCUEQDJY2bdro9xcXF2PmzJlo1KgRHB0dMWrUKGRkZBicIzk5GYMHD4a9vT08PT3x0ksvoays+g+7rC62nBAREUlAigGxDzzwAPbs2aNfl8tvpwFz5szBL7/8gm+//RYuLi6YNWsWRo4cib/++gtAxazpgwcPhlqtxoEDB5CWlobx48fD1tYWb775pglXUhmTEyIiIglI0a0jl8uhVqsrbc/NzcWnn36KLVu2oE+fPgCATZs2oW3btjh48CB69uyJXbt24dy5c9izZw+8vLzQuXNnLFu2DPPnz0dkZKT+0S/mwG4dIiIiCZjrwX8ajcZgKSkx/iTwixcvwtvbGy1atMC4ceOQnJwMADh27Bi0Wi369eunL9umTRv4+voiNjYWABAbG4sOHTrAy8tLXyYsLAwajQZnz5p39mEmJ0RERPWYj48PXFxc9Iux2dB79OiBqKgo7Ny5E+vWrUNiYiJ69eqFvLw8pKenQ6FQwNXV1eAYLy8vpKenAwDS09MNEpNb+2/tMyd26xAREUnAXN06KSkpBs/WUSqVVZYfOHCg/t8dO3ZEjx494Ofnh61bt8LOzu7+A6kFbDkhIiKSgGiGBQCcnZ0NFmPJyb+5urqidevWSEhIgFqtRmlpKXJycgzKZGRk6MeoqNXqSnfv3FqvahyLKZicEBERNUD5+fm4dOkSmjRpgm7dusHW1hZ79+7V74+Pj0dycjKCgoIAAEFBQTh9+jQyMzP1ZXbv3g1nZ2e0a9fOrLGxW4eIiEgCdX23zrx58zB06FD4+fkhNTUVixcvho2NDcaMGQMXFxdMnjwZc+fOhbu7O5ydnfHcc88hKCgIPXv2BAD0798f7dq1wzPPPIOVK1ciPT0dCxYswMyZM6vdWlNdTE6IiIgkUNfJydWrVzFmzBjcvHkTHh4eePTRR3Hw4EF4eHgAANasWQOZTIZRo0ahpKQEYWFh+PDDD/XH29jYYMeOHZg+fTqCgoLg4OCA8PBwLF269P4vwggmJ0RERA3A119/fdf9KpUKa9euxdq1a42W8fPzw6+//mru0CphckJERCQBKWaIrS+YnBAREUmAD/4zjnfrEBERkUVhywkREZEE2HJiHJMTIiIiCXDMiXFMToiIiCTAlhPjOOaEiIiILApbToiIiCQgwsSWE7NFYnmYnBAREUmAY06MY7cOERERWRS2nBAREUmAA2KNY3JCREQkAVEEdExOqsRuHSIiIrIobDkhIiKSALt1jGNyQmTBVmw9L3UI9ULKt7ZSh1AvvP1LS6lDsHhieQnykurotcC7dYxhtw4RERFZFLacEBERSUAUBYiiYNLx1orJCRERkQQ45sQ4JidEREQS4JgT4zjmhIiIiCwKW06IiIgkoBMBwYTmD1MmcLN0TE6IiIgkwDEnxrFbh4iIiCwKW06IiIgkwAGxxjE5ISIikgDHnBjHbh0iIiKyKGw5ISIikgAHxBrH5ISIiEgCFWNOTJi+3nyhWBx26xAREZFFYcsJERGRBDgg1jgmJ0RERBLgmBPjmJwQERFJQBRNa/2w5uSEY06IiIjIorDlhIiISAKcIdY4JidEREQS0JmYnVjzgFh26xAREZFFYXJCREQkAVEUTF5qYvny5XjwwQfh5OQET09PDB8+HPHx8QZlQkJCIAiCwTJt2jSDMsnJyRg8eDDs7e3h6emJl156CWVlZSbXx53YrUNERCQBXR0f/8cff2DmzJl48MEHUVZWhldffRX9+/fHuXPn4ODgoC83depULF26VL9ub2+v/3d5eTkGDx4MtVqNAwcOIC0tDePHj4etrS3efPNNE6/oNiYnREREDcDOnTsN1qOiouDp6Yljx46hd+/e+u329vZQq9VVnmPXrl04d+4c9uzZAy8vL3Tu3BnLli3D/PnzERkZCYVCYZZY2a1DREQkAZ1o+gIAGo3GYCkpKanW6+fm5gIA3N3dDbZv3rwZjRs3Rvv27REREYHCwkL9vtjYWHTo0AFeXl76bWFhYdBoNDh79qyJNXIbW06IiIgkYK67dXx8fAy2L168GJGRkXc/VqfDCy+8gEceeQTt27fXbx87diz8/Pzg7e2NU6dOYf78+YiPj8cPP/wAAEhPTzdITADo19PT0+//Yv6FyQkREVE9lpKSAmdnZ/26Uqm85zEzZ87EmTNn8Oeffxpsf/bZZ/X/7tChA5o0aYK+ffvi0qVLaNmypfmCvgd26xAREUnAXN06zs7OBsu9kpNZs2Zhx44diI6ORrNmze5atkePHgCAhIQEAIBarUZGRoZBmVvrxsap3A8mJ0RERBLQQTB5qQlRFDFr1iz8+OOP+P333+Hv73/PY+Li4gAATZo0AQAEBQXh9OnTyMzM1JfZvXs3nJ2d0a5duxrFczfs1iEiIpKADjBtzEkNy8+cORNbtmzBTz/9BCcnJ/0YERcXF9jZ2eHSpUvYsmULBg0ahEaNGuHUqVOYM2cOevfujY4dOwIA+vfvj3bt2uGZZ57BypUrkZ6ejgULFmDmzJnV6k6qLracEBERNQDr1q1Dbm4uQkJC0KRJE/3yzTffAAAUCgX27NmD/v37o02bNnjxxRcxatQo/Pzzz/pz2NjYYMeOHbCxsUFQUBCefvppjB8/3mBeFHNgy4mVmzGyCPPGFULtrsPJBDlmr3bEkfO2UodlcVhP99bQ6ujgOREbtutw6rKIzGzg45dkGPDQ7d9zPk9UPSPma0/LMG2Y4e++Eq2IxyPKce4KsHOlDR7wv90cf/6KiNc+KcepS4C7MzBxoAzTh9Xf341znriGoUFZaNWsCMWlMhw+74TFUb5IuGanLxMeloEnQm6gY8tCONuXw+/J7sgtMPw6cnUsw8ppiRjwUA5EHbD9gDte+ag5Copt6vqSao14x7iR+z2+ZuXvfoCPjw/++OOPe57Hz88Pv/76a81evIYkfQdMmDCh0jS5giBgwIABtf66w4cPr9XXsASj+xbj7dn5WLrRAd0muuFUghw71+TCw83UeQmtC+vp3hpiHRWViGjrB7w+ueqPyWMf2Rgsb82QQRCAgT0rjwN48wsdvNwrb88rFDFuWTmaeQj45X82eO0ZGVZv1WHz7vpbr4+01+CTX7zw2Lz2GLGwLeRyET8uOw97Zbm+jL1Shz3HXLF6q7fR83w87yLa+hZhxII2eHJpIB5un4d3Zl2ui0uoM+VmWKyV5On5gAEDkJaWZrB89dVXUodlFeY8VYRPtqsQ9YsK55PkmLbSEYUlAiYNKZY6NIvCerq3hlhHoV1keHmMDQb2qPpj0tNNMFh2HRHx8AMC/LwMk5DoEzrsOyViwTOVz/PjfhGlZcBb02UI9BEw7BEZJg0U8PGO+puc/GdxW2zZ64kLyfY4k+iAGWtawsezFJ0DCvRl1m1vgne+a4qj8Y5VnqN1syI81j0Xz73XAsf+dsLBc854eX1zjOp9E2r30rq6FJKQ5MmJUqmEWq02WNzc3AAAgiBgw4YNGDJkCOzt7dG2bVvExsYiISEBISEhcHBwwMMPP4xLly7pzxcZGYnOnTtjw4YN8PHxgb29PUaPHq2fCS8yMhKfffYZfvrpJ31LTUxMDPr06YNZs2YZxHb9+nUoFArs3bu37irETGzlIroFlmHP0dtTCYuigD1HbNGzvVbCyCwL6+neWEf3dj1HxO/HRTzZR6i0/eX1OrzznA3sqhgrePxvET3aCVDY3j4uuLOAS6lATr4J7f0WxNmh4vd9dn71RxE81DYPOfk2iEu4nbzExLlAJwLdA/PNHqNUykXTF2sleXJyL8uWLcP48eMRFxeHNm3aYOzYsfjvf/+LiIgIHD16VH9r1J0SEhKwdetW/Pzzz9i5cydOnDiBGTNmAADmzZuH0aNHG7TYPPzww5gyZQq2bNliMO3vl19+iaZNm6JPnz5VxlZSUlJp2mBL0dhVB7kcyMgy/E+cmSWD2r3+/iozN9bTvbGO7u27P0Q4qICBPW4nGaIoYu5aHZ7uL0OnllXf8pmZA3i4GG5r7FJR9npOLQVbhwRBxPKpSYg964TzV+zvfcA/PF21uJ5jOJ6pXCcgO08OT1fraTkpE01frJXkycmOHTvg6OhosNz5ZMOJEydi9OjRaN26NebPn4+kpCSMGzcOYWFhaNu2LZ5//nnExMQYnLO4uBiff/45OnfujN69e+P999/H119/jfT0dDg6OsLOzs6gxUahUGDkyJEAgJ9++kl/nqioKP24mKosX74cLi4u+uXfUwgTUcPwze86jOglQKW4/Vmx6TcRBUUiZg2v2VwU1uSt6Ylo51eIySsDpA6F6hnJ79YJDQ3FunXrDLbd+RCiW/dWA7fn7+/QoYPBtuLiYmg0Gv30vb6+vmjatKm+TFBQEHQ6HeLj443OYKdSqfDMM89g48aNGD16NI4fP44zZ85g+/btRmOPiIjA3Llz9esajcZiEpQbOTKUlQFe//pl6+muQ3qW5DmpxWA93Rvr6O4OnRdxKRX4cI5hXfx1RsSxv4GWYw2HLQ5+pRwjeglYM8sGnq7A9VzD893Irfg57OFai0HXgZXTEhH2YA4Gv9IOqTdrNv9FZo4tPFwNuwxtZCLcnMqQmWOep95agnIIEGo4kdqdRBOOtXSSJycODg4ICDCeVdva3m7au9WCUdU2nc705uUpU6agc+fOuHr1KjZt2oQ+ffrAz8/PaHmlUmnWSWfMSVsm4Fi8HH27leKnfRUxCoKIvt21WPu93T2ObjhYT/fGOrq7r/fq0KEF0K654RfF0okyvPTU7fWMbBFPv67Dh3Nk6NKqomzX1gJWfqWDtkyErbxi275TIlp6A66O9fWLR8TKaUkYEpSFIRHtcCVDVeMzHD7vBFfHcnRqmY+TlyrGnfTulAuZAKODaOujMhEQ6vBW4vrEKn/2JCcnIzU1Vb9+8OBByGQyBAYGAqiYaKa8vPJNWB06dED37t3x8ccfY8uWLZg0aVKdxVwb1nxthymPF2P8wGK08SvDupfy4aASsWlHzT8srBnr6d4aYh0VFIk4m1ixAEBKJnA2UcS167e/EfIKRfxyUMSYvpU/Spt6CGjje3tp0aQi2fDzEtCkUcW/hz8qQCEHXlqnQ3yKiO1/6bDxVxFTh9Tfj+a3pifhyZAbmLqqFfILbeDpWgpP11KoFLd/QHq6lqKDfwH8m1SM8WvXvBAd/Avg6lgxd8zfV+2w+6gL3nvuMrq2zkePtnlYNS0J3+9rhPQs62k5IeMkbzkpKSmp9JhluVyOxo0b3/c5VSoVwsPD8dZbb0Gj0WD27NkYPXq0vkunefPm+L//+z/Ex8ejUaNGcHFx0bfGTJkyBbNmzYKDgwNGjBhx/xdmAbbuVcHDVcSSqQVQu+sQd1GOgXNdkJldfz/4agPr6d4aYh2duixidOTtL9Sln1X8+z/BFV0yALD9LxGiCAx75P5aOZwdBGxeaIPXPinH4PnlcHMCXviPDOMeq7/1OmVwxUPgfllxzmD7jDUtsGWvJwBg0qAMvDL2mn7fb/87V6nM1LdaYdW0RPz0+jnoRAE/H3DH/A3N6+AK6pBoYuuHFbecSJ6c7Ny5U/9AoVsCAwNx4cKF+z5nQEAARo4ciUGDBiErKwtDhgzBhx9+qN8/depUxMTEoHv37sjPz0d0dDRCQkIAAGPGjMELL7yAMWPGQKWq/78K135vx6b3amA93VtDq6OgB2RI+fbuScK4x6qfSPh4Ckj5tvJHbls/AT8sk/yj2Gxch/S8Z5kVW3ywYsvdx+fl5Msx9a1W5grLQokwLcOw3uxE0ndEVFQUoqKijO7/91S7zZs3r7QtJCSkyil5p0+fjunTp1d5Xg8PD+zatavKfTdu3EBxcTEmT558j+iJiIhMwNzEKOtJ102k1Wpx8+ZNLFiwAD179kTXrl2lDomIiKhBqr8dm2b2119/oUmTJjhy5AjWr18vdThERGT1RDMs1snqWk4iIyMRGRlZ4+OMdQ8RERHVClEERBOmwbDi7yy2nBAREZFFsbqWEyIionpBNPFeYituOWFyQkREJAndP4spx1sndusQERGRRWHLCRERkRREnYkDYq235YTJCRERkRSYnBjFbh0iIiKyKGw5ISIikgQHxBrD5ISIiEgK7NYxiskJERGRFDjPiVEcc0JEREQWhS0nREREkuCYE2OYnBAREUmBY06MYrcOERERWRS2nBAREUlBFE1sObHeAbFMToiIiCTBMSfGsFuHiIiILApbToiIiKTAeU6MYnJCREQkBd6tYxS7dYiIiMiisOWEiIhICmw5MYrJCRERkSTEfxZTjrdOTE6IiIgkYWLLCW8lJiIiImuwdu1aNG/eHCqVCj169MDhw4elDqkSJidERERSuDXmxJSlhr755hvMnTsXixcvxvHjx9GpUyeEhYUhMzOzFi7w/jE5ISIiksKteU5MWWpo9erVmDp1KiZOnIh27dph/fr1sLe3x8aNG2vhAu8fx5yYkXjrD0VXJm0gRA1MXr7UEdQPYnmJ1CFYPLG8tOL/62KCM1O/K/45XqPRGGxWKpVQKpWVipeWluLYsWOIiIjQb5PJZOjXrx9iY2NNi8XMmJyYUV5eXsU/kvdIGwhRA9MuWOoIyNrk5eXBxcWlVs6tUCigVquRnrzb5HM5OjrCx8fHYNvixYsRGRlZqeyNGzdQXl4OLy8vg+1eXl64cOGCybGYE5MTM/L29kZKSgqcnJwgCILU4QCoyKh9fHyQkpICZ2dnqcOxWKyn6mE9VQ/rqXossZ5EUUReXh68vb1r7TVUKhUSExNRWlpq8rlEUaz0fVNVq0l9w+TEjGQyGZo1ayZ1GFVydna2mDe/JWM9VQ/rqXpYT9VjafVUWy0md1KpVFCpVLX+Ondq3LgxbGxskJGRYbA9IyMDarW6TmO5Fw6IJSIiagAUCgW6deuGvXv36rfpdDrs3bsXQUFBEkZWGVtOiIiIGoi5c+ciPDwc3bt3x0MPPYR33nkHBQUFmDhxotShGWByYuWUSiUWL15sFX2QtYn1VD2sp+phPVUP66nuPfnkk7h+/ToWLVqE9PR0dO7cGTt37qw0SFZqglgn90sRERERVQ/HnBAREZFFYXJCREREFoXJCREREVkUJicNVExMDARBQE5ODgAgKioKrq6uksZEZG0EQcC2bdukDoOo3mFyUg+sX78eTk5OKCu7/RyG/Px82NraIiQkxKDsraTj0qVLdRyl5ZkwYQIEQYAgCLC1tYW/vz9efvllFBcXSx2apCZMmIDhw4dLHYZVuH79OqZPnw5fX18olUqo1WqEhYXhr7/+AgCkpaVh4MCBAICkpCQIgoC4uDgJIzbNne+pO5cBAwbU+uvyb7Zh4a3E9UBoaCjy8/Nx9OhR9OzZEwCwf/9+qNVqHDp0CMXFxfqZBqOjo+Hr64uWLVtKGbLFGDBgADZt2gStVotjx44hPDwcgiDgf//7n9ShkRUYNWoUSktL8dlnn6FFixbIyMjA3r17cfPmTQCwuFk3zeHWe+pOvBWYzI0tJ/VAYGAgmjRpgpiYGP22mJgYDBs2DP7+/jh48KDB9tDQUHzxxRfo3r07nJycoFarMXbsWGRmZlb7Na9fv47u3btjxIgRKCmpv08yvfVr1sfHB8OHD0e/fv2we3fFw7aaN2+Od955x6B8586dDR6YJQgCPvnkE4wYMQL29vZo1aoVtm/fXodXULuqWwcbNmzAkCFDYG9vj7Zt2yI2NhYJCQkICQmBg4MDHn74YYPWusjISHTu3BkbNmyAj48P7O3tMXr0aOTm5tbRldW+nJwc7N+/H//73/8QGhoKPz8/PPTQQ4iIiMDjjz8OwLBbx9/fHwDQpUsXCIJQqdWzvrj1nrpzcXNzA1A7fyuRkZH47LPP8NNPP+lbamJiYtCnTx/MmjXLILbr169DoVAYzIBK9ROTk3oiNDQU0dHR+vXo6GiEhIQgODhYv72oqAiHDh1CaGgotFotli1bhpMnT2Lbtm1ISkrChAkTqvVaKSkp6NWrF9q3b4/vvvvOan4VnTlzBgcOHIBCoajRcUuWLMHo0aNx6tQpDBo0COPGjUNWVlYtRWmZli1bhvHjxyMuLg5t2rTB2LFj8d///hcRERE4evQoRFGs9EWRkJCArVu34ueff8bOnTtx4sQJzJgxQ6IrMD9HR0c4Ojpi27Zt1UrgDx8+DADYs2cP0tLS8MMPP9R2iJIw99/KvHnzMHr0aAwYMABpaWlIS0vDww8/jClTpmDLli0Gdf/ll1+iadOm6NOnT51eM9UCkeqFjz/+WHRwcBC1Wq2o0WhEuVwuZmZmilu2bBF79+4tiqIo7t27VwQgXrlypdLxR44cEQGIeXl5oiiKYnR0tAhAzM7OFkVRFDdt2iS6uLiIFy5cEH18fMTZs2eLOp2uzq6vNoSHh4s2Njaig4ODqFQqRQCiTCYTv/vuO1EURdHPz09cs2aNwTGdOnUSFy9erF8HIC5YsEC/np+fLwIQf/vtt7q4hFoRHh4uDhs2TBTF+6uD2NhYEYD46aef6rd99dVXokql0q8vXrxYtLGxEa9evarf9ttvv4kymUxMS0sz7wVJ6LvvvhPd3NxElUolPvzww2JERIR48uRJ/X4A4o8//iiKoigmJiaKAMQTJ05IE6wZ3PmeunN54403RFGsvb+VO/9mbykqKhLd3NzEb775Rr+tY8eOYmRkpFmvmaTBlpN6IiQkBAUFBThy5Aj279+P1q1bw8PDA8HBwfpxJzExMWjRogV8fX1x7NgxDB06FL6+vnByckJwcDAAIDk52ehrFBUVoVevXhg5ciTefffdSo/hro9CQ0MRFxeHQ4cOITw8HBMnTsSoUaNqdI6OHTvq/+3g4ABnZ+cadZFZgzvr4NY01x06dDDYVlxcDI1Go9/m6+uLpk2b6teDgoKg0+kQHx9fBxHXjVGjRiE1NRXbt2/HgAEDEBMTg65duyIqKkrq0GrNrffUncu0adP0++vqb0WlUuGZZ57Bxo0bAQDHjx/HmTNnqt1CTJaNyUk9ERAQgGbNmiE6OhrR0dH6ZMPb2xs+Pj44cOAAoqOj0adPHxQUFCAsLAzOzs7YvHkzjhw5gh9//BEAUFpaavQ1lEol+vXrhx07duDatWt1cl21zcHBAQEBAejUqRM2btyIQ4cO4dNPPwUAyGQyiP96eoNWq610DltbW4N1QRCg0+lqL+g6dD91cCtprWqbtdRLTahUKjz22GNYuHAhDhw4gAkTJmDx4sVSh1Vrbr2n7lzc3d31++vyb2XKlCnYvXs3rl69ik2bNqFPnz7w8/Mz+bwkPSYn9UhoaChiYmIQExNjMJiud+/e+O2333D48GGEhobiwoULuHnzJlasWIFevXqhTZs21fqlL5PJ8MUXX6Bbt24IDQ1FampqLV5N3ZPJZHj11VexYMECFBUVwcPDA2lpafr9Go0GiYmJEkZY92qzDpKTkw3+hg4ePAiZTIbAwECznN9StWvXDgUFBZW23xrrVF5eXtchWbx7/a0oFIoq661Dhw7o3r07Pv74Y2zZsgWTJk2qs5ipdjE5qUdCQ0Px559/Ii4uTt9yAgDBwcHYsGEDSktLERoaCl9fXygUCrz//vu4fPkytm/fjmXLllXrNWxsbLB582Z06tQJffr0QXp6em1djiSeeOIJ2NjYYO3atejTpw+++OIL7N+/H6dPn0Z4eDhsbGykDrFO1WYdqFQqhIeH4+TJk9i/fz9mz56N0aNHW83ttTdv3kSfPn3w5Zdf4tSpU0hMTMS3336LlStXYtiwYZXKe3p6ws7ODjt37kRGRka9vXOppKQE6enpBsuNGzdMOue9/laaN2+OU6dOIT4+Hjdu3DBo3ZsyZQpWrFgBURQxYsQIk+Igy8HkpB4JDQ1FUVERAgICDB5vHRwcjLy8PP0txx4eHoiKisK3336Ldu3aYcWKFXjrrbeq/TpyuRxfffUVHnjgAfTp08eqxlfI5XLMmjULK1euxCuvvILg4GAMGTIEgwcPxvDhwxvE/DA6nQ5yecUURxEREbVWBwEBARg5ciQGDRqE/v37o2PHjvjwww/Ncm5L4OjoiB49emDNmjXo3bs32rdvj4ULF2Lq1Kn44IMPKpWXy+V47733sGHDBnh7e1eZwNQHO3fuRJMmTQyWRx991KRz3utvZerUqQgMDET37t3h4eGhn+QOAMaMGQO5XI4xY8bo53ui+k8Q/93hTERWbcCAAQgICKjyC9RcIiMjsW3btno9GyrVDVP/VpKSktCyZUscOXIEXbt2NW9wJBm2nBA1ENnZ2dixYwdiYmLQr18/qcMhMolWq0V6ejoWLFiAnj17MjGxMpy+nqiBmDRpEo4cOYIXX3yx3nYpEN3y119/ITQ0FK1bt8Z3330ndThkZuzWISIiIovCbh0iIiKyKExOiIiIyKIwOSEiIiKLwuSEiIiILAqTEyIiIrIoTE6IrMyECRMwfPhw/XpISAheeOGFOo8jJiYGgiAgJyfHaBlBELBt27ZqnzMyMhKdO3c2Ka6kpCQIgsAJ4ogsGJMTojowYcIECIIAQRCgUCgQEBCApUuXoqysrNZf+4cffqj2s5Wqk1AQEdU2TsJGVEcGDBiATZs2oaSkBL/++itmzpwJW1tbREREVCpbWlqqf4qtqe58nD0RUX3AlhOiOqJUKqFWq+Hn54fp06ejX79+2L59O4DbXTFvvPEGvL299Y+KT0lJwejRo+Hq6gp3d3cMGzYMSUlJ+nOWl5dj7ty5cHV1RaNGjfDyyy/j3/Mq/rtbp6SkBPPnz4ePjw+USiUCAgLw6aefIikpCaGhoQAANzc3CIKACRMmAKh4WODy5cvh7+8POzs7dOrUqdKsnL/++itat24NOzs7hIaGGsRZXfPnz0fr1q1hb2+PFi1aYOHChQZPoL1lw4YN8PHxgb29PUaPHl3pCb+ffPIJ2rZtC5VKhTZt2ljVAweJGgImJ0QSsbOzQ2lpqX597969iI+Px+7du7Fjxw5otVqEhYXByckJ+/fvx19//QVHR0cMGDBAf9zbb7+NqKgobNy4EX/++SeysrLw448/3vV1x48fj6+++grvvfcezp8/jw0bNsDR0RE+Pj74/vvvAQDx8fFIS0vDu+++CwBYvnw5Pv/8c6xfvx5nz57FnDlz8PTTT+OPP/4AUJFEjRw5EkOHDkVcXBymTJmCV155pcZ14uTkhKioKJw7dw7vvvsuPv74Y6xZs8agTEJCArZu3Yqff/4ZO3fuxIkTJzBjxgz9/s2bN2PRokV44403cP78ebz55ptYuHAhPvvssxrHQ0QSEYmo1oWHh4vDhg0TRVEUdTqduHv3blGpVIrz5s3T7/fy8hJLSkr0x3zxxRdiYGCgqNPp9NtKSkpEOzs78f/+7/9EURTFJk2aiCtXrtTv12q1YrNmzfSvJYqiGBwcLD7//POiKIpifHy8CEDcvXt3lXFGR0eLAMTs7Gz9tuLiYtHe3l48cOCAQdnJkyeLY8aMEUVRFCMiIsR27doZ7J8/f36lc/0bAPHHH380un/VqlVit27d9OuLFy8WbWxsxKtXr+q3/fbbb6JMJhPT0tJEURTFli1bilu2bDE4z7Jly8SgoCBRFEUxMTFRBCCeOHHC6OsSkbQ45oSojuzYsQOOjo7QarXQ6XQYO3YsIiMj9fs7dOhgMM7k5MmTSEhIgJOTk8F5iouLcenSJeTm5iItLQ09evTQ75PL5ejevXulrp1b4uLiYGNjg+Dg4GrHnZCQgMLCQjz22GMG20tLS9GlSxcAwPnz5w3iAICgoKBqv8Yt33zzDd577z1cunQJ+fn5KCsrg7Ozs0EZX19fNG3a1OB1dDod4uPj4eTkhEuXLmHy5MmYOnWqvkxZWRlcXFxqHA8RSYPJCVEdCQ0Nxbp166BQKODt7Q253PDt5+DgYLCen5+Pbt26YfPmzZXO5eHhcV8x2NnZ1fiY/Px8AMAvv/xikBQAFeNozCU2Nhbjxo3DkiVLEBYWBhcXF3z99dd4++23axzrxx9/XClZsrGxMVusRFS7mJwQ1REHBwcEBARUu3zXrl3xzTffwNPTs1LrwS1NmjTBoUOH0Lt3bwAVLQTHjh1D165dqyzfoUMH6HQ6/PHHH+jXr1+l/bdabsrLy/Xb2rVrB6VSieTkZKMtLm3bttUP7r3l4MGD977IOxw4cAB+fn547bXX9NuuXLlSqVxycjJSU1Ph7e2tfx2ZTIbAwEB4eXnB29sbly9fxrhx42r0+kRkOTgglshCjRs3Do0bN8awYcOwf/9+JCYmIiYmBrNnz8bVq1cBAM8//zxWrFiBbdu24cKFC5gxY8Zd5yhp3rw5wsPDMWnSJGzbtk1/zq1btwIA/Pz8IAgCduzYgevXryM/Px9OTk6YN28e5syZg88++wyXLl3C8ePH8f777+sHmU6bNg0XL17ESy+9hPj4eGzZsgVRUVE1ut5WrVohOTkZX3/9NS5duoT33nuvysG9KpUK4eHhOHnyJPbv34/Zs2dj9OjRUKvVAIAlS5Zg+fLleO+99/D333/j9OnT2LRpE1avXl2jeIhIOkxOiCyUvb099u3bB19fX4wcORJt27bF5MmTUVxcrG9JefHFF/HMM88gPDwcQUFBcHJywogRI+563nXr1uE///kPZsyYgTZt2mDq1KkoKCgAADRt2hRLlizBK6+8Ai8vL8yaNQsAsGzZMixcuBDLly9H27ZtMWDAAPzyyy/w9/cHUDEO5Pvvv8e2bdvQqVMnrF+/Hm+++WaNrvfxxx/HnDlzMGvWLHTu3BkHDhzAwoULK5ULCAjAyJEjMWjQIPTv3x8dO3Y0uFV4ypQp+OSTT7Bp0yZ06NABwcHBiIqK0sdKRJZPEI2NnCMiIiKSAFtOiIiIyKIwOSEiIiKLwuSEiIiILAqTEyIiIrIoTE6IiIjIojA5ISIiIovC5ISIiIgsCpMTIiIisihMToiIiMiiMDkhIiIii8LkhIiIiCzK/wOAXCsSM9WMTQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = './dumps/0_components'\n",
    "filename = f'8lvls_single_antenna_{antenna}'\n",
    "train_dump_dir=os.path.join(directory, f'training/{filename}.pkl')\n",
    "test_dump_dir=os.path.join(directory, f'test/{filename}_test.pkl')\n",
    "results = []\n",
    "\n",
    "\n",
    "print(\"-------------- Training and testing DL model --------------\")\n",
    "X_train, y_train, y_train_dummy, scaler, fcolumns = load_experiment(train_dump_dir)\n",
    "X_test, y_test, y_test_dummy, _, fcolumns = load_experiment(test_dump_dir, scaler)\n",
    "\n",
    "name = \"No-Fused-1\"\n",
    "run_edl_experiment(name, 0, 8, X_train, y_train_dummy)\n",
    "\n",
    "# Test model\n",
    "accuracy = results_test(0, 8, train_dump_dir, test_dump_dir)\n",
    "results.append(\n",
    "    {\n",
    "        \"num_components\": 0,\n",
    "        \"num_levels\": 8,\n",
    "        \"accuracy\": accuracy\n",
    "    })\n",
    "        \n",
    "results_df = pd.DataFrame(results)\n",
    "os.makedirs('results_csv', exist_ok=True)\n",
    "results_df.to_csv('results_csv/results2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
