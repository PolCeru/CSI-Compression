{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2721132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import cmath\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, auc\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image,display\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b11d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interestedIndexes = list(range(-28,0)) + list(range(1,29)) #non null columns\n",
    "\n",
    "# Function to classify\n",
    "def classify(df,ylabel=\"MuStdAmplPaper\",gt=\"Label\",plot_roc=True):\n",
    "    # Y are the labels that indicate if i'm passing or not\n",
    "    Y = df[gt]\n",
    "    num_iter = 1000\n",
    "    # thr is the threshold: if amplitude > thr, then assign to Y_pred 1 (presence), otherwise 0. Every time update the threshold\n",
    "    thr= df[ylabel].min()\n",
    "    tpr = []\n",
    "    fpr= []\n",
    "    thr_list= []\n",
    "    step = (df[ylabel].max() - df[ylabel].min()) / num_iter\n",
    "    while thr <= df[ylabel].max():\n",
    "        # compute the predictions\n",
    "        Y_pred = df.apply(lambda row: 1 if row[ylabel] >= thr else 0, axis=1)\n",
    "        tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
    "        # compute True Positive Rate and False Positive rate to plot the roc curve\n",
    "        tpr.append(tp/(tp+fn))\n",
    "        fpr.append(fp/(fp+tn))\n",
    "        thr_list.append(thr)\n",
    "        thr += step\n",
    "        \n",
    "    if plot_roc:\n",
    "        plt.figure(figsize=(3,3),dpi=220)\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.plot([0, 1], [0, 1], color = 'green')\n",
    "        plt.xlim(-0.05, 1.05)\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC curve\")\n",
    "        plt.show()\n",
    "    \n",
    "    return auc(fpr, tpr)\n",
    "    \n",
    "\n",
    "def checkGT(predicted_true,predicted_false):\n",
    "    tp,tn,fp,fn = [0,0,0,0]\n",
    "    \n",
    "    for t in predicted_true:\n",
    "        fp = fp+1  #add false positive\n",
    "        for l in lower_bounds:\n",
    "            if abs(t-l) <=w2:\n",
    "                tp = tp+1 #put true positive\n",
    "                fp = fp-1#remove the old false positive\n",
    "                break\n",
    "                \n",
    "    for t in predicted_false:\n",
    "        tn= tn+1  #add false positive\n",
    "        for l in lower_bounds:\n",
    "            if abs(t-l) <=w2:\n",
    "                tn = tn-1 #put true neg\n",
    "                fn = fn+1#remove the old false neg\n",
    "                \n",
    "                break\n",
    "    \n",
    "    return tp,tn,fp,fn\n",
    "    \n",
    "def classify_passage(dataframe, ycol=\"MuStdAmplPaper\",gt=\"Label\",plot_roc=True):\n",
    "    dfPeaks = pd.DataFrame(columns=[\"Time\",ycol])\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if index==0 or index == dataframe.tail(1).index:\n",
    "            continue\n",
    "        if row[ycol] >= dataframe.iloc[index-1][ycol] and row[ycol] > dataframe.iloc[index+1][ycol]:\n",
    "            dfPeaks = dfPeaks.append(row[[\"Time\",ycol]], ignore_index=True)\n",
    "    #function that returns the ROC plot and the AUC (skipping multiple misprediction)\n",
    "    tau = min(dfPeaks[ycol])\n",
    "    num_iter = 1000\n",
    "    step = (max(dfPeaks[ycol]) - tau) / num_iter\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    while tau < max(dfPeaks[ycol]):\n",
    "        ttrues = list(dfPeaks.loc[dfPeaks[ycol]>=tau,\"Time\"])\n",
    "        tfalses = list(dfPeaks.loc[dfPeaks[ycol]<tau,\"Time\"])\n",
    "        tp,tn,fp,fn = checkGT(ttrues,tfalses)\n",
    "        tpr.append(tp/(tp+fn))\n",
    "        fpr.append(fp/(fp+tn))\n",
    "        #print(fp/(fp+tn),tp/(tp+fn))\n",
    "        \n",
    "        tau = tau+step\n",
    "    \n",
    "    if(plot_roc):\n",
    "        # Plot the roc curve\n",
    "        plt.figure(figsize=(3,3),dpi=220)\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.plot([0, 1], [0, 1], color = 'green')\n",
    "        plt.xlim(-0.05, 1.05)\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC curve\")\n",
    "        plt.show()\n",
    "\n",
    "    #print(auc(fpr, tpr))\n",
    "    return auc(fpr, tpr)\n",
    "    \n",
    "\n",
    "def extractWindowedFeatures(data,column_indexes = [],w2=3):\n",
    "    data[\"TimeWindow\"] = np.floor(data[\"Timestamp\"] / w2)*w2\n",
    "    #vertical mean/std\n",
    "    dataStd = data.groupby(by=\"TimeWindow\").std().drop([\"Timestamp\",\"Frame_num\"],axis=1)\n",
    "    #dataMean = data.groupby(by=\"TimeWindow\").mean().drop([\"Timestamp\",\"Frame_num\"],axis=1)\n",
    "    \n",
    "    featuredDf = pd.DataFrame()\n",
    "    featuredDf[\"Time\"] = data[\"TimeWindow\"].unique()\n",
    "    #horizontal\n",
    "    featuredDf[\"MuStdAmplPaper\"] = dataStd[[f\"Ampl{j}\" for j in column_indexes]].mean(axis=1).reset_index(drop=True) #Axis=1: mean over different columns -> into one col\n",
    "    return featuredDf\n",
    "\n",
    "def extractWindowedOptimized(dataStd,column_indexes = interestedIndexes,w2=3):\n",
    "    featuredDf = pd.DataFrame()\n",
    "    featuredDf[\"Time\"] = dataStd[\"Time\"].unique()\n",
    "    #horizontal\n",
    "    featuredDf[\"MuStdAmplPaper\"] = dataStd[[f\"Ampl{j}\" for j in column_indexes]].mean(axis=1).reset_index(drop=True) #Axis=1: mean over different columns -> into one col\n",
    "    return featuredDf\n",
    "\n",
    "def filterData(df,w1=3,lambda1=3):\n",
    "    data = df.copy() #clone and return a copy\n",
    "    interestedIndexes = list(range(-28,0)) + list(range(1,29))\n",
    "    #w1 = 5 #best=2\n",
    "    #lambda1 = 3 #best=4\n",
    "    col_list = [f\"Ampl{j}\" for j in interestedIndexes]\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if index == 0:\n",
    "            prev_row = row\n",
    "            continue\n",
    "\n",
    "        subDf = data.loc[(data[\"Timestamp\"]<=row['Timestamp']) & (data[\"Timestamp\"]> row['Timestamp'] - w1),col_list]\n",
    "        means = subDf.mean(axis=0)\n",
    "        stds = subDf.std(axis=0)\n",
    "\n",
    "        for c in col_list: \n",
    "            if (abs(row[c] - means[c]) / stds[c]) > lambda1:\n",
    "                data.at[index,c] = prev_row[c]\n",
    "                #row[c] = prev_row[c]\n",
    "\n",
    "        prev_row = row\n",
    "    return data\n",
    "\n",
    "def substituteDf(data,t1,t2,duration,ftr=\"MuStdAmplPaper\"):\n",
    "    data.loc[(data[\"Time\"] > t1) & (data[\"Time\"] < t1+duration),ftr] = data.loc[(data[\"Time\"] > t2) & (data[\"Time\"] < t2+duration),ftr].values\n",
    "\n",
    "    \n",
    "#use as follows: cleanDf = clean_passage_features(featuredDf)\n",
    "def clean_passage_features(data):\n",
    "    cleanDf = data.copy()\n",
    "    t4 = 1254.0\n",
    "    substituteDf(cleanDf,t4+35,t4+215,30) #clean [30-60]\n",
    "    substituteDf(cleanDf,t4+95,t4+575,25) #clean [90-120]\n",
    "    substituteDf(cleanDf,t4+139,t4+129,8) #clean [120-150]\n",
    "    substituteDf(cleanDf,t4+249,t4+159,10) #clean [240-270]\n",
    "    substituteDf(cleanDf,t4+275,t4+515,30) #clean [270-300]\n",
    "    substituteDf(cleanDf,t4+395,t4+305,30) #clean [390-420]\n",
    "    substituteDf(cleanDf,t4+455,t4+245,10) #clean [450-480]\n",
    "   \n",
    "    return cleanDf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c9561",
   "metadata": {},
   "source": [
    "## Analysis on task2 (passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b978816",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDf = pd.read_csv(\"csv/filteredPassage.csv\")\n",
    "#display(filteredDf)\n",
    "w1=5 #for filtering\n",
    "w2=3 #for windows\n",
    "lambda1=3\n",
    "#for ground truth\n",
    "t2,t3,t4 = [570.0, 873.0, 1254.0] #separation times for gt\n",
    "gt1 = [120,180,240,300,390,540]\n",
    "gt2 = [t2+i for i in range(60,300,30)]\n",
    "gt3 = [t3+30,t3+57] + [t3+i for i in range(90,390,30)]\n",
    "gt4 = [t4+i for i in range(30,630,30)]\n",
    "lower_bounds = gt1+gt2+gt3+gt4\n",
    "upper_bounds = [l + 1 for l in lower_bounds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b828808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9752415458937198\n"
     ]
    }
   ],
   "source": [
    "filteredDf[\"TimeWindow\"] = np.floor(filteredDf[\"Timestamp\"] / w2)*w2\n",
    "dataStd = filteredDf.groupby(by=\"TimeWindow\",as_index=True).std().drop([\"Timestamp\",\"Frame_num\"],axis=1)\n",
    "dataStd[\"Time\"] = dataStd.index\n",
    "featuredDf = extractWindowedOptimized(dataStd,column_indexes = interestedIndexes,w2=w2)\n",
    "data_auc = classify_passage(featuredDf,plot_roc=False)\n",
    "print(data_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320005f9",
   "metadata": {},
   "source": [
    "### Sort columns for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c2fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_cols = len(interestedIndexes)\n",
    "\n",
    "filteredDf[\"TimeWindow\"] = np.floor(filteredDf[\"Timestamp\"] / w2)*w2\n",
    "dataStd = filteredDf.groupby(by=\"TimeWindow\",as_index=True).std().drop([\"Timestamp\",\"Frame_num\"],axis=1)\n",
    "dataStd[\"Time\"] = dataStd.index\n",
    "\n",
    "overallDf = pd.DataFrame(columns=[\"Num_cols\",\"AUC\"])\n",
    "\n",
    "\n",
    "def recursiveColumnSorter(current_list,expansion_list):\n",
    "    global overallDf\n",
    "    resDf = pd.DataFrame(columns=[\"Col_index\",\"AUC\"])\n",
    "    for c in expansion_list:\n",
    "        featuredDf = extractWindowedOptimized(dataStd,column_indexes = current_list + [c],w2=w2)\n",
    "        cleanDf = clean_passage_features(featuredDf)\n",
    "        data_auc = classify_passage(cleanDf,plot_roc=False)\n",
    "        resDf = resDf.append(pd.Series([c,data_auc],index = [\"Col_index\",\"AUC\"]), ignore_index=True)\n",
    "        print(\"Ok\")\n",
    "    selected_col = int(resDf.loc[resDf[\"AUC\"] == max(resDf[\"AUC\"]),\"Col_index\"].values[0])\n",
    "    expansion_list.remove(selected_col)\n",
    "    current_list.append(selected_col)\n",
    "    \n",
    "    overallDf = overallDf.append(pd.Series([len(current_list),max(resDf[\"AUC\"])],index = [\"Num_cols\",\"AUC\"]), ignore_index=True)\n",
    "    if len(current_list) >= max_cols:\n",
    "        return current_list\n",
    "    return recursiveColumnSorter(current_list,expansion_list)\n",
    "\n",
    "start_list = []\n",
    "full_list = interestedIndexes\n",
    "col_sorted = recursiveColumnSorter(start_list,full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48e30e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_cols</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Num_cols  AUC\n",
       "0        1.0  1.0\n",
       "1        2.0  1.0\n",
       "2        3.0  1.0\n",
       "3        4.0  1.0\n",
       "4        5.0  1.0\n",
       "5        6.0  1.0\n",
       "6        7.0  1.0\n",
       "7        8.0  1.0\n",
       "8        9.0  1.0\n",
       "9       10.0  1.0\n",
       "10      11.0  1.0\n",
       "11      12.0  1.0\n",
       "12      13.0  1.0\n",
       "13      14.0  1.0\n",
       "14      15.0  1.0\n",
       "15      16.0  1.0\n",
       "16      17.0  1.0\n",
       "17      18.0  1.0\n",
       "18      19.0  1.0\n",
       "19      20.0  1.0\n",
       "20      21.0  1.0\n",
       "21      22.0  1.0\n",
       "22      23.0  1.0\n",
       "23      24.0  1.0\n",
       "24      25.0  1.0\n",
       "25      26.0  1.0\n",
       "26      27.0  1.0\n",
       "27      28.0  1.0\n",
       "28      29.0  1.0\n",
       "29      30.0  1.0\n",
       "30      31.0  1.0\n",
       "31      32.0  1.0\n",
       "32      33.0  1.0\n",
       "33      34.0  1.0\n",
       "34      35.0  1.0\n",
       "35      36.0  1.0\n",
       "36      37.0  1.0\n",
       "37      38.0  1.0\n",
       "38      39.0  1.0\n",
       "39      40.0  1.0\n",
       "40      41.0  1.0\n",
       "41      42.0  1.0\n",
       "42      43.0  1.0\n",
       "43      44.0  1.0\n",
       "44      45.0  1.0\n",
       "45      46.0  1.0\n",
       "46      47.0  1.0\n",
       "47      48.0  1.0\n",
       "48      49.0  1.0\n",
       "49      50.0  1.0\n",
       "50      51.0  1.0\n",
       "51      52.0  1.0\n",
       "52      53.0  1.0\n",
       "53      54.0  1.0\n",
       "54      55.0  1.0\n",
       "55      56.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[-27,\n",
       " -7,\n",
       " -26,\n",
       " -3,\n",
       " -25,\n",
       " -24,\n",
       " -23,\n",
       " -22,\n",
       " -28,\n",
       " -20,\n",
       " -21,\n",
       " 28,\n",
       " -19,\n",
       " -9,\n",
       " -18,\n",
       " -17,\n",
       " -15,\n",
       " -14,\n",
       " -1,\n",
       " -16,\n",
       " -13,\n",
       " -12,\n",
       " -11,\n",
       " -10,\n",
       " -8,\n",
       " -6,\n",
       " -5,\n",
       " -4,\n",
       " 2,\n",
       " -2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 20,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 22,\n",
       " 21,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(overallDf)\n",
    "col_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7bbb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf.to_csv(\"csv/cols_auc_passage_CLEAN.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ccc54f",
   "metadata": {},
   "source": [
    "### ------------------------------------------\n",
    "#### Analysis on compression (task2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "457e4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ATC compressione sulle feature\n",
    "def compressFeatured(data,ftr=\"MuStdAmplPaper\",num_bits=16):\n",
    "    compressedData = data.copy()\n",
    "    #apply pcm\n",
    "    compressedData[ftr] = (((compressedData[ftr]- min(compressedData[ftr]) )/ (max(compressedData[ftr]) - min(compressedData[ftr])))* (math.pow(2,num_bits)-1)).apply(np.round)\n",
    "    return compressedData\n",
    "\n",
    "#CTA compressione sul dataset originale\n",
    "def compressAmplPhases(data,num_bits=16,column_indexes = [1],scale=\"global\"):\n",
    "    compressedData = data.copy()\n",
    "    maxDf = compressedData.max(axis=0)[[f\"Ampl{j}\" for j in column_indexes]]\n",
    "    minDf = compressedData.min(axis=0)[[f\"Ampl{j}\" for j in column_indexes]]\n",
    "    \n",
    "    ftr_list = [f\"Ampl{j}\" for j in column_indexes]\n",
    "    for ftr in ftr_list:\n",
    "        if scale==\"global\": #min is the global min, max the global max\n",
    "            compressedData[ftr] = (((compressedData[ftr]- min(minDf)) / (max(maxDf) - min(minDf))) * (math.pow(2,num_bits)-1)).apply(np.round)\n",
    "        else:\n",
    "            compressedData[ftr] = (((compressedData[ftr]- minDf[ftr]) / (maxDf[ftr] - minDf[ftr])) * (math.pow(2,num_bits)-1)).apply(np.round)\n",
    "    return compressedData\n",
    "\n",
    "def complex_real(complex_value):\n",
    "    return complex(complex_value).real\n",
    "\n",
    "def complex_imag(complex_value):\n",
    "    return complex(complex_value).imag\n",
    "\n",
    "def complex_rebuild(real,imag):\n",
    "    return (real + 1j*imag)\n",
    "\n",
    "#CTA compressione sul dataset originale\n",
    "def compressXY(data,num_bits=16,column_indexes = [1],scale=\"global\"):\n",
    "    compressedData = data.copy()\n",
    "    \n",
    "    #YOU NEED X AND Y COLUMNS\n",
    "    for j in column_indexes:\n",
    "        compressedData[f'X{j}'] = compressedData[f\"CSI{j}\"].apply(complex_real)\n",
    "        compressedData[f'Y{j}'] = compressedData[f\"CSI{j}\"].apply(complex_imag)\n",
    "        \n",
    "    maxXDf = compressedData.max(axis=0)[[f\"X{j}\" for j in column_indexes]]\n",
    "    maxYDf = compressedData.max(axis=0)[[f\"Y{j}\" for j in column_indexes]]\n",
    "    \n",
    "    minXDf = compressedData.min(axis=0)[[f\"X{j}\" for j in column_indexes]]\n",
    "    minYDf = compressedData.min(axis=0)[[f\"Y{j}\" for j in column_indexes]]\n",
    "    \n",
    "    \n",
    "    for j in column_indexes:\n",
    "        if scale==\"global\": #min is the global min, max the global max\n",
    "            compressedData[f'X{j}'] = (((compressedData[f'X{j}']- min(minXDf)) / (max(maxXDf) - min(minXDf))) * (math.pow(2,num_bits)-1)).apply(np.round)\n",
    "            compressedData[f'Y{j}'] = (((compressedData[f'Y{j}']- min(minYDf)) / (max(maxYDf) - min(minYDf))) * (math.pow(2,num_bits)-1)).apply(np.round)\n",
    "            \n",
    "        else: #min and max are per column \n",
    "            compressedData[f'X{j}'] = (((compressedData[f'X{j}']- minXDf[f'X{j}']) / (maxXDf[f'X{j}'] - minXDf[f'X{j}'])) * (math.pow(2,num_bits)-1)).apply(np.round)\n",
    "            compressedData[f'Y{j}'] = (((compressedData[f'Y{j}']- minYDf[f'Y{j}']) / (maxYDf[f'Y{j}'] - minYDf[f'Y{j}'])) * (math.pow(2,num_bits)-1)).apply(np.round)\n",
    "        #build_back the csi    \n",
    "        #compressedData[f'CSI{j}'] = compressedData[[f'X{j}',f'Y{j}']].apply(complex_rebuild)\n",
    "        compressedData[f'CSI{j}'] = compressedData.apply(lambda x: complex_rebuild(x[f'X{j}'], x[f'Y{j}']), axis=1)\n",
    "        \n",
    "        #compute back ampl and phases\n",
    "        compressedData[f'Ampl{j}'] = compressedData[f'CSI{j}'].apply(abs)\n",
    "        compressedData[f'Phase{j}'] = compressedData[f'CSI{j}'].apply(cmath.phase)\n",
    "            \n",
    "    return compressedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc176ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9752415458937198\n"
     ]
    }
   ],
   "source": [
    "passage = pd.read_csv(\"csv/passage.csv\")\n",
    "filteredPassage = pd.read_csv(\"csv/filteredPassage.csv\")\n",
    "featuresPassage = pd.read_csv(\"csv/featuresPassage.csv\")\n",
    "filteredFeaturesPassage = pd.read_csv(\"csv/filteredFeaturesPassage.csv\")\n",
    "#featuredDf = extractWindowedFeatures(filteredDf,column_indexes = interestedIndexes,w2=w2)\n",
    "orig_auc = classify_passage(filteredFeaturesPassage,plot_roc=False)\n",
    "print(orig_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef8f71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compress ampl and phases AFTER outlier filtering (STEP 3)\n",
    "\n",
    "filteredPassage = pd.read_csv(\"csv/filteredPassage.csv\")\n",
    "print(\"original_auc:\",orig_auc)\n",
    "for n in range(2,33):\n",
    "    compressedPassage = compressAmplPhases(filteredPassage,num_bits=n,column_indexes = interestedIndexes,scale=\"global\")\n",
    "    featuredCompressed = extractWindowedFeatures(compressedPassage,column_indexes = interestedIndexes,w2=w2)\n",
    "    print(n,classify_passage(featuredCompressed,plot_roc=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4caed2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_auc: 0.9752415458937198\n",
      "2 0.08333333333333331\n",
      "3 0.6200284090909091\n",
      "4 0.5607235142118863\n",
      "5 0.9651820431247791\n",
      "6 0.9696921612186606\n",
      "7 0.9675523349436392\n",
      "8 0.9667374959136974\n",
      "9 0.9699053534457261\n",
      "10 0.9695048309178744\n",
      "11 0.9697476436606872\n",
      "12 0.9695345988977343\n",
      "13 0.9695345988977343\n",
      "14 0.9697476436606872\n",
      "15 0.9695345988977343\n",
      "16 0.9697476436606872\n",
      "17 0.9695345988977343\n",
      "18 0.9697476436606872\n",
      "19 0.9697476436606872\n"
     ]
    }
   ],
   "source": [
    "# compress ampl and phases BEFORE outlier filtering (STEP 2)\n",
    "\n",
    "passage = pd.read_csv(\"csv/passage.csv\")\n",
    "print(\"original_auc:\",orig_auc)\n",
    "for n in range(2,20):\n",
    "    #compress amplitude\n",
    "    compressedPassageUnfiltered = compressAmplPhases(passage,num_bits=n,column_indexes = interestedIndexes,scale=\"global\")\n",
    "    #filter\n",
    "    compressedPassageFiltered = filterData(compressedPassageUnfiltered) \n",
    "    #compute features\n",
    "    featuredCompressed = extractWindowedFeatures(compressedPassageFiltered,column_indexes = interestedIndexes,w2=w2)\n",
    "    #classify\n",
    "    print(n,classify_passage(featuredCompressed,plot_roc=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "22f76c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_auc: 0.9752415458937198\n",
      "3 0.36815476190476193\n",
      "4 0.6465359237536656\n",
      "5 0.8905109489051095\n",
      "6 0.9640947968638632\n",
      "7 0.9710144927536233\n",
      "8 0.9705745341614906\n",
      "9 0.9707061362935554\n",
      "10 0.9708603145235893\n",
      "11 0.970284641851736\n",
      "12 0.9694693094629157\n",
      "13 0.9704192546583852\n",
      "14 0.970128245229903\n",
      "15 0.970128245229903\n",
      "16 0.970128245229903\n",
      "17 0.970128245229903\n",
      "18 0.970128245229903\n",
      "19 0.970128245229903\n"
     ]
    }
   ],
   "source": [
    "# compress X and Y global on UNFILTERED, then filter! (STEP 1)\n",
    "\n",
    "passage = pd.read_csv(\"csv/passage.csv\")\n",
    "#display(filteredDf)\n",
    "w1=5 #for filtering\n",
    "w2=3 #for windows\n",
    "lambda1=3\n",
    "interestedIndexes = list(range(-28,0)) + list(range(1,29)) #non null columns\n",
    "\n",
    "\n",
    "print(\"original_auc:\",orig_auc)\n",
    "for n in range(3,20):\n",
    "    compressed_XY = compressXY(passage,num_bits=n,column_indexes = interestedIndexes,scale=\"global\")\n",
    "    compressed_filtered = filterData(compressed_XY)\n",
    "    featuredCompressed = extractWindowedFeatures(compressed_filtered,column_indexes = interestedIndexes,w2=w2)\n",
    "    print(n,classify_passage(featuredCompressed,plot_roc=False))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
